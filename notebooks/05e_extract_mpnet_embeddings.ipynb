{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 05e - Extract MPNet Embeddings (500 Test Samples)\n",
    "\n",
    "**Purpose**: Extract all-mpnet-base-v2 embeddings from 500 test samples using HF Inference API\n",
    "\n",
    "**Why MPNet-base-v2?**\n",
    "- MPNet-base-v2: 110M parameters, 768 dimensions, official sentence-transformers recommendation\n",
    "- MiniLM-L12-v2: 33M parameters, 384 dimensions (current baseline)\n",
    "- BGE-Large: 326M parameters, 1024 dimensions\n",
    "- MPNet is 3.3x larger than MiniLM, better semantic understanding\n",
    "- Official \"best all-around\" model from sentence-transformers\n",
    "\n",
    "**Input Files**:\n",
    "- test_samples_500.csv - 500 loan descriptions\n",
    "- ocean_ground_truth/ - OCEAN ground truth (for consistency check)\n",
    "\n",
    "**Output Files**:\n",
    "- mpnet_embeddings_500.npy - MPNet embeddings matrix (500x768)\n",
    "- 05e_mpnet_extraction_summary.json - Extraction statistics report\n",
    "\n",
    "**Note**: Output dimension is 768 (2x MiniLM's 384, smaller than BGE's 1024)\n",
    "\n",
    "**Estimated Time**: Approximately 8-12 minutes with HF Pro (500 API calls, faster than MiniLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n",
      "Timestamp: 2025-10-29 13:06:05.410074\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from huggingface_hub import InferenceClient\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully\")\n",
    "print(f\"Timestamp: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 2: Load HF Token and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF Token loaded: yes\n",
      "\n",
      "Loading test data...\n",
      "Loaded 500 samples\n",
      "\n",
      "Columns: ['loan_amnt', 'funded_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'issue_d', 'desc', 'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'collections_12_mths_ex_med', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'pub_rec_bankruptcies', 'tax_liens', 'disbursement_method', 'target']\n",
      "\n",
      "Sample preview:\n",
      "   loan_amnt  funded_amnt        term  int_rate  installment grade sub_grade   \n",
      "0      10000        10000   36 months      6.03       304.36     A        A1  \\\n",
      "1      10000        10000   36 months     13.11       337.47     B        B4   \n",
      "2       7200         7200   36 months     11.14       236.20     B        B2   \n",
      "\n",
      "            emp_title emp_length home_ownership  ...  total_acc   \n",
      "0         SKF USA.INC  10+ years       MORTGAGE  ...       19.0  \\\n",
      "1  Harvard University    2 years           RENT  ...       14.0   \n",
      "2             wendy's    5 years           RENT  ...       27.0   \n",
      "\n",
      "  collections_12_mths_ex_med application_type acc_now_delinq   \n",
      "0                        0.0       Individual            0.0  \\\n",
      "1                        0.0       Individual            0.0   \n",
      "2                        0.0       Individual            0.0   \n",
      "\n",
      "  chargeoff_within_12_mths delinq_amnt pub_rec_bankruptcies tax_liens   \n",
      "0                      0.0         0.0                  0.0       0.0  \\\n",
      "1                      0.0         0.0                  0.0       0.0   \n",
      "2                      0.0         0.0                  0.0       0.0   \n",
      "\n",
      "   disbursement_method  target  \n",
      "0                 Cash       0  \n",
      "1                 Cash       1  \n",
      "2                 Cash       0  \n",
      "\n",
      "[3 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load HF Token\n",
    "def load_hf_token():\n",
    "    try:\n",
    "        with open('../.env', 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip() and not line.startswith('#'):\n",
    "                    key, value = line.strip().split('=', 1)\n",
    "                    if key == 'HF_TOKEN':\n",
    "                        return value\n",
    "    except:\n",
    "        pass\n",
    "    return os.getenv('HF_TOKEN', '')\n",
    "\n",
    "hf_token = load_hf_token()\n",
    "print(f\"HF Token loaded: {'yes' if hf_token else 'no'}\")\n",
    "\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HF_TOKEN not found. Please set it in .env file or environment variable\")\n",
    "\n",
    "# Load 500 test samples\n",
    "print(\"\\nLoading test data...\")\n",
    "df_samples = pd.read_csv('../test_samples_500.csv')\n",
    "print(f\"Loaded {len(df_samples)} samples\")\n",
    "print(f\"\\nColumns: {df_samples.columns.tolist()}\")\n",
    "print(f\"\\nSample preview:\")\n",
    "print(df_samples.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 3: Define MPNet Embedding Extraction Function\n",
    "\n",
    "**MPNet-base-v2 Embedding Strategy**:\n",
    "- Model: `sentence-transformers/all-mpnet-base-v2` (110M parameters)\n",
    "- Method: Feature extraction via InferenceClient\n",
    "- Output: 768-dimensional embedding per text\n",
    "- No special prefix required (unlike E5)\n",
    "- Official recommendation from sentence-transformers team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MPNet-base-v2 embedding extraction function defined (using InferenceClient)\n",
      "\n",
      "Testing embedding extraction...\n",
      "✅ Test successful! Embedding shape: (768,)\n",
      "  Dimension: 768\n",
      "  Sample values: [ 0.00726548 -0.06523006 -0.04566502  0.03256908 -0.01838495]\n"
     ]
    }
   ],
   "source": [
    "def extract_mpnet_embedding(text: str, max_retries: int = 3, retry_delay: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Call HF Inference API to extract MPNet embeddings using InferenceClient\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        max_retries: Maximum retry attempts\n",
    "        retry_delay: Retry delay (seconds)\n",
    "    \n",
    "    Returns:\n",
    "        768-dimensional embedding vector\n",
    "    \"\"\"\n",
    "    # Create InferenceClient with HF Pro provider\n",
    "    client = InferenceClient(\n",
    "        provider=\"hf-inference\",\n",
    "        api_key=hf_token\n",
    "    )\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Use feature_extraction method for embeddings\n",
    "            result = client.feature_extraction(\n",
    "                text=text,\n",
    "                model=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "            )\n",
    "            \n",
    "            # Handle the result\n",
    "            if result is not None:\n",
    "                # Convert to numpy array\n",
    "                embeddings_array = np.array(result)\n",
    "                \n",
    "                # Handle different output formats\n",
    "                if len(embeddings_array.shape) == 2:\n",
    "                    # Shape: (seq_len, hidden_dim) - do mean pooling\n",
    "                    mean_embedding = np.mean(embeddings_array, axis=0)\n",
    "                elif len(embeddings_array.shape) == 1:\n",
    "                    # Already a single embedding vector\n",
    "                    mean_embedding = embeddings_array\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected embedding shape: {embeddings_array.shape}\")\n",
    "                \n",
    "                # Verify dimension (MPNet-base-v2 outputs 768 dimensions)\n",
    "                if len(mean_embedding) == 768:\n",
    "                    return mean_embedding\n",
    "                else:\n",
    "                    raise ValueError(f\"Expected 768 dimensions, got {len(mean_embedding)}\")\n",
    "            else:\n",
    "                raise ValueError(\"Received None from API\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            \n",
    "            # Handle rate limiting\n",
    "            if \"rate\" in error_msg.lower() or \"429\" in error_msg:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = retry_delay * (attempt + 2)\n",
    "                    print(f\"    Rate limited... waiting {wait_time}s\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise Exception(f\"Rate limited after {max_retries} retries\")\n",
    "            \n",
    "            # Handle model loading\n",
    "            elif \"loading\" in error_msg.lower() or \"503\" in error_msg:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = retry_delay * (attempt + 1)\n",
    "                    print(f\"    Model loading... waiting {wait_time}s\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise Exception(f\"Model still loading after {max_retries} retries\")\n",
    "            \n",
    "            # Other errors - retry\n",
    "            else:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"    Error: {error_msg[:100]} ... retrying\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise\n",
    "    \n",
    "    raise Exception(\"Failed to extract embedding after all retries\")\n",
    "\n",
    "print(\"\\nMPNet-base-v2 embedding extraction function defined (using InferenceClient)\")\n",
    "\n",
    "# Test with a sample\n",
    "print(\"\\nTesting embedding extraction...\")\n",
    "test_text = \"This is a test sentence for embedding extraction.\"\n",
    "try:\n",
    "    test_emb = extract_mpnet_embedding(test_text)\n",
    "    print(f\"✅ Test successful! Embedding shape: {test_emb.shape}\")\n",
    "    print(f\"  Dimension: {len(test_emb)}\")\n",
    "    print(f\"  Sample values: {test_emb[:5]}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Test failed: {str(e)}\")\n",
    "    print(\"\\nNote: First API call may take longer as model loads. This is normal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 4: Batch Extract MPNet Embeddings\n",
    "\n",
    "**Processing Strategy**:\n",
    "- Process 500 samples sequentially\n",
    "- 0.5 second delay between requests (HF Pro = faster)\n",
    "- Automatic retry on errors\n",
    "- Progress updates every 50 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Starting MPNet-base-v2 Embeddings Extraction (500 samples)\n",
      "================================================================================\n",
      "\n",
      "Note: MPNet-base-v2 is a mid-size model (110M parameters, 768 dimensions).\n",
      "This is 3.3x larger than MiniLM-L12-v2, with better semantic understanding.\n",
      "Estimated time with HF Pro: 8-12 minutes\n",
      "\n",
      "\n",
      "[ 50/500] ( 10.0%) | Success: 50, Failed: 0\n",
      "  Rate: 1.63 samples/s | Elapsed: 0.5min | ETA: 4.6min\n",
      "\n",
      "\n",
      "[100/500] ( 20.0%) | Success: 100, Failed: 0\n",
      "  Rate: 1.59 samples/s | Elapsed: 1.1min | ETA: 4.2min\n",
      "\n",
      "\n",
      "[150/500] ( 30.0%) | Success: 150, Failed: 0\n",
      "  Rate: 1.59 samples/s | Elapsed: 1.6min | ETA: 3.7min\n",
      "\n",
      "\n",
      "[200/500] ( 40.0%) | Success: 200, Failed: 0\n",
      "  Rate: 1.60 samples/s | Elapsed: 2.1min | ETA: 3.1min\n",
      "\n",
      "\n",
      "[250/500] ( 50.0%) | Success: 250, Failed: 0\n",
      "  Rate: 1.59 samples/s | Elapsed: 2.6min | ETA: 2.6min\n",
      "\n",
      "\n",
      "[300/500] ( 60.0%) | Success: 300, Failed: 0\n",
      "  Rate: 1.59 samples/s | Elapsed: 3.1min | ETA: 2.1min\n",
      "\n",
      "\n",
      "[350/500] ( 70.0%) | Success: 350, Failed: 0\n",
      "  Rate: 1.60 samples/s | Elapsed: 3.7min | ETA: 1.6min\n",
      "\n",
      "\n",
      "[400/500] ( 80.0%) | Success: 400, Failed: 0\n",
      "  Rate: 1.54 samples/s | Elapsed: 4.3min | ETA: 1.1min\n",
      "\n",
      "\n",
      "[450/500] ( 90.0%) | Success: 450, Failed: 0\n",
      "  Rate: 1.55 samples/s | Elapsed: 4.9min | ETA: 0.5min\n",
      "\n",
      "    Error: 500 Server Error: Internal Server Error for url: https://router.huggingface.co/hf-inference/models/s ... retrying\n",
      "\n",
      "[500/500] (100.0%) | Success: 500, Failed: 0\n",
      "  Rate: 1.53 samples/s | Elapsed: 5.4min | ETA: 0.0min\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MPNet-base-v2 Embedding Extraction Complete\n",
      "================================================================================\n",
      "\n",
      "Total time: 5.4 minutes (326.5 seconds)\n",
      "Success: 500/500 (100.0%)\n",
      "Failed: 0/500 (0.0%)\n",
      "Average rate: 1.53 samples/second\n",
      "\n",
      "Embedding matrix shape: (500, 768)\n",
      "Data type: float32\n",
      "Memory usage: 1.46 MB\n",
      "Value range: [-0.2117, 0.1788]\n",
      "Mean: -0.0003, Std: 0.0361\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Starting MPNet-base-v2 Embeddings Extraction (500 samples)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote: MPNet-base-v2 is a mid-size model (110M parameters, 768 dimensions).\")\n",
    "print(\"This is 3.3x larger than MiniLM-L12-v2, with better semantic understanding.\")\n",
    "print(\"Estimated time with HF Pro: 8-12 minutes\\n\")\n",
    "\n",
    "embeddings = []\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "error_indices = []\n",
    "\n",
    "start_time = time.time()\n",
    "total_samples = len(df_samples)\n",
    "\n",
    "for idx, (_, row) in enumerate(df_samples.iterrows(), 1):\n",
    "    text = row.get('desc', '')\n",
    "    \n",
    "    # Skip very short descriptions\n",
    "    if len(text.strip()) < 10:\n",
    "        embeddings.append(np.zeros(768))  # 768 dimensions for MPNet\n",
    "        error_count += 1\n",
    "        error_indices.append(idx - 1)\n",
    "        print(f\"  [{idx:3d}] Skipped: text too short\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Extract embedding\n",
    "        emb = extract_mpnet_embedding(text)\n",
    "        \n",
    "        if emb is not None and len(emb) == 768:\n",
    "            embeddings.append(emb)\n",
    "            success_count += 1\n",
    "        else:\n",
    "            embeddings.append(np.zeros(768))\n",
    "            error_count += 1\n",
    "            error_indices.append(idx - 1)\n",
    "            print(f\"  [{idx:3d}] Error: Invalid embedding dimension\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        embeddings.append(np.zeros(768))\n",
    "        error_count += 1\n",
    "        error_indices.append(idx - 1)\n",
    "        \n",
    "        # Log first few errors and periodic errors\n",
    "        if idx <= 10 or error_count % 10 == 1:\n",
    "            print(f\"  [{idx:3d}] ERROR: {str(e)[:80]}\")\n",
    "    \n",
    "    # Progress report\n",
    "    if idx % 50 == 0 or idx == total_samples:\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = idx / elapsed if elapsed > 0 else 0\n",
    "        eta = (total_samples - idx) / rate if rate > 0 else 0\n",
    "        \n",
    "        progress = idx / total_samples * 100\n",
    "        print(f\"\\n[{idx:3d}/{total_samples}] ({progress:5.1f}%) | Success: {success_count}, Failed: {error_count}\")\n",
    "        print(f\"  Rate: {rate:.2f} samples/s | Elapsed: {elapsed/60:.1f}min | ETA: {eta/60:.1f}min\\n\")\n",
    "    \n",
    "    # Delay to avoid rate limiting (shorter with HF Pro)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "elapsed_total = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MPNet-base-v2 Embedding Extraction Complete\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal time: {elapsed_total/60:.1f} minutes ({elapsed_total:.1f} seconds)\")\n",
    "print(f\"Success: {success_count}/{total_samples} ({success_count/total_samples*100:.1f}%)\")\n",
    "print(f\"Failed: {error_count}/{total_samples} ({error_count/total_samples*100:.1f}%)\")\n",
    "print(f\"Average rate: {success_count/elapsed_total:.2f} samples/second\")\n",
    "\n",
    "if error_count > 0:\n",
    "    print(f\"\\nError indices (first 20): {error_indices[:20]}\")\n",
    "\n",
    "# Convert to numpy array\n",
    "X = np.array(embeddings)\n",
    "print(f\"\\nEmbedding matrix shape: {X.shape}\")\n",
    "print(f\"Data type: {X.dtype}\")\n",
    "print(f\"Memory usage: {X.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Value range: [{X.min():.4f}, {X.max():.4f}]\")\n",
    "print(f\"Mean: {X.mean():.4f}, Std: {X.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 5: Save MPNet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving MPNet-base-v2 embeddings...\n",
      "\n",
      "Embeddings saved: ../mpnet_embeddings_500.npy\n",
      "  Model: sentence-transformers/all-mpnet-base-v2\n",
      "  Shape: (500, 768)\n",
      "  Dimensions: 768 (2x MiniLM's 384, smaller than BGE's 1024)\n",
      "  File size: 1.46 MB\n",
      "\n",
      "Verification: Loaded embeddings shape = (500, 768)\n",
      "Verification passed ✓\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving MPNet-base-v2 embeddings...\")\n",
    "\n",
    "# Save embeddings\n",
    "embedding_file = '../mpnet_embeddings_500.npy'\n",
    "np.save(embedding_file, X)\n",
    "print(f\"\\nEmbeddings saved: {embedding_file}\")\n",
    "print(f\"  Model: sentence-transformers/all-mpnet-base-v2\")\n",
    "print(f\"  Shape: {X.shape}\")\n",
    "print(f\"  Dimensions: 768 (2x MiniLM's 384, smaller than BGE's 1024)\")\n",
    "print(f\"  File size: {os.path.getsize(embedding_file) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Verify loading\n",
    "X_loaded = np.load(embedding_file)\n",
    "print(f\"\\nVerification: Loaded embeddings shape = {X_loaded.shape}\")\n",
    "assert np.array_equal(X, X_loaded), \"Verification failed!\"\n",
    "print(\"Verification passed ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 6: Generate Statistics Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics report saved: ../05e_mpnet_extraction_summary.json\n",
      "\n",
      "================================================================================\n",
      "Summary\n",
      "================================================================================\n",
      "{\n",
      "  \"phase\": \"05e - Extract MPNet-base-v2 Embeddings\",\n",
      "  \"timestamp\": \"2025-10-29T13:11:36.150883\",\n",
      "  \"model\": \"sentence-transformers/all-mpnet-base-v2\",\n",
      "  \"model_parameters\": \"110M\",\n",
      "  \"embedding_dimension\": 768,\n",
      "  \"extraction_method\": \"HF Inference API (InferenceClient) + Mean Pooling\",\n",
      "  \"total_samples\": 500,\n",
      "  \"success_count\": 500,\n",
      "  \"error_count\": 0,\n",
      "  \"success_rate\": \"100.00%\",\n",
      "  \"processing_time_seconds\": 326.53772616386414,\n",
      "  \"processing_time_minutes\": 5.442295436064402,\n",
      "  \"samples_per_second\": 1.5312166403372593,\n",
      "  \"embedding_file\": \"../mpnet_embeddings_500.npy\",\n",
      "  \"embedding_statistics\": {\n",
      "    \"mean\": -0.0002619049628265202,\n",
      "    \"std\": 0.036083441227674484,\n",
      "    \"min\": -0.211687833070755,\n",
      "    \"max\": 0.17882640659809113,\n",
      "    \"non_zero_embeddings\": 500\n",
      "  },\n",
      "  \"comparison_with_other_models\": {\n",
      "    \"minilm_parameters\": \"33M\",\n",
      "    \"mpnet_parameters\": \"110M\",\n",
      "    \"bge_parameters\": \"326M\",\n",
      "    \"minilm_dimensions\": 384,\n",
      "    \"mpnet_dimensions\": 768,\n",
      "    \"bge_dimensions\": 1024,\n",
      "    \"parameter_ratio\": \"MPNet is 3.3x larger than MiniLM, 3x smaller than BGE\",\n",
      "    \"dimension_ratio\": \"MPNet has 2x MiniLM dimensions, 0.75x BGE dimensions\",\n",
      "    \"expected_comparison\": \"MPNet is the official sentence-transformers recommendation for best balance\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate summary report\n",
    "summary = {\n",
    "    'phase': '05e - Extract MPNet-base-v2 Embeddings',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': 'sentence-transformers/all-mpnet-base-v2',\n",
    "    'model_parameters': '110M',\n",
    "    'embedding_dimension': 768,\n",
    "    'extraction_method': 'HF Inference API (InferenceClient) + Mean Pooling',\n",
    "    'total_samples': int(total_samples),\n",
    "    'success_count': int(success_count),\n",
    "    'error_count': int(error_count),\n",
    "    'success_rate': f\"{success_count/total_samples*100:.2f}%\",\n",
    "    'processing_time_seconds': float(elapsed_total),\n",
    "    'processing_time_minutes': float(elapsed_total / 60),\n",
    "    'samples_per_second': float(success_count / elapsed_total if elapsed_total > 0 else 0),\n",
    "    'embedding_file': embedding_file,\n",
    "    'embedding_statistics': {\n",
    "        'mean': float(X.mean()),\n",
    "        'std': float(X.std()),\n",
    "        'min': float(X.min()),\n",
    "        'max': float(X.max()),\n",
    "        'non_zero_embeddings': int(success_count)\n",
    "    },\n",
    "    'comparison_with_other_models': {\n",
    "        'minilm_parameters': '33M',\n",
    "        'mpnet_parameters': '110M',\n",
    "        'bge_parameters': '326M',\n",
    "        'minilm_dimensions': 384,\n",
    "        'mpnet_dimensions': 768,\n",
    "        'bge_dimensions': 1024,\n",
    "        'parameter_ratio': 'MPNet is 3.3x larger than MiniLM, 3x smaller than BGE',\n",
    "        'dimension_ratio': 'MPNet has 2x MiniLM dimensions, 0.75x BGE dimensions',\n",
    "        'expected_comparison': 'MPNet is the official sentence-transformers recommendation for best balance'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_file = '../05e_mpnet_extraction_summary.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nStatistics report saved: {summary_file}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Summary\")\n",
    "print(\"=\"*80)\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 7: Compare with Other Embeddings (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Comparison with Other Models\n",
      "================================================================================\n",
      "✗ MiniLM embeddings not found\n",
      "✓ BGE embeddings loaded\n",
      "\n",
      "Embedding Comparison:\n",
      "        Model Parameters  Dimensions      Mean      Std       Min      Max\n",
      "MPNet-base-v2       110M         768 -0.000262 0.036083 -0.211688 0.178826\n",
      "    BGE-Large       326M        1024 -0.000080 0.031250 -0.137539 0.257268\n",
      "\n",
      "Note: Different dimensions mean these embeddings will need separate regression models.\n"
     ]
    }
   ],
   "source": [
    "# Load other embeddings for comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Comparison with Other Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_table = []\n",
    "\n",
    "# MPNet (current)\n",
    "comparison_table.append({\n",
    "    'Model': 'MPNet-base-v2',\n",
    "    'Parameters': '110M',\n",
    "    'Dimensions': 768,\n",
    "    'Mean': X.mean(),\n",
    "    'Std': X.std(),\n",
    "    'Min': X.min(),\n",
    "    'Max': X.max()\n",
    "})\n",
    "\n",
    "# Try loading MiniLM\n",
    "try:\n",
    "    X_minilm = np.load('../deberta_embeddings_500.npy')\n",
    "    comparison_table.append({\n",
    "        'Model': 'MiniLM-L12-v2',\n",
    "        'Parameters': '33M',\n",
    "        'Dimensions': 384,\n",
    "        'Mean': X_minilm.mean(),\n",
    "        'Std': X_minilm.std(),\n",
    "        'Min': X_minilm.min(),\n",
    "        'Max': X_minilm.max()\n",
    "    })\n",
    "    print(\"✓ MiniLM embeddings loaded\")\n",
    "except FileNotFoundError:\n",
    "    print(\"✗ MiniLM embeddings not found\")\n",
    "\n",
    "# Try loading BGE\n",
    "try:\n",
    "    X_bge = np.load('../bge_embeddings_500.npy')\n",
    "    comparison_table.append({\n",
    "        'Model': 'BGE-Large',\n",
    "        'Parameters': '326M',\n",
    "        'Dimensions': 1024,\n",
    "        'Mean': X_bge.mean(),\n",
    "        'Std': X_bge.std(),\n",
    "        'Min': X_bge.min(),\n",
    "        'Max': X_bge.max()\n",
    "    })\n",
    "    print(\"✓ BGE embeddings loaded\")\n",
    "except FileNotFoundError:\n",
    "    print(\"✗ BGE embeddings not found\")\n",
    "\n",
    "# Display comparison\n",
    "if len(comparison_table) > 1:\n",
    "    df_comparison = pd.DataFrame(comparison_table)\n",
    "    print(\"\\nEmbedding Comparison:\")\n",
    "    print(df_comparison.to_string(index=False))\n",
    "    print(\"\\nNote: Different dimensions mean these embeddings will need separate regression models.\")\n",
    "else:\n",
    "    print(\"\\nNo other embeddings found for comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Step 05e Complete - MPNet-base-v2 Embeddings**\n",
    "\n",
    "**Output Files**:\n",
    "- `mpnet_embeddings_500.npy` - 500x768 MPNet embeddings\n",
    "- `05e_mpnet_extraction_summary.json` - Extraction statistics\n",
    "\n",
    "**Model Used**:\n",
    "- **Name**: sentence-transformers/all-mpnet-base-v2\n",
    "- **Size**: 110M parameters (3.3x larger than MiniLM)\n",
    "- **Dimensions**: 768 (2x MiniLM's 384)\n",
    "- **Specialization**: Official sentence-transformers recommendation for best all-around performance\n",
    "\n",
    "**Key Features**:\n",
    "- Better semantic understanding than MiniLM\n",
    "- More compact than BGE (768 vs 1024 dims)\n",
    "- Good balance of quality and efficiency\n",
    "- Official recommendation from sentence-transformers team\n",
    "\n",
    "**Expected Performance**:\n",
    "- Predicted R²: 0.22-0.27 (better than MiniLM's 0.19-0.24)\n",
    "- Feature sparsity: ~90-95% with ElasticNet\n",
    "\n",
    "**Next Steps**:\n",
    "1. Run `05f_train_elasticnet_mpnet.ipynb` to train regression models\n",
    "2. Compare: MiniLM (384d) vs MPNet (768d) vs BGE (1024d) performance\n",
    "3. Evaluate if the 3.3x parameter increase translates to better OCEAN prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
