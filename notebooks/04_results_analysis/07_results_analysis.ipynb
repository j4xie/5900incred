{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Results Analysis and Model Comparison\n",
    "\n",
    "**Objective**: Comprehensive comparison of Baseline and Full Model, evaluate OCEAN feature value\n",
    "\n",
    "## Analysis Contents:\n",
    "1. Load evaluation metrics from both models\n",
    "2. Performance comparison analysis\n",
    "3. Deep dive into OCEAN feature importance\n",
    "4. Business insights and recommendations\n",
    "5. Final conclusions\n",
    "6. Generate comprehensive report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline metrics\n",
    "print(\"Loading Baseline model metrics...\")\n",
    "with open('../../baseline_metrics.json', 'r') as f:\n",
    "    baseline_metrics = json.load(f)\n",
    "\n",
    "print(\"Baseline Model (without OCEAN):\")\n",
    "print(json.dumps(baseline_metrics, indent=2))\n",
    "\n",
    "# Load full model metrics\n",
    "print(\"\\nLoading Full Model metrics...\")\n",
    "with open('../../full_model_metrics.json', 'r') as f:\n",
    "    full_model_metrics = json.load(f)\n",
    "\n",
    "print(\"\\nFull Model (with OCEAN):\")\n",
    "print(json.dumps(full_model_metrics, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Performance Comparison Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance comparison table\n",
    "print(\"=\" * 80)\n",
    "print(\"Detailed Model Performance Comparison\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_data = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC', 'N Features'],\n",
    "    'Baseline': [\n",
    "        baseline_metrics['accuracy'],\n",
    "        baseline_metrics['precision'],\n",
    "        baseline_metrics['recall'],\n",
    "        baseline_metrics['f1_score'],\n",
    "        baseline_metrics['roc_auc'],\n",
    "        baseline_metrics['n_features']\n",
    "    ],\n",
    "    'Full Model': [\n",
    "        full_model_metrics['accuracy'],\n",
    "        full_model_metrics['precision'],\n",
    "        full_model_metrics['recall'],\n",
    "        full_model_metrics['f1_score'],\n",
    "        full_model_metrics['roc_auc'],\n",
    "        full_model_metrics['n_features']\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Calculate absolute difference and percentage improvement\n",
    "comparison_df['Absolute Diff'] = comparison_df['Full Model'] - comparison_df['Baseline']\n",
    "comparison_df['Improvement %'] = (comparison_df['Absolute Diff'] / comparison_df['Baseline']) * 100\n",
    "\n",
    "# For N Features, improvement percentage is not meaningful\n",
    "comparison_df.loc[comparison_df['Metric'] == 'N Features', 'Improvement %'] = np.nan\n",
    "\n",
    "print(\"\\nPerformance comparison table:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison results\n",
    "comparison_df.to_csv('../../final_model_comparison.csv', index=False)\n",
    "print(\"\\nComparison results saved: final_model_comparison.csv\")\n",
    "\n",
    "# Statistical analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Performance Improvement Statistics\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Exclude N Features\n",
    "metric_comparison = comparison_df[comparison_df['Metric'] != 'N Features']\n",
    "\n",
    "avg_improvement = metric_comparison['Improvement %'].mean()\n",
    "max_improvement = metric_comparison['Improvement %'].max()\n",
    "min_improvement = metric_comparison['Improvement %'].min()\n",
    "best_metric = metric_comparison.loc[metric_comparison['Improvement %'].idxmax(), 'Metric']\n",
    "worst_metric = metric_comparison.loc[metric_comparison['Improvement %'].idxmin(), 'Metric']\n",
    "\n",
    "print(f\"Average improvement: {avg_improvement:+.3f}%\")\n",
    "print(f\"Maximum improvement: {max_improvement:+.3f}% ({best_metric})\")\n",
    "print(f\"Minimum improvement: {min_improvement:+.3f}% ({worst_metric})\")\n",
    "print(f\"\\nOCEAN feature count: {full_model_metrics['n_ocean_features']}\")\n",
    "print(f\"Feature increase: {full_model_metrics['n_features'] - baseline_metrics['n_features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: OCEAN Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full model feature importance\n",
    "print(\"Loading feature importance data...\\n\")\n",
    "full_importance = pd.read_csv('../../full_model_feature_importance.csv')\n",
    "\n",
    "# Extract OCEAN features\n",
    "ocean_features = full_importance[full_importance['is_ocean'] == True].copy()\n",
    "non_ocean_features = full_importance[full_importance['is_ocean'] == False].copy()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Detailed OCEAN Feature Importance Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nOCEAN feature rankings:\")\n",
    "ocean_sorted = ocean_features.sort_values('importance', ascending=False)\n",
    "for idx, row in ocean_sorted.iterrows():\n",
    "    rank_in_all = full_importance[full_importance['importance'] >= row['importance']].shape[0]\n",
    "    trait_name = row['feature'].title()\n",
    "    print(f\"  {trait_name:20s}: {row['importance']:.6f} (Overall rank: {rank_in_all}/{len(full_importance)})\")\n",
    "\n",
    "# Statistical analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OCEAN vs Non-OCEAN Feature Comparison\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ocean_total = ocean_features['importance'].sum()\n",
    "non_ocean_total = non_ocean_features['importance'].sum()\n",
    "total = full_importance['importance'].sum()\n",
    "\n",
    "ocean_avg = ocean_features['importance'].mean()\n",
    "non_ocean_avg = non_ocean_features['importance'].mean()\n",
    "\n",
    "print(f\"\\nOCEAN features:\")\n",
    "print(f\"  Count: {len(ocean_features)}\")\n",
    "print(f\"  Total importance: {ocean_total:.6f}\")\n",
    "print(f\"  Average importance: {ocean_avg:.6f}\")\n",
    "print(f\"  Contribution: {ocean_total/total*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nNon-OCEAN features:\")\n",
    "print(f\"  Count: {len(non_ocean_features)}\")\n",
    "print(f\"  Total importance: {non_ocean_total:.6f}\")\n",
    "print(f\"  Average importance: {non_ocean_avg:.6f}\")\n",
    "print(f\"  Contribution: {non_ocean_total/total*100:.2f}%\")\n",
    "\n",
    "# OCEAN personality dimension interpretations\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OCEAN Personality Dimension Interpretations\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ocean_descriptions = {\n",
    "    'openness': 'Openness - Curiosity, imagination, willingness to try new things',\n",
    "    'conscientiousness': 'Conscientiousness - Responsibility, self-discipline, organization',\n",
    "    'extraversion': 'Extraversion - Sociability, energy, positive emotions',\n",
    "    'agreeableness': 'Agreeableness - Cooperation, trust, altruism',\n",
    "    'neuroticism': 'Neuroticism - Emotional instability, anxiety, vulnerability'\n",
    "}\n",
    "\n",
    "for idx, row in ocean_sorted.iterrows():\n",
    "    trait = row['feature']\n",
    "    print(f\"\\n{trait}:\")\n",
    "    print(f\"  {ocean_descriptions.get(trait, 'Unknown dimension')}\")\n",
    "    print(f\"  Importance: {row['importance']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Confusion Matrix Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract confusion matrices\n",
    "cm_baseline = np.array(baseline_metrics['confusion_matrix'])\n",
    "cm_full = np.array(full_model_metrics['confusion_matrix'])\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Confusion Matrix Comparison\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nBaseline Model:\")\n",
    "print(cm_baseline)\n",
    "print(f\"  TN: {cm_baseline[0,0]:,}  |  FP: {cm_baseline[0,1]:,}\")\n",
    "print(f\"  FN: {cm_baseline[1,0]:,}  |  TP: {cm_baseline[1,1]:,}\")\n",
    "\n",
    "print(\"\\nFull Model (with OCEAN):\")\n",
    "print(cm_full)\n",
    "print(f\"  TN: {cm_full[0,0]:,}  |  FP: {cm_full[0,1]:,}\")\n",
    "print(f\"  FN: {cm_full[1,0]:,}  |  TP: {cm_full[1,1]:,}\")\n",
    "\n",
    "# Calculate differences\n",
    "cm_diff = cm_full - cm_baseline\n",
    "print(\"\\nDifference (Full - Baseline):\")\n",
    "print(cm_diff)\n",
    "print(f\"  TN: {cm_diff[0,0]:+,}  |  FP: {cm_diff[0,1]:+,}\")\n",
    "print(f\"  FN: {cm_diff[1,0]:+,}  |  TP: {cm_diff[1,1]:+,}\")\n",
    "\n",
    "# Business impact analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Business Impact Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Assume average loan amount (can be calculated from actual data)\n",
    "avg_loan_amount = 15000  # Example value\n",
    "default_loss_rate = 0.7  # Assume 70% default loss rate\n",
    "\n",
    "# Calculate misclassification costs\n",
    "fp_reduction = cm_baseline[0,1] - cm_full[0,1]  # Reduction in false positives\n",
    "fn_reduction = cm_baseline[1,0] - cm_full[1,0]  # Reduction in false negatives\n",
    "\n",
    "# FP: Rejected good customers, lost interest income\n",
    "fp_cost_saved = fp_reduction * avg_loan_amount * 0.10  # Assume 10% interest rate\n",
    "\n",
    "# FN: Approved bad customers, bear default losses\n",
    "fn_cost_saved = fn_reduction * avg_loan_amount * default_loss_rate\n",
    "\n",
    "total_savings = fp_cost_saved + fn_cost_saved\n",
    "\n",
    "print(f\"\\nFalse Positive (FP) improvement: {fp_reduction:+,} cases\")\n",
    "print(f\"  Potential revenue increase: ${fp_cost_saved:,.2f}\")\n",
    "\n",
    "print(f\"\\nFalse Negative (FN) improvement: {fn_reduction:+,} cases\")\n",
    "print(f\"  Potential loss reduction: ${fn_cost_saved:,.2f}\")\n",
    "\n",
    "print(f\"\\nTotal potential savings: ${total_savings:,.2f}\")\n",
    "\n",
    "if total_savings > 0:\n",
    "    print(\"\\nFull Model has superior business value over Baseline\")\n",
    "elif total_savings < 0:\n",
    "    print(\"\\nFull Model has slightly inferior business value compared to Baseline\")\n",
    "else:\n",
    "    print(\"\\nBoth models have comparable business value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Comprehensive Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 4, hspace=0.35, wspace=0.35)\n",
    "\n",
    "# 1. Performance metrics comparison (Radar chart)\n",
    "ax1 = fig.add_subplot(gs[0, :2], projection='polar')\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC']\n",
    "baseline_vals = [baseline_metrics['accuracy'], baseline_metrics['precision'],\n",
    "                 baseline_metrics['recall'], baseline_metrics['f1_score'],\n",
    "                 baseline_metrics['roc_auc']]\n",
    "full_vals = [full_model_metrics['accuracy'], full_model_metrics['precision'],\n",
    "             full_model_metrics['recall'], full_model_metrics['f1_score'],\n",
    "             full_model_metrics['roc_auc']]\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n",
    "baseline_vals += baseline_vals[:1]\n",
    "full_vals += full_vals[:1]\n",
    "angles += angles[:1]\n",
    "\n",
    "ax1.plot(angles, baseline_vals, 'o-', linewidth=2, label='Baseline', color='#3498db')\n",
    "ax1.fill(angles, baseline_vals, alpha=0.15, color='#3498db')\n",
    "ax1.plot(angles, full_vals, 'o-', linewidth=2, label='Full Model', color='#e74c3c')\n",
    "ax1.fill(angles, full_vals, alpha=0.15, color='#e74c3c')\n",
    "\n",
    "ax1.set_xticks(angles[:-1])\n",
    "ax1.set_xticklabels(metrics, fontsize=10)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_title('Performance Comparison (Radar Chart)', fontsize=13, fontweight='bold', pad=20)\n",
    "ax1.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)\n",
    "ax1.grid(True)\n",
    "\n",
    "# 2. Improvement bar chart\n",
    "ax2 = fig.add_subplot(gs[0, 2:])\n",
    "improvements = metric_comparison['Improvement %'].values\n",
    "colors_bar = ['#2ecc71' if x > 0 else '#e74c3c' for x in improvements]\n",
    "bars = ax2.bar(range(len(metrics)), improvements, color=colors_bar, alpha=0.7, edgecolor='black')\n",
    "ax2.set_xticks(range(len(metrics)))\n",
    "ax2.set_xticklabels(metrics, rotation=45, ha='right', fontsize=10)\n",
    "ax2.set_ylabel('Improvement (%)', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Performance Improvement by Metric', fontsize=13, fontweight='bold')\n",
    "ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, improvements):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{val:+.2f}%', ha='center', va='bottom' if height > 0 else 'top',\n",
    "             fontweight='bold', fontsize=9)\n",
    "\n",
    "# 3 & 4. Confusion matrix comparison\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', ax=ax3,\n",
    "            xticklabels=['Fully Paid', 'Charged Off'],\n",
    "            yticklabels=['Fully Paid', 'Charged Off'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "ax3.set_title('Baseline - Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('True', fontsize=10, fontweight='bold')\n",
    "ax3.set_xlabel('Predicted', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "sns.heatmap(cm_full, annot=True, fmt='d', cmap='Reds', ax=ax4,\n",
    "            xticklabels=['Fully Paid', 'Charged Off'],\n",
    "            yticklabels=['Fully Paid', 'Charged Off'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "ax4.set_title('Full Model - Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('True', fontsize=10, fontweight='bold')\n",
    "ax4.set_xlabel('Predicted', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 5. OCEAN feature importance\n",
    "ax5 = fig.add_subplot(gs[1, 2:])\n",
    "ocean_sorted_plot = ocean_sorted.copy()\n",
    "ocean_sorted_plot['trait_name'] = ocean_sorted_plot['feature'].str.title()\n",
    "bars_ocean = ax5.bar(range(len(ocean_sorted_plot)), ocean_sorted_plot['importance'].values,\n",
    "                     color='#9b59b6', alpha=0.7, edgecolor='black')\n",
    "ax5.set_xticks(range(len(ocean_sorted_plot)))\n",
    "ax5.set_xticklabels(ocean_sorted_plot['trait_name'].values, rotation=45, ha='right', fontsize=10)\n",
    "ax5.set_ylabel('Importance', fontsize=11, fontweight='bold')\n",
    "ax5.set_title('OCEAN Features Importance Ranking', fontsize=13, fontweight='bold')\n",
    "ax5.grid(axis='y', alpha=0.3)\n",
    "# Add value labels\n",
    "for bar, val in zip(bars_ocean, ocean_sorted_plot['importance'].values):\n",
    "    height = bar.get_height()\n",
    "    ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{val:.4f}', ha='center', va='bottom',\n",
    "             fontweight='bold', fontsize=8)\n",
    "\n",
    "# 6. Top 10 feature comparison\n",
    "ax6 = fig.add_subplot(gs[2, :])\n",
    "top_10 = full_importance.head(10)\n",
    "colors_top10 = ['#e74c3c' if is_ocean else '#3498db' for is_ocean in top_10['is_ocean']]\n",
    "y_pos = np.arange(len(top_10))\n",
    "ax6.barh(y_pos, top_10['importance'].values, color=colors_top10, alpha=0.7, edgecolor='black')\n",
    "ax6.set_yticks(y_pos)\n",
    "ax6.set_yticklabels(top_10['feature'].values, fontsize=10)\n",
    "ax6.invert_yaxis()\n",
    "ax6.set_xlabel('Importance', fontsize=11, fontweight='bold')\n",
    "ax6.set_title('Top 10 Most Important Features (Red = OCEAN, Blue = Others)', \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax6.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.savefig('../../comprehensive_results_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nComprehensive visualization saved: comprehensive_results_analysis.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Business Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Business Insights and Recommendations\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. OCEAN Feature Value Assessment\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if avg_improvement > 1:\n",
    "    print(\"Conclusion: OCEAN personality features significantly improved credit risk prediction model performance\")\n",
    "    print(f\"   - Average performance improvement: {avg_improvement:.2f}%\")\n",
    "    print(f\"   - OCEAN feature contribution: {ocean_total/total*100:.2f}%\")\n",
    "    print(\"   - Recommendation: Strongly recommend using full model with OCEAN features in production\")\n",
    "elif avg_improvement > 0:\n",
    "    print(\"Conclusion: OCEAN personality features slightly improved model performance\")\n",
    "    print(f\"   - Average performance improvement: {avg_improvement:.2f}%\")\n",
    "    print(f\"   - OCEAN feature contribution: {ocean_total/total*100:.2f}%\")\n",
    "    print(\"   - Recommendation: Consider using OCEAN features, but weigh implementation costs\")\n",
    "else:\n",
    "    print(\"Conclusion: OCEAN personality features did not improve model performance\")\n",
    "    print(f\"   - Average performance improvement: {avg_improvement:.2f}%\")\n",
    "    print(\"   - Recommendation: Not recommended to use OCEAN features, or improve feature extraction method\")\n",
    "\n",
    "print(\"\\n2. Most Valuable OCEAN Dimension\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "top_ocean_trait = ocean_sorted.iloc[0]\n",
    "trait_name = top_ocean_trait['feature'].title()\n",
    "print(f\"Most important dimension: {trait_name}\")\n",
    "print(f\"Importance score: {top_ocean_trait['importance']:.6f}\")\n",
    "print(f\"Business meaning: {ocean_descriptions.get(top_ocean_trait['feature'], 'Unknown')}\")\n",
    "\n",
    "print(\"\\n3. Model Deployment Recommendations\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Data requirements:\")\n",
    "print(\"  - Applicants must provide loan purpose description (desc field)\")\n",
    "print(\"  - Text length recommendation: 50-500 characters\")\n",
    "print(\"  - Text quality: Authentic, detailed personal statement\")\n",
    "\n",
    "print(\"\\nImplementation steps:\")\n",
    "print(\"  1. Collect applicant loan application descriptions\")\n",
    "print(\"  2. Use OCEAN feature extraction model to process text\")\n",
    "print(\"  3. Combine OCEAN features with traditional features\")\n",
    "print(\"  4. Use full model for credit scoring\")\n",
    "print(\"  5. Make approval decisions based on predictions and business rules\")\n",
    "\n",
    "print(\"\\n4. Potential Risks and Limitations\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Data quality risks:\")\n",
    "print(\"  - Applicants may provide false or embellished descriptions\")\n",
    "print(\"  - Text length and quality may vary significantly\")\n",
    "print(\"  - Different cultural backgrounds may affect expression patterns\")\n",
    "\n",
    "print(\"\\nTechnical limitations:\")\n",
    "print(\"  - Current dictionary-based method may not be as accurate as deep learning models\")\n",
    "print(\"  - OCEAN extraction depends on text quality\")\n",
    "print(\"  - Model requires regular updates and validation\")\n",
    "\n",
    "print(\"\\n5. Future Improvement Directions\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Feature extraction improvements:\")\n",
    "print(\"  - Use pre-trained Transformer models (BERT, RoBERTa)\")\n",
    "print(\"  - Train specialized personality prediction models\")\n",
    "print(\"  - Combine other text fields (title, purpose)\")\n",
    "\n",
    "print(\"\\nModel optimization:\")\n",
    "print(\"  - Hyperparameter tuning\")\n",
    "print(\"  - Try other algorithms (LightGBM, CatBoost)\")\n",
    "print(\"  - Ensemble learning methods\")\n",
    "print(\"  - Feature engineering and selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Final Conclusions\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nResearch Objective\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Evaluate the value of OCEAN personality features in credit risk prediction\")\n",
    "\n",
    "print(\"\\nKey Findings\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"1. Model performance comparison:\")\n",
    "print(f\"   - Baseline model ROC-AUC: {baseline_metrics['roc_auc']:.4f}\")\n",
    "print(f\"   - Full Model ROC-AUC: {full_model_metrics['roc_auc']:.4f}\")\n",
    "print(f\"   - Improvement: {(full_model_metrics['roc_auc'] - baseline_metrics['roc_auc'])/baseline_metrics['roc_auc']*100:+.2f}%\")\n",
    "\n",
    "print(f\"\\n2. OCEAN feature analysis:\")\n",
    "print(f\"   - Feature count: {len(ocean_features)}\")\n",
    "print(f\"   - Total contribution: {ocean_total/total*100:.2f}%\")\n",
    "print(f\"   - Average importance: {ocean_avg:.6f}\")\n",
    "print(f\"   - Most important dimension: {ocean_sorted.iloc[0]['feature'].title()}\")\n",
    "\n",
    "print(f\"\\n3. Business value:\")\n",
    "if total_savings > 0:\n",
    "    print(f\"   - Potential savings: ${total_savings:,.2f} (based on test set)\")\n",
    "    print(f\"   - FP improvement: {fp_reduction:+,} cases\")\n",
    "    print(f\"   - FN improvement: {fn_reduction:+,} cases\")\n",
    "else:\n",
    "    print(f\"   - Business value assessment: Requires further analysis\")\n",
    "\n",
    "print(\"\\nFinal Recommendation\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if avg_improvement > 1 and total_savings > 0:\n",
    "    print(\"Strongly recommend using full model with OCEAN features:\")\n",
    "    print(\"  - Significant performance improvement\")\n",
    "    print(\"  - Clear business value\")\n",
    "    print(\"  - OCEAN features provide unique predictive information\")\n",
    "elif avg_improvement > 0:\n",
    "    print(\"Consider using OCEAN features, but weigh costs:\")\n",
    "    print(\"  - Performance improved but not significantly\")\n",
    "    print(\"  - Need to collect and process text data\")\n",
    "    print(\"  - Recommend small-scale pilot test first\")\n",
    "else:\n",
    "    print(\"Currently not recommended to use OCEAN features:\")\n",
    "    print(\"  - No performance improvement observed\")\n",
    "    print(\"  - Increased model complexity\")\n",
    "    print(\"  - Suggest improving feature extraction method before re-evaluation\")\n",
    "\n",
    "print(\"\\nResearch Contributions\")\n",
    "print(\"-\" * 80)\n",
    "print(\"1. Validated application value of psycholinguistic features in financial risk control\")\n",
    "print(\"2. Provided complete feature engineering and modeling workflow\")\n",
    "print(\"3. Established rigorous data leakage prevention mechanism\")\n",
    "print(\"4. Developed reusable OCEAN feature extraction method\")\n",
    "\n",
    "print(\"\\nFuture Research Directions\")\n",
    "print(\"-\" * 80)\n",
    "print(\"1. Use advanced NLP models to extract OCEAN features\")\n",
    "print(\"2. Explore other psychological features (e.g., moral judgment, risk preference)\")\n",
    "print(\"3. Study OCEAN feature variations across different customer segments\")\n",
    "print(\"4. Develop real-time personality trait assessment system\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Analysis report generation complete\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate Text Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text report\n",
    "report_content = f\"\"\"\n",
    "{'='*80}\n",
    "OCEAN Personality Features in Credit Risk Prediction\n",
    "Final Analysis Report\n",
    "{'='*80}\n",
    "\n",
    "1. Research Overview\n",
    "{'-'*80}\n",
    "This study evaluates the application value of the OCEAN Big Five personality traits\n",
    "(Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) in credit risk\n",
    "prediction models. We used the Prosper loan dataset to compare XGBoost model performance\n",
    "with and without OCEAN features.\n",
    "\n",
    "Dataset Information:\n",
    "- Total samples: {baseline_metrics['train_size'] + baseline_metrics['test_size']:,}\n",
    "- Training set: {baseline_metrics['train_size']:,}\n",
    "- Test set: {baseline_metrics['test_size']:,}\n",
    "- Samples with description text: 5.58%\n",
    "\n",
    "2. Model Performance Comparison\n",
    "{'-'*80}\n",
    "Baseline Model (without OCEAN features):\n",
    "  - Accuracy:  {baseline_metrics['accuracy']:.4f}\n",
    "  - Precision: {baseline_metrics['precision']:.4f}\n",
    "  - Recall:    {baseline_metrics['recall']:.4f}\n",
    "  - F1 Score:  {baseline_metrics['f1_score']:.4f}\n",
    "  - ROC-AUC:   {baseline_metrics['roc_auc']:.4f}\n",
    "  - Features:  {baseline_metrics['n_features']}\n",
    "\n",
    "Full Model (with OCEAN features):\n",
    "  - Accuracy:  {full_model_metrics['accuracy']:.4f}\n",
    "  - Precision: {full_model_metrics['precision']:.4f}\n",
    "  - Recall:    {full_model_metrics['recall']:.4f}\n",
    "  - F1 Score:  {full_model_metrics['f1_score']:.4f}\n",
    "  - ROC-AUC:   {full_model_metrics['roc_auc']:.4f}\n",
    "  - Features:  {full_model_metrics['n_features']}\n",
    "  - OCEAN features: {full_model_metrics['n_ocean_features']}\n",
    "\n",
    "Performance Improvement:\n",
    "  - Average improvement: {avg_improvement:+.2f}%\n",
    "  - ROC-AUC improvement: {(full_model_metrics['roc_auc'] - baseline_metrics['roc_auc'])/baseline_metrics['roc_auc']*100:+.2f}%\n",
    "\n",
    "3. OCEAN Feature Importance Analysis\n",
    "{'-'*80}\n",
    "OCEAN total contribution: {ocean_total/total*100:.2f}%\n",
    "OCEAN average importance: {ocean_avg:.6f}\n",
    "Non-OCEAN average importance: {non_ocean_avg:.6f}\n",
    "\n",
    "Importance ranking by dimension:\n",
    "\"\"\"\n",
    "\n",
    "for idx, row in ocean_sorted.iterrows():\n",
    "    trait_name = row['feature'].title()\n",
    "    report_content += f\"  {trait_name:20s}: {row['importance']:.6f}\\n\"\n",
    "\n",
    "report_content += f\"\"\"\n",
    "4. Business Impact Assessment\n",
    "{'-'*80}\n",
    "Confusion matrix changes:\n",
    "  - False Positive change: {cm_diff[0,1]:+,}\n",
    "  - False Negative change: {cm_diff[1,0]:+,}\n",
    "  - True Positive change: {cm_diff[1,1]:+,}\n",
    "  - True Negative change: {cm_diff[0,0]:+,}\n",
    "\n",
    "Potential business value:\n",
    "  - Total potential savings: ${total_savings:,.2f}\n",
    "  - From FP improvement: ${fp_cost_saved:,.2f}\n",
    "  - From FN improvement: ${fn_cost_saved:,.2f}\n",
    "\n",
    "5. Conclusions and Recommendations\n",
    "{'-'*80}\n",
    "\"\"\"\n",
    "\n",
    "if avg_improvement > 1:\n",
    "    report_content += \"\"\"Conclusion: OCEAN personality features significantly improved credit risk prediction model performance\n",
    "\n",
    "Recommendations:\n",
    "  - Deploy full model with OCEAN features in production environment\n",
    "  - Collect applicant loan purpose descriptions as model input\n",
    "  - Regularly monitor and update OCEAN feature extraction model\n",
    "  - Consider using more advanced NLP techniques to further improve performance\n",
    "\"\"\"\n",
    "elif avg_improvement > 0:\n",
    "    report_content += \"\"\"Conclusion: OCEAN personality features slightly improved model performance\n",
    "\n",
    "Recommendations:\n",
    "  - Consider using OCEAN features, but weigh implementation costs\n",
    "  - Recommend small-scale A/B testing to validate business value first\n",
    "  - Explore better feature extraction methods\n",
    "\"\"\"\n",
    "else:\n",
    "    report_content += \"\"\"Conclusion: Current OCEAN features did not significantly improve model performance\n",
    "\n",
    "Recommendations:\n",
    "  - Not recommended to use current OCEAN features in production\n",
    "  - Improve feature extraction method (use deep learning models)\n",
    "  - Increase training sample size\n",
    "  - Explore other psychological features\n",
    "\"\"\"\n",
    "\n",
    "report_content += f\"\"\"\n",
    "6. Research Limitations\n",
    "{'-'*80}\n",
    "  - Only used dictionary-based method to extract OCEAN features\n",
    "  - Only 5.58% of samples contain description text\n",
    "  - Did not consider text authenticity and quality\n",
    "  - Did not conduct stratified analysis for different customer segments\n",
    "\n",
    "7. Future Work\n",
    "{'-'*80}\n",
    "  - Use pre-trained Transformer models (BERT/RoBERTa) to extract features\n",
    "  - Collect more samples with description text\n",
    "  - Develop text quality assessment mechanism\n",
    "  - Research OCEAN feature interpretability\n",
    "  - Explore other psycholinguistic features\n",
    "\n",
    "{'='*80}\n",
    "Report generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "with open('../../FINAL_ANALYSIS_REPORT.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"\\nFinal analysis report generated: FINAL_ANALYSIS_REPORT.txt\")\n",
    "print(\"\\n\" + report_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
