{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05b - 训练 Ridge 回归学习 OCEAN 权重\n",
    "\n",
    "**目标**: 使用 500 个带 OCEAN 标签的样本，训练 Ridge 回归模型学习特征对各个 OCEAN 维度的影响\n",
    "\n",
    "## 工作流程:\n",
    "1. 加载 Ground Truth OCEAN 标签 (500 样本)\n",
    "2. 加载干净的建模数据并提取对应的 500 个样本\n",
    "3. 选择 PRE-LOAN 特征（确保无数据泄漏）\n",
    "4. 编码特征（数值型标准化 + 分类型 One-hot）\n",
    "5. 为每个 OCEAN 维度训练 Ridge 回归 (alpha=0.17)\n",
    "6. 提取并保存权重系数\n",
    "7. 评估模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# 设置显示选项\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"库加载成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 加载 Ground Truth OCEAN 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 Ground Truth OCEAN 标签\n",
    "print(\"加载 Ground Truth OCEAN 标签...\")\n",
    "df_ground_truth = pd.read_csv('ocean_ground_truth_500.csv', low_memory=False)\n",
    "\n",
    "print(f\"数据形状: {df_ground_truth.shape}\")\n",
    "print(f\"\\n列名: {list(df_ground_truth.columns)}\")\n",
    "print(f\"\\n目标变量分布:\")\n",
    "print(df_ground_truth['target'].value_counts())\n",
    "\n",
    "# OCEAN 列\n",
    "ocean_cols = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "print(f\"\\nOCEAN 分数统计:\")\n",
    "print(df_ground_truth[ocean_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 加载干净的建模数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 加载干净的建模数据\nprint(\"加载干净的建模数据...\")\ndf_modeling = pd.read_csv('data/loan_clean_for_modeling.csv', low_memory=False)\n\nprint(f\"建模数据形状: {df_modeling.shape}\")\n\n# 由于 Ground Truth 的索引可能不连续，我们需要重新对齐\n# 创建一个 ID 映射来匹配样本\n# 注意: 这里假设 500 个样本的顺序与选择时一致\n\n# 从 ground truth 中获取样本的原始索引（如果有保存）\n# 否则，我们使用前 500 行相应的样本\n\n# 创建一个索引映射\n# 这里我们使用 ground truth 中的 desc 来匹配原始数据\nprint(\"\\n对齐 Ground Truth 和建模数据...\")\n\n# 为了确保准确匹配，我们可以使用 desc 的哈希值\nfrom hashlib import md5\n\ndef get_desc_hash(desc):\n    \"\"\"计算 desc 的哈希值用于匹配\"\"\"\n    if pd.isna(desc):\n        return None\n    return md5(str(desc).encode()).hexdigest()\n\n# 添加哈希列\ndf_ground_truth['desc_hash'] = df_ground_truth['desc'].apply(get_desc_hash)\ndf_modeling['desc_hash'] = df_modeling['desc'].apply(get_desc_hash)\n\n# 查找匹配的行\nmatching_indices = []\nfor hash_val in df_ground_truth['desc_hash']:\n    idx = df_modeling[df_modeling['desc_hash'] == hash_val].index[0] if any(df_modeling['desc_hash'] == hash_val) else None\n    if idx is not None:\n        matching_indices.append(idx)\n\nprint(f\"\\n成功匹配的样本数: {len(matching_indices)} / {len(df_ground_truth)}\")\n\nif len(matching_indices) == len(df_ground_truth):\n    # 使用匹配的索引\n    df_features = df_modeling.loc[matching_indices].reset_index(drop=True)\n    print(\"✅ 所有样本成功对齐\")\nelse:\n    print(f\"⚠️ 警告: 只有 {len(matching_indices)} 个样本成功对齐\")\n    # 使用匹配的部分\n    df_features = df_modeling.loc[matching_indices].reset_index(drop=True)\n    df_ground_truth = df_ground_truth.iloc[:len(df_features)].reset_index(drop=True)\n\nprint(f\"\\n最终数据形状: {df_features.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 定义 PRE-LOAN 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 PRE-LOAN 特征（确保无数据泄漏）\n",
    "# 这些是申请时就已知的特征\n",
    "\n",
    "numeric_features = [\n",
    "    'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'annual_inc', 'dti',\n",
    "    'delinq_2yrs', 'fico_range_low', 'fico_range_high', 'inq_last_6mths',\n",
    "    'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'term', 'grade', 'sub_grade', 'purpose', 'home_ownership', 'emp_length',\n",
    "    'verification_status', 'application_type'\n",
    "]\n",
    "\n",
    "# 检查这些特征是否在数据中存在\n",
    "print(\"检查 PRE-LOAN 特征...\\n\")\n",
    "\n",
    "available_numeric = [f for f in numeric_features if f in df_features.columns]\n",
    "available_categorical = [f for f in categorical_features if f in df_features.columns]\n",
    "\n",
    "print(f\"可用的数值型特征: {len(available_numeric)} 个\")\n",
    "print(available_numeric)\n",
    "\n",
    "print(f\"\\n可用的分类特征: {len(available_categorical)} 个\")\n",
    "print(available_categorical)\n",
    "\n",
    "# 使用可用的特征\n",
    "numeric_features = available_numeric\n",
    "categorical_features = available_categorical\n",
    "all_features = numeric_features + categorical_features\n",
    "\n",
    "print(f\"\\n总特征数: {len(all_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 特征编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备特征矩阵\n",
    "print(\"准备特征矩阵...\\n\")\n",
    "\n",
    "X = df_features[all_features].copy()\n",
    "\n",
    "# 处理缺失值\n",
    "print(\"处理缺失值...\")\n",
    "for col in numeric_features:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col].fillna(X[col].median(), inplace=True)\n",
    "\n",
    "for col in categorical_features:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col].fillna('unknown', inplace=True)\n",
    "\n",
    "print(f\"缺失值处理完成\")\n",
    "\n",
    "# 创建预处理器\n",
    "print(\"\\n创建预处理器...\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 拟合并转换特征\n",
    "print(\"编码特征...\")\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "print(f\"\\n编码后的特征形状: {X_processed.shape}\")\n",
    "\n",
    "# 获取特征名称\n",
    "try:\n",
    "    cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "    feature_names = list(numeric_features) + list(cat_feature_names)\n",
    "    print(f\"总特征数（编码后）: {len(feature_names)}\")\nexcept:\n",
    "    feature_names = [f'feature_{i}' for i in range(X_processed.shape[1])]\n",
    "    print(f\"总特征数（编码后）: {X_processed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 训练 Ridge 回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为每个 OCEAN 维度训练 Ridge 回归模型\n",
    "print(\"为每个 OCEAN 维度训练 Ridge 回归模型...\\n\")\n",
    "\n",
    "alpha = 0.17  # 指定的正则化参数\n",
    "ocean_models = {}\n",
    "ocean_scores = {}\n",
    "\n",
    "for ocean_trait in ocean_cols:\n",
    "    print(f\"\\n训练 {ocean_trait.upper()} 模型...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # 目标变量\n",
    "    y = df_ground_truth[ocean_trait].values\n",
    "    \n",
    "    # 创建并训练 Ridge 回归模型\n",
    "    model = Ridge(alpha=alpha, random_state=RANDOM_STATE)\n",
    "    model.fit(X_processed, y)\n",
    "    \n",
    "    # 预测\n",
    "    y_pred = model.predict(X_processed)\n",
    "    \n",
    "    # 计算评估指标\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    # 保存模型和分数\n",
    "    ocean_models[ocean_trait] = model\n",
    "    ocean_scores[ocean_trait] = {\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"MSE:  {mse:.6f}\")\n",
    "    print(f\"RMSE: {rmse:.6f}\")\n",
    "    print(f\"MAE:  {mae:.6f}\")\n",
    "    print(f\"R²:   {r2:.6f}\")\n",
    "    \n",
    "    # 显示权重最大的特征\n",
    "    coef_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coefficient': model.coef_\n",
    "    }).sort_values('coefficient', key=abs, ascending=False)\n",
    "    \n",
    "    print(f\"\\n前 10 个重要特征:\")\n",
    "    print(coef_df.head(10).to_string(index=False))\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"所有模型训练完成！\")\nprint(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 性能总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建性能总结\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"Ridge 回归模型性能总结\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "performance_df = pd.DataFrame(ocean_scores).T\n",
    "print(\"\\n性能指标对比:\")\n",
    "print(performance_df.to_string())\n",
    "\n",
    "print(\"\\n\\n平均性能:\")\n",
    "print(f\"平均 R²: {performance_df['r2'].mean():.6f}\")\n",
    "print(f\"平均 RMSE: {performance_df['rmse'].mean():.6f}\")\n",
    "print(f\"平均 MAE: {performance_df['mae'].mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: 提取并保存权重系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取所有模型的权重和截距\n",
    "print(\"提取权重系数...\\n\")\n",
    "\n",
    "weights_summary = {}\n",
    "\n",
    "for ocean_trait, model in ocean_models.items():\n",
    "    weights_summary[ocean_trait] = {\n",
    "        'intercept': float(model.intercept_),\n",
    "        'coefficients': {feature_names[i]: float(model.coef_[i]) for i in range(len(feature_names))},\n",
    "        'alpha': alpha\n",
    "    }\n",
    "\n",
    "# 保存为 JSON\n",
    "print(\"保存权重到 JSON...\")\njson_file = 'ocean_weights_formula.json'\nwith open(json_file, 'w') as f:\n",
    "    json.dump(weights_summary, f, indent=2)\n\nprint(f\"✅ 权重已保存: {json_file}\")\n\n# 也保存为 pickle 格式（用于 Python 加载）\nprint(\"\\n保存模型到 pickle...\")\npickle_file = 'ocean_ridge_models.pkl'\nwith open(pickle_file, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'models': ocean_models,\n",
    "        'preprocessor': preprocessor,\n",
    "        'feature_names': feature_names,\n",
    "        'numeric_features': numeric_features,\n",
    "        'categorical_features': categorical_features,\n",
    "        'alpha': alpha\n",
    "    }, f)\n\nprint(f\"✅ 模型已保存: {pickle_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: 创建权重系数 CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建权重系数表\n",
    "print(\"创建权重系数表...\\n\")\n",
    "\n",
    "coefficients_list = []\n\nfor ocean_trait in ocean_cols:\n",
    "    model = ocean_models[ocean_trait]\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # 添加截距行\n",
    "    coefficients_list.append({\n",
    "        'OCEAN_trait': ocean_trait,\n",
    "        'feature': 'INTERCEPT',\n",
    "        'coefficient': intercept\n",
    "    })\n",
    "    \n",
    "    # 添加所有特征的系数\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        coefficients_list.append({\n",
    "            'OCEAN_trait': ocean_trait,\n",
    "            'feature': feature,\n",
    "            'coefficient': model.coef_[i]\n",
    "        })\n",
    "\ncoefficients_df = pd.DataFrame(coefficients_list)\n\n# 保存为 CSV\ncsv_file = 'ocean_weights_coefficients.csv'\ncoefficients_df.to_csv(csv_file, index=False)\n\nprint(f\"✅ 权重系数表已保存: {csv_file}\")\nprint(f\"形状: {coefficients_df.shape}\")\nprint(f\"\\n前 20 行:\")\nprint(coefficients_df.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: 可视化权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化每个 OCEAN 维度的权重\n",
    "print(\"生成权重可视化...\\n\")\n",
    "\nfig, axes = plt.subplots(1, 5, figsize=(20, 5))\n\nfor idx, ocean_trait in enumerate(ocean_cols):\n",
    "    model = ocean_models[ocean_trait]\n",
    "    \n",
    "    # 获取最大的 15 个系数（按绝对值）\n",
    "    coef_abs = np.abs(model.coef_)\n",
    "    top_indices = np.argsort(coef_abs)[-15:][::-1]\n",
    "    \n",
    "    top_features = [feature_names[i] for i in top_indices]\n",
    "    top_coefs = [model.coef_[i] for i in top_indices]\n",
    "    \n",
    "    # 绘图\n",
    "    ax = axes[idx]\n",
    "    colors = ['red' if c < 0 else 'green' for c in top_coefs]\n",
    "    y_pos = np.arange(len(top_features))\n",
    "    \n",
    "    ax.barh(y_pos, top_coefs, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels([f[:20] for f in top_features], fontsize=8)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Coefficient', fontsize=10, fontweight='bold')\n",
    "    ax.set_title(f'{ocean_trait.upper()}\\n(R²={ocean_scores[ocean_trait][\"r2\"]:.4f})', \n",
    "                fontsize=11, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "\nplt.tight_layout()\nplt.savefig('ocean_weights_visualization.png', dpi=300, bbox_inches='tight')\nprint(\"✅ 可视化已保存: ocean_weights_visualization.png\")\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: 总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\nprint(\"Ridge 回归权重训练总结\")\nprint(\"=\" * 80)\n\nprint(\"\\n1️⃣ 训练数据\")\nprint(\"-\" * 80)\nprint(f\"样本数: {len(df_ground_truth):,}\")\nprint(f\"特征数: {X_processed.shape[1]}\")\nprint(f\"  - 数值型特征: {len(numeric_features)}\")\nprint(f\"  - 分类特征 (编码后): {len(feature_names) - len(numeric_features)}\")\n\nprint(\"\\n2️⃣ 模型配置\")\nprint(\"-\" * 80)\nprint(f\"算法: Ridge 回归\")\nprint(f\"正则化参数 (alpha): {alpha}\")\nprint(f\"OCEAN 维度数: {len(ocean_cols)}\")\nprint(f\"每个模型的系数数: {len(feature_names) + 1}\")\n\nprint(\"\\n3️⃣ 性能指标\")\nprint(\"-\" * 80)\nfor ocean_trait in ocean_cols:\n    r2 = ocean_scores[ocean_trait]['r2']\n    rmse = ocean_scores[ocean_trait]['rmse']\n    print(f\"{ocean_trait:20s}: R²={r2:.6f}, RMSE={rmse:.6f}\")\n\nprint(\"\\n4️⃣ 生成的文件\")\nprint(\"-\" * 80)\nprint(\"1. ocean_weights_formula.json\")\nprint(\"   - 格式: JSON 对象，包含每个 OCEAN 维度的权重\")\nprint(f\"   - 结构: {{ ocean_trait: {{ 'intercept': ..., 'coefficients': {{...}}, 'alpha': ... }} }}\")\nprint(\"\")\nprint(\"2. ocean_ridge_models.pkl\")\nprint(\"   - 格式: Python pickle 文件\")\nprint(\"   - 内容: 5 个已训练的 Ridge 模型 + 预处理器\")\nprint(\"\")\nprint(\"3. ocean_weights_coefficients.csv\")\nprint(f\"   - 格式: CSV 文件，{coefficients_df.shape[0]} 行\")\nprint(\"   - 列: OCEAN_trait, feature, coefficient\")\nprint(\"\")\nprint(\"4. ocean_weights_visualization.png\")\nprint(\"   - 5 个 OCEAN 维度的权重可视化\")\n\nprint(\"\\n5️⃣ 下一步\")\nprint(\"-\" * 80)\nprint(\"运行 05c_apply_ocean_to_all.ipynb:\")\nprint(\"1. 加载保存的权重公式\")\nprint(\"2. 为所有客户应用公式\")\nprint(\"3. 生成完整的 OCEAN 特征 CSV\")\nprint(\"\")\nprint(\"然后进行后续的 XGBoost 建模:\")\nprint(\"- 04_xgboost_baseline.ipynb\")\nprint(\"- 06_xgboost_with_ocean.ipynb\")\nprint(\"- 07_results_analysis.ipynb\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"✅ Ridge 回归权重训练完成！\")\nprint(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}