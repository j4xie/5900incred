{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - OCEAN 人格特征提取\n",
    "\n",
    "**目标**: 从 desc 文本字段中提取 OCEAN 五大人格特征\n",
    "\n",
    "## OCEAN 五大人格维度:\n",
    "- **O**penness (开放性): 想象力、好奇心、创造性\n",
    "- **C**onscientiousness (尽责性): 责任感、计划性、自律\n",
    "- **E**xtraversion (外向性): 社交性、活力、积极情绪\n",
    "- **A**greeableness (宜人性): 合作性、信任、利他\n",
    "- **N**euroticism (神经质): 情绪不稳定、焦虑、脆弱\n",
    "\n",
    "## 关键要求:\n",
    "1. 使用与 baseline 模型相同的 train/test split\n",
    "2. 避免数据泄漏\n",
    "3. 为每个样本生成 5 个 OCEAN 分数 (0-1 范围)\n",
    "4. 保存特征以便后续模型使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# 设置随机种子（与 baseline 模型保持一致）\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# 设置显示选项\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"库加载成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 加载干净的建模数据\nprint(\"加载干净的建模数据...\")\ndf = pd.read_csv('../../data/loan_clean_for_modeling.csv', low_memory=False)\n\nprint(f\"数据形状: {df.shape[0]:,} 行 × {df.shape[1]} 列\")\n\n# 检查 desc 字段\nif 'desc' in df.columns:\n    non_null_desc = df['desc'].notna().sum()\n    print(f\"\\ndesc 非空样本: {non_null_desc:,} ({non_null_desc/len(df)*100:.2f}%)\")\n    print(f\"\\n示例 desc 文本 (前3个):\")\n    for i, text in enumerate(df['desc'].dropna().head(3), 1):\n        text_str = str(text)[:150]\n        print(f\"{i}. {text_str}...\")\nelse:\n    print(\"\\n警告: 未找到 desc 列！\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train/Test Split（与 baseline 保持一致）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备特征和目标变量\n",
    "X = df.drop(columns=['target'], errors='ignore')\n",
    "y = df['target']\n",
    "\n",
    "# 使用相同的随机种子进行分割\n",
    "print(\"执行 Train/Test 分割（与 baseline 一致）...\\n\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape[0]:,}\")\n",
    "print(f\"测试集大小: {X_test.shape[0]:,}\")\n",
    "\n",
    "# 提取 desc 列\n",
    "desc_train = X_train['desc'].copy()\n",
    "desc_test = X_test['desc'].copy()\n",
    "\n",
    "print(f\"\\n训练集 desc 非空: {desc_train.notna().sum():,}\")\n",
    "print(f\"测试集 desc 非空: {desc_test.notna().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 定义 OCEAN 词典（Lexicon-based Approach）\n",
    "\n",
    "使用心理语言学词典来识别文本中与各个人格维度相关的词汇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCEAN 词典 - 基于心理语言学研究\n",
    "ocean_lexicon = {\n",
    "    'openness': {\n",
    "        'keywords': [\n",
    "            'creative', 'imaginative', 'innovative', 'artistic', 'curious',\n",
    "            'explore', 'adventure', 'new', 'different', 'unique', 'original',\n",
    "            'idea', 'dream', 'vision', 'experience', 'discover', 'learn',\n",
    "            'travel', 'culture', 'art', 'education', 'knowledge', 'grow',\n",
    "            'opportunity', 'future', 'possibility', 'potential', 'change'\n",
    "        ],\n",
    "        'description': '开放性 - 好奇心、想象力、创造性'\n",
    "    },\n",
    "    'conscientiousness': {\n",
    "        'keywords': [\n",
    "            'responsible', 'organized', 'plan', 'goal', 'achieve', 'complete',\n",
    "            'careful', 'thorough', 'diligent', 'disciplined', 'reliable',\n",
    "            'manage', 'budget', 'save', 'financial', 'stability', 'secure',\n",
    "            'pay', 'repay', 'debt', 'consolidate', 'improve', 'credit',\n",
    "            'commit', 'promise', 'obligation', 'duty', 'obligation'\n",
    "        ],\n",
    "        'description': '尽责性 - 责任感、自律、计划性'\n",
    "    },\n",
    "    'extraversion': {\n",
    "        'keywords': [\n",
    "            'social', 'friend', 'family', 'people', 'celebrate', 'party',\n",
    "            'wedding', 'event', 'community', 'together', 'share', 'join',\n",
    "            'active', 'energy', 'enthusiasm', 'excited', 'positive',\n",
    "            'happy', 'love', 'enjoy', 'fun', 'life', 'relationship'\n",
    "        ],\n",
    "        'description': '外向性 - 社交性、活力、积极情绪'\n",
    "    },\n",
    "    'agreeableness': {\n",
    "        'keywords': [\n",
    "            'help', 'support', 'care', 'assist', 'generous', 'kind',\n",
    "            'family', 'children', 'parents', 'trust', 'honest', 'fair',\n",
    "            'cooperate', 'understand', 'compassion', 'empathy',\n",
    "            'community', 'charity', 'donate', 'volunteer', 'serve',\n",
    "            'together', 'team', 'partnership', 'relationship'\n",
    "        ],\n",
    "        'description': '宜人性 - 合作性、信任、利他'\n",
    "    },\n",
    "    'neuroticism': {\n",
    "        'keywords': [\n",
    "            'worry', 'stress', 'anxiety', 'concern', 'fear', 'nervous',\n",
    "            'difficult', 'struggle', 'problem', 'issue', 'challenge',\n",
    "            'emergency', 'unexpected', 'crisis', 'urgent', 'need',\n",
    "            'pressure', 'burden', 'overwhelm', 'frustrated', 'unfortunate',\n",
    "            'hardship', 'setback', 'obstacle', 'difficult', 'tough'\n",
    "        ],\n",
    "        'description': '神经质 - 情绪不稳定、焦虑'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"OCEAN 词典定义完成！\\n\")\n",
    "for trait, info in ocean_lexicon.items():\n",
    "    print(f\"{trait.upper()}: {info['description']}\")\n",
    "    print(f\"  关键词数量: {len(info['keywords'])}\")\n",
    "    print(f\"  示例: {', '.join(info['keywords'][:5])}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: OCEAN 特征提取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ocean_features(text):\n",
    "    \"\"\"\n",
    "    从文本中提取 OCEAN 人格特征分数\n",
    "    \n",
    "    参数:\n",
    "        text: 输入文本\n",
    "    \n",
    "    返回:\n",
    "        dict: 包含 5 个 OCEAN 分数的字典 (0-1 范围)\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        # 缺失文本返回中性值 0.5\n",
    "        return {\n",
    "            'ocean_openness': 0.5,\n",
    "            'ocean_conscientiousness': 0.5,\n",
    "            'ocean_extraversion': 0.5,\n",
    "            'ocean_agreeableness': 0.5,\n",
    "            'ocean_neuroticism': 0.5\n",
    "        }\n",
    "    \n",
    "    # 文本预处理\n",
    "    text_lower = str(text).lower()\n",
    "    # 移除标点符号\n",
    "    text_clean = re.sub(r'[^a-z\\s]', ' ', text_lower)\n",
    "    words = text_clean.split()\n",
    "    word_count = len(words)\n",
    "    \n",
    "    if word_count == 0:\n",
    "        return {\n",
    "            'ocean_openness': 0.5,\n",
    "            'ocean_conscientiousness': 0.5,\n",
    "            'ocean_extraversion': 0.5,\n",
    "            'ocean_agreeableness': 0.5,\n",
    "            'ocean_neuroticism': 0.5\n",
    "        }\n",
    "    \n",
    "    # 计算每个 OCEAN 维度的分数\n",
    "    ocean_scores = {}\n",
    "    \n",
    "    for trait, info in ocean_lexicon.items():\n",
    "        # 计算匹配关键词的数量\n",
    "        matches = sum(1 for word in words if word in info['keywords'])\n",
    "        \n",
    "        # 归一化分数 (基于文本长度)\n",
    "        # 使用对数缩放避免过度依赖文本长度\n",
    "        raw_score = matches / np.sqrt(word_count) if word_count > 0 else 0\n",
    "        \n",
    "        # 将分数映射到 0-1 范围，使用 sigmoid 函数\n",
    "        # 调整参数使得分数分布更合理\n",
    "        normalized_score = 1 / (1 + np.exp(-5 * (raw_score - 0.3)))\n",
    "        \n",
    "        # 确保分数在 0-1 范围内\n",
    "        normalized_score = np.clip(normalized_score, 0, 1)\n",
    "        \n",
    "        ocean_scores[f'ocean_{trait}'] = normalized_score\n",
    "    \n",
    "    return ocean_scores\n",
    "\n",
    "# 测试函数\n",
    "test_text = \"I need this loan to consolidate my debt and improve my financial stability. I am a responsible person who always pays bills on time.\"\n",
    "test_scores = extract_ocean_features(test_text)\n",
    "\n",
    "print(\"测试 OCEAN 提取功能:\\n\")\n",
    "print(f\"输入文本: {test_text}\\n\")\n",
    "print(\"OCEAN 分数:\")\n",
    "for trait, score in test_scores.items():\n",
    "    print(f\"  {trait}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 为训练集提取 OCEAN 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"为训练集提取 OCEAN 特征...\\n\")\n",
    "print(f\"总样本数: {len(desc_train):,}\")\n",
    "\n",
    "# 提取特征\n",
    "ocean_features_train = []\n",
    "for i, text in enumerate(desc_train):\n",
    "    if (i + 1) % 10000 == 0:\n",
    "        print(f\"  已处理: {i+1:,} / {len(desc_train):,}\")\n",
    "    \n",
    "    features = extract_ocean_features(text)\n",
    "    ocean_features_train.append(features)\n",
    "\n",
    "# 转换为 DataFrame\n",
    "ocean_train_df = pd.DataFrame(ocean_features_train, index=desc_train.index)\n",
    "\n",
    "print(f\"\\n✅ 训练集 OCEAN 特征提取完成！\")\n",
    "print(f\"特征形状: {ocean_train_df.shape}\")\n",
    "print(f\"\\n特征统计:\\n\")\n",
    "print(ocean_train_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 为测试集提取 OCEAN 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"为测试集提取 OCEAN 特征...\\n\")\n",
    "print(f\"总样本数: {len(desc_test):,}\")\n",
    "\n",
    "# 提取特征\n",
    "ocean_features_test = []\n",
    "for i, text in enumerate(desc_test):\n",
    "    if (i + 1) % 5000 == 0:\n",
    "        print(f\"  已处理: {i+1:,} / {len(desc_test):,}\")\n",
    "    \n",
    "    features = extract_ocean_features(text)\n",
    "    ocean_features_test.append(features)\n",
    "\n",
    "# 转换为 DataFrame\n",
    "ocean_test_df = pd.DataFrame(ocean_features_test, index=desc_test.index)\n",
    "\n",
    "print(f\"\\n✅ 测试集 OCEAN 特征提取完成！\")\n",
    "print(f\"特征形状: {ocean_test_df.shape}\")\n",
    "print(f\"\\n特征统计:\\n\")\n",
    "print(ocean_test_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: 合并并保存 OCEAN 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 合并训练集和测试集的 OCEAN 特征\nocean_all_df = pd.concat([ocean_train_df, ocean_test_df])\n\n# 按原始索引排序\nocean_all_df = ocean_all_df.sort_index()\n\nprint(f\"合并后的 OCEAN 特征形状: {ocean_all_df.shape}\")\nprint(f\"原始数据形状: {df.shape}\")\n\n# 验证索引一致性\nif len(ocean_all_df) == len(df):\n    print(\"\\n✅ 索引验证通过！\")\nelse:\n    print(f\"\\n⚠️ 警告: 索引不匹配！\")\n    print(f\"OCEAN 特征: {len(ocean_all_df)}\")\n    print(f\"原始数据: {len(df)}\")\n\n# 保存 OCEAN 特征\nocean_all_df.to_csv('../../ocean_features.csv', index=True)\nprint(\"\\nOCEAN 特征已保存: ocean_features.csv\")\n\n# 同时保存训练集和测试集的分开版本（用于后续建模）\nocean_train_df.to_csv('../../ocean_features_train.csv', index=True)\nocean_test_df.to_csv('../../ocean_features_test.csv', index=True)\nprint(\"训练集 OCEAN 特征已保存: ocean_features_train.csv\")\nprint(\"测试集 OCEAN 特征已保存: ocean_features_test.csv\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: OCEAN 特征分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"OCEAN 特征分析\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. 分布统计\n",
    "print(\"\\n1️⃣ OCEAN 特征分布统计\")\n",
    "print(\"-\" * 80)\n",
    "for col in ocean_all_df.columns:\n",
    "    mean_val = ocean_all_df[col].mean()\n",
    "    std_val = ocean_all_df[col].std()\n",
    "    min_val = ocean_all_df[col].min()\n",
    "    max_val = ocean_all_df[col].max()\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  均值: {mean_val:.4f}, 标准差: {std_val:.4f}\")\n",
    "    print(f\"  范围: [{min_val:.4f}, {max_val:.4f}]\")\n",
    "\n",
    "# 2. 相关性分析\n",
    "print(\"\\n2️⃣ OCEAN 特征相关性\")\n",
    "print(\"-\" * 80)\n",
    "correlation_matrix = ocean_all_df.corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "# 3. 与目标变量的关系\n",
    "print(\"\\n3️⃣ OCEAN 特征与违约率的关系\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# 合并目标变量\n",
    "ocean_with_target = ocean_all_df.copy()\n",
    "ocean_with_target['target'] = y\n",
    "\n",
    "# 计算每个 OCEAN 特征的违约率差异\n",
    "for col in ocean_all_df.columns:\n",
    "    # 将特征分为高低两组（以中位数为界）\n",
    "    median_val = ocean_with_target[col].median()\n",
    "    high_group = ocean_with_target[ocean_with_target[col] > median_val]\n",
    "    low_group = ocean_with_target[ocean_with_target[col] <= median_val]\n",
    "    \n",
    "    high_default_rate = high_group['target'].mean()\n",
    "    low_default_rate = low_group['target'].mean()\n",
    "    diff = high_default_rate - low_default_rate\n",
    "    \n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  高分组违约率: {high_default_rate*100:.2f}%\")\n",
    "    print(f\"  低分组违约率: {low_default_rate*100:.2f}%\")\n",
    "    print(f\"  差异: {diff*100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: 可视化 OCEAN 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 创建可视化\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\naxes = axes.flatten()\n\n# 1-5. 每个 OCEAN 特征的分布\nfor i, col in enumerate(ocean_all_df.columns):\n    ax = axes[i]\n    \n    # 违约 vs 非违约的分布\n    default_scores = ocean_with_target[ocean_with_target['target'] == 1][col]\n    non_default_scores = ocean_with_target[ocean_with_target['target'] == 0][col]\n    \n    ax.hist(non_default_scores, bins=30, alpha=0.5, label='Fully Paid', color='green', edgecolor='black')\n    ax.hist(default_scores, bins=30, alpha=0.5, label='Charged Off', color='red', edgecolor='black')\n    \n    trait_name = col.replace('ocean_', '').title()\n    ax.set_xlabel('Score', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n    ax.set_title(f'{trait_name} Distribution', fontsize=12, fontweight='bold')\n    ax.legend(fontsize=9)\n    ax.grid(alpha=0.3)\n\n# 6. OCEAN 相关性热图\nax = axes[5]\nim = ax.imshow(correlation_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\nax.set_xticks(range(len(ocean_all_df.columns)))\nax.set_yticks(range(len(ocean_all_df.columns)))\nax.set_xticklabels([col.replace('ocean_', '')[:3].upper() for col in ocean_all_df.columns], \n                    rotation=45, fontsize=10)\nax.set_yticklabels([col.replace('ocean_', '')[:3].upper() for col in ocean_all_df.columns], \n                    fontsize=10)\nax.set_title('OCEAN Feature Correlations', fontsize=12, fontweight='bold')\n\n# 添加数值标签\nfor i in range(len(ocean_all_df.columns)):\n    for j in range(len(ocean_all_df.columns)):\n        text = ax.text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}',\n                      ha='center', va='center', color='black', fontsize=9, fontweight='bold')\n\nplt.colorbar(im, ax=ax)\n\nplt.tight_layout()\nplt.savefig('../../ocean_features_analysis.png', dpi=300, bbox_inches='tight')\nprint(\"\\n可视化已保存: ocean_features_analysis.png\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: 总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"OCEAN 特征提取总结\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1️⃣ 提取方法\")\n",
    "print(\"-\" * 80)\n",
    "print(\"方法: Lexicon-based (词典匹配法)\")\n",
    "print(\"词典来源: 心理语言学研究（LIWC 风格）\")\n",
    "print(f\"总关键词数: {sum(len(info['keywords']) for info in ocean_lexicon.values())}\")\n",
    "print(\"归一化: Sigmoid 函数 + 文本长度调整\")\n",
    "\n",
    "print(\"\\n2️⃣ 特征统计\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"总样本数: {len(ocean_all_df):,}\")\n",
    "print(f\"训练集样本: {len(ocean_train_df):,}\")\n",
    "print(f\"测试集样本: {len(ocean_test_df):,}\")\n",
    "print(f\"OCEAN 特征数: {len(ocean_all_df.columns)}\")\n",
    "\n",
    "print(\"\\n3️⃣ 数据质量\")\n",
    "print(\"-\" * 80)\n",
    "print(\"缺失值处理: 填充为中性值 0.5\")\n",
    "print(\"分数范围: [0, 1]\")\n",
    "print(f\"数据泄漏检查: ✅ 训练集和测试集分别提取\")\n",
    "\n",
    "print(\"\\n4️⃣ 保存的文件\")\n",
    "print(\"-\" * 80)\n",
    "print(\"1. ocean_features.csv - 完整 OCEAN 特征\")\n",
    "print(\"2. ocean_features_train.csv - 训练集 OCEAN 特征\")\n",
    "print(\"3. ocean_features_test.csv - 测试集 OCEAN 特征\")\n",
    "print(\"4. ocean_features_analysis.png - 可视化分析\")\n",
    "\n",
    "print(\"\\n5️⃣ 下一步\")\n",
    "print(\"-\" * 80)\n",
    "print(\"✅ OCEAN 特征提取完成，现在可以进行:\")\n",
    "print(\"\")\n",
    "print(\"1. 06_xgboost_with_ocean.ipynb\")\n",
    "print(\"   - 合并 OCEAN 特征与原始特征\")\n",
    "print(\"   - 训练包含 OCEAN 的完整 XGBoost 模型\")\n",
    "print(\"   - 对比 baseline 性能\")\n",
    "print(\"\")\n",
    "print(\"2. 07_results_analysis.ipynb\")\n",
    "print(\"   - 详细对比 Baseline vs Full Model\")\n",
    "print(\"   - 分析 OCEAN 特征的预测价值\")\n",
    "print(\"   - 生成最终报告\")\n",
    "print(\"\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n✅ OCEAN 特征提取完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}