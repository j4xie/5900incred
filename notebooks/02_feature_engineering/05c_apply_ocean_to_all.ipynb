{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05c - 应用 OCEAN 权重公式到所有客户\n",
    "\n",
    "**目标**: 使用从 Ridge 回归学到的权重公式，为所有客户生成 OCEAN 人格分数\n",
    "\n",
    "## 工作流程:\n",
    "1. 加载保存的权重公式和预处理器\n",
    "2. 加载完整的建模数据\n",
    "3. 应用相同的特征编码\n",
    "4. 使用学到的公式计算每个客户的 OCEAN 分数\n",
    "5. 保存完整的 OCEAN 特征到 CSV\n",
    "6. 生成统计和可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# 设置显示选项\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"库加载成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 加载训练好的模型和权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 pickle 格式的模型\n",
    "print(\"加载已训练的 Ridge 回归模型...\")\n",
    "\ntry:\n",
    "    with open('ocean_ridge_models.pkl', 'rb') as f:\n",
    "        model_package = pickle.load(f)\n",
    "    \n",
    "    ocean_models = model_package['models']\n",
    "    preprocessor = model_package['preprocessor']\n",
    "    feature_names = model_package['feature_names']\n",
    "    numeric_features = model_package['numeric_features']\n",
    "    categorical_features = model_package['categorical_features']\n",
    "    alpha = model_package['alpha']\n",
    "    \n",
    "    print(\"✅ 模型加载成功！\")\n",
    "    print(f\"\\n模型信息:\")\n",
    "    print(f\"- OCEAN 维度数: {len(ocean_models)}\")\n",
    "    print(f\"- 总特征数: {len(feature_names)}\")\n",
    "    print(f\"- 数值特征: {len(numeric_features)}\")\n",
    "    print(f\"- 分类特征: {len(categorical_features)}\")\n",
    "    print(f\"- 正则化参数 alpha: {alpha}\")\n",
    "    \nexcept FileNotFoundError:\n",
    "    print(\"❌ 错误: 未找到 ocean_ridge_models.pkl\")\n",
    "    print(\"请先运行 05b_train_ocean_ridge_weights.ipynb\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 加载失败: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 加载完整的建模数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 加载完整的建模数据\nprint(\"加载完整的建模数据...\")\ndf = pd.read_csv('data/loan_clean_for_modeling.csv', low_memory=False)\n\nprint(f\"数据形状: {df.shape}\")\nprint(f\"\\n列名: {list(df.columns)}\")\n\n# 准备特征矩阵\nprint(\"\\n准备特征矩阵...\")\nX = df[numeric_features + categorical_features].copy()\n\n# 处理缺失值\nprint(\"处理缺失值...\")\nfor col in numeric_features:\n    if X[col].isnull().sum() > 0:\n        X[col].fillna(X[col].median(), inplace=True)\n\nfor col in categorical_features:\n    if X[col].isnull().sum() > 0:\n        X[col].fillna('unknown', inplace=True)\n\nprint(f\"\\n特征矩阵形状: {X.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 应用特征编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用已学习的预处理器对新数据进行编码\n",
    "print(\"编码特征...\")\nX_processed = preprocessor.transform(X)\n\nprint(f\"编码后的特征形状: {X_processed.shape}\")\nprint(f\"预期特征数: {len(feature_names)}\")\n\nif X_processed.shape[1] == len(feature_names):\n",
    "    print(\"✅ 特征维度匹配\")\nelse:\n",
    "    print(f\"⚠️ 警告: 特征维度不匹配\")\n",
    "    print(f\"   预期: {len(feature_names)}, 实际: {X_processed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 应用 Ridge 回归模型生成 OCEAN 分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为所有客户生成 OCEAN 分数\n",
    "print(\"应用 Ridge 回归模型生成 OCEAN 分数...\\n\")\n\nocean_cols = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\nocean_features_dict = {col: [] for col in ocean_cols}\n\nfor ocean_trait, model in ocean_models.items():\n",
    "    print(f\"生成 {ocean_trait} 分数...\")\n",
    "    \n",
    "    # 使用模型预测\n",
    "    scores = model.predict(X_processed)\n",
    "    \n",
    "    # 确保分数在 0-1 范围内\n",
    "    scores = np.clip(scores, 0, 1)\n",
    "    \n",
    "    ocean_features_dict[ocean_trait] = scores\n",
    "    \n",
    "    print(f\"  统计: 均值={scores.mean():.4f}, 最小={scores.min():.4f}, 最大={scores.max():.4f}\")\n\n# 转换为 DataFrame\nocean_df = pd.DataFrame(ocean_features_dict)\n\nprint(f\"\\n✅ OCEAN 分数生成完成！\")\nprint(f\"\\n最终 OCEAN 特征统计:\")\nprint(ocean_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 创建最终的 OCEAN 特征数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建最终数据集（包含原始数据和 OCEAN 分数）\n",
    "print(\"创建最终的 OCEAN 特征数据集...\\n\")\n",
    "\n# 验证长度\nif len(ocean_df) == len(df):\n",
    "    print(\"✅ 长度验证通过\")\n",
    "    \n",
    "    # 合并原始数据和 OCEAN 分数\n",
    "    df_with_ocean = df.copy()\n",
    "    for col in ocean_cols:\n",
    "        df_with_ocean[col] = ocean_df[col]\n",
    "    \n",
    "    print(f\"\\n最终数据集形状: {df_with_ocean.shape}\")\n",
    "    print(f\"列名: {list(df_with_ocean.columns)}\")\n",
    "    \nelse:\n",
    "    print(f\"❌ 长度不匹配: OCEAN={len(ocean_df)}, 原始数据={len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 保存 OCEAN 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存两个版本\n",
    "\n# 版本 1: 只包含 OCEAN 特征\nprint(\"保存 OCEAN 特征...\")\nocean_only_df = ocean_df.copy()\nocean_only_file = 'ocean_features.csv'\nocean_only_df.to_csv(ocean_only_file, index=False)\n\nimport os\nfile_size = os.path.getsize(ocean_only_file) / (1024)  # KB\nprint(f\"✅ {ocean_only_file} ({file_size:.2f} KB)\")\nprint(f\"   形状: {ocean_only_df.shape}\")\n\n# 版本 2: 包含所有特征和 OCEAN\nprint(\"\\n保存完整数据集...\")\nfull_file = 'loan_clean_with_ocean.csv'\ndf_with_ocean.to_csv(full_file, index=False)\n\nfile_size = os.path.getsize(full_file) / (1024 * 1024)  # MB\nprint(f\"✅ {full_file} ({file_size:.2f} MB)\")\nprint(f\"   形状: {df_with_ocean.shape}\")\n\n# 版本 3: JSON 格式\njson_file = 'ocean_features.json'\nocean_only_df.to_json(json_file, orient='records')\nprint(f\"✅ {json_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: OCEAN 特征按目标变量分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按目标变量分析 OCEAN 特征\n",
    "print(\"=\" * 80)\n",
    "print(\"OCEAN 特征按目标变量分析\")\n",
    "print(\"=\" * 80)\n",
    "\n# 添加目标变量\nocean_with_target = ocean_df.copy()\nocean_with_target['target'] = df['target'].values\n\nprint(\"\\nFully Paid (target=0) 的 OCEAN 分数:\")\nprint(ocean_with_target[ocean_with_target['target'] == 0][ocean_cols].describe())\n\nprint(\"\\nCharged Off (target=1) 的 OCEAN 分数:\")\nprint(ocean_with_target[ocean_with_target['target'] == 1][ocean_cols].describe())\n\n# 计算两组的平均值差异\nprint(\"\\n\\n两组平均值的差异 (Charged Off - Fully Paid):\")\nprint(\"-\" * 80)\nmean_fully_paid = ocean_with_target[ocean_with_target['target'] == 0][ocean_cols].mean()\nmean_charged_off = ocean_with_target[ocean_with_target['target'] == 1][ocean_cols].mean()\ndiff = mean_charged_off - mean_fully_paid\n\nfor col in ocean_cols:\n",
    "    print(f\"{col:20s}: {diff[col]:+.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: 可视化 OCEAN 特征分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建可视化\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\naxes = axes.flatten()\n\n# 1. 每个 OCEAN 维度的分布\nfor idx, col in enumerate(ocean_cols):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    ax.hist(ocean_df[col], bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    ax.axvline(ocean_df[col].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {ocean_df[col].mean():.3f}')\n",
    "    ax.set_xlabel('Score', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{col.upper()} Distribution', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(alpha=0.3)\n\n# 6. 按目标变量分组的箱线图\nax = axes[5]\nocean_melt = ocean_with_target.melt(id_vars=['target'], value_vars=ocean_cols)\nocean_melt['target_label'] = ocean_melt['target'].apply(lambda x: 'Fully Paid' if x == 0 else 'Charged Off')\n\nsns.boxplot(data=ocean_melt, x='variable', y='value', hue='target_label', ax=ax, palette=['green', 'red'])\nax.set_xlabel('OCEAN Trait', fontsize=11, fontweight='bold')\nax.set_ylabel('Score', fontsize=11, fontweight='bold')\nax.set_title('OCEAN Scores by Target Variable', fontsize=12, fontweight='bold')\nax.set_xticklabels([c[:3].upper() for c in ocean_cols])\nax.legend(title='Status', fontsize=10)\nax.grid(alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.savefig('ocean_features_distribution.png', dpi=300, bbox_inches='tight')\nprint(\"✅ 可视化已保存: ocean_features_distribution.png\")\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: 生成总结报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\nprint(\"OCEAN 特征应用总结报告\")\nprint(\"=\" * 80)\n\nprint(\"\\n1️⃣ 数据规模\")\nprint(\"-\" * 80)\nprint(f\"总样本数: {len(df_with_ocean):,}\")\nprint(f\"OCEAN 维度: {len(ocean_cols)}\")\nprint(f\"总特征数: {df_with_ocean.shape[1]}\")\nprint(f\"  - 原始特征: {df.shape[1]}\")\nprint(f\"  - OCEAN 特征: {len(ocean_cols)}\")\n\nprint(\"\\n2️⃣ OCEAN 分数统计\")\nprint(\"-\" * 80)\nfor col in ocean_cols:\n",
    "    mean_val = ocean_df[col].mean()\n",
    "    std_val = ocean_df[col].std()\n",
    "    print(f\"{col:20s}: 均值={mean_val:.4f}, 标准差={std_val:.4f}, 范围=[{ocean_df[col].min():.4f}, {ocean_df[col].max():.4f}]\")\n\nprint(\"\\n3️⃣ 生成的文件\")\nprint(\"-\" * 80)\nprint(f\"1. ocean_features.csv ({len(ocean_df):,} 行 × {len(ocean_cols)} 列)\")\nprint(f\"   - 格式: CSV\")\nprint(f\"   - 内容: 所有客户的 OCEAN 分数\")\nprint(f\"\")\nprint(f\"2. loan_clean_with_ocean.csv ({df_with_ocean.shape[0]:,} 行 × {df_with_ocean.shape[1]} 列)\")\nprint(f\"   - 格式: CSV\")\nprint(f\"   - 内容: 原始特征 + OCEAN 分数\")\nprint(f\"\")\nprint(f\"3. ocean_features.json\")\nprint(f\"   - 格式: JSON\")\nprint(f\"   - 内容: OCEAN 分数（对象数组格式）\")\nprint(f\"\")\nprint(f\"4. ocean_features_distribution.png\")\nprint(f\"   - 6 个子图: 5 个 OCEAN 维度分布 + 按目标变量分组的箱线图\")\n\nprint(\"\\n4️⃣ 权重公式应用信息\")\nprint(\"-\" * 80)\nprint(f\"权重来源: Ridge 回归 (alpha={alpha})\")\nprint(f\"训练样本: 500 个 (250 Fully Paid + 250 Charged Off)\")\nprint(f\"特征集: {len(numeric_features)} 个数值特征 + {len(categorical_features)} 个分类特征\")\nprint(f\"公式形式: score = intercept + Σ(weight × feature)\")\n\nprint(\"\\n5️⃣ 下一步\")\nprint(\"-\" * 80)\nprint(\"✅ OCEAN 特征已生成完毕\")\nprint(\"\\n现在可以进行 XGBoost 建模:\")\nprint(\"\")\nprint(\"1. 04_xgboost_baseline.ipynb (已存在)\")\nprint(\"   - 训练无 OCEAN 的基线模型\")\nprint(\"\")\nprint(\"2. 06_xgboost_with_ocean.ipynb (已存在)\")\nprint(\"   - 训练包含 OCEAN 特征的完整模型\")\nprint(\"   - 修改加载数据为: loan_clean_with_ocean.csv\")\nprint(\"\")\nprint(\"3. 07_results_analysis.ipynb (已存在)\")\nprint(\"   - 对比两个模型的性能\")\n",
    "print(\"   - 评估 OCEAN 特征的价值\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"✅ OCEAN 特征应用完成！\")\nprint(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}