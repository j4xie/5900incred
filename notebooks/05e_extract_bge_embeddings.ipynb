{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05e - Extract BGE-Large Embeddings (500 Test Samples)\n",
    "\n",
    "**Purpose**: Extract BGE-Large embeddings from 500 test samples as input features for Ridge regression model training\n",
    "\n",
    "**Input Files**:\n",
    "- test_samples_500.csv - 500 samples\n",
    "- ocean_ground_truth/ - OCEAN ground truth (select best model)\n",
    "\n",
    "**Output Files**:\n",
    "- bge_embeddings_500.npy - BGE embeddings matrix (500x1024)\n",
    "- ocean_targets_500.csv - Corresponding OCEAN scores (500x5)\n",
    "- 05e_extraction_summary.json - Extraction statistics report\n",
    "\n",
    "**Estimated Time**: Approximately 15-20 minutes (500 API calls, 0.3 second delay each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Test Data and OCEAN Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "  Loading existing file: ../test_samples_500.csv\n",
      "\n",
      "✓ Loaded 500 samples\n",
      "  Columns: 33\n",
      "  Has 'desc': True\n",
      "  Valid descriptions: 500/500\n",
      "\n",
      "First 3 descriptions (preview):\n",
      "  [0] I currently have a loan out with CashCall. The interest rate is 96%! At the time I took out the loan...\n",
      "  [1] Temporary cash flow challenges. Would like this loan to offset mortgage payments-next 90 days. Have ...\n",
      "  [2] Hi! So $5,500 doesn't sound like much to be debt free. Well, when you're 24 years old it seems like ...\n",
      "\n",
      "================================================================================\n",
      "Loading OCEAN ground truth...\n",
      "================================================================================\n",
      "\n",
      "✓ Loaded 500 OCEAN scores\n",
      "  Columns: ['sample_id', 'openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
      "\n",
      "OCEAN score statistics:\n",
      "        sample_id    openness  conscientiousness  extraversion  agreeableness   \n",
      "count  500.000000  500.000000         500.000000    500.000000     500.000000  \\\n",
      "mean   249.500000    0.293200           0.764800      0.255600       0.489800   \n",
      "std    144.481833    0.103029           0.114136      0.080259       0.148189   \n",
      "min      0.000000    0.200000           0.200000      0.100000       0.200000   \n",
      "25%    124.750000    0.200000           0.800000      0.200000       0.400000   \n",
      "50%    249.500000    0.300000           0.800000      0.200000       0.400000   \n",
      "75%    374.250000    0.300000           0.800000      0.300000       0.600000   \n",
      "max    499.000000    0.800000           0.900000      0.700000       0.900000   \n",
      "\n",
      "       neuroticism  \n",
      "count   500.000000  \n",
      "mean      0.383000  \n",
      "std       0.201425  \n",
      "min       0.100000  \n",
      "25%       0.200000  \n",
      "50%       0.300000  \n",
      "75%       0.600000  \n",
      "max       0.900000  \n",
      "\n",
      "✓ Data alignment verified: 500 samples match 500 OCEAN scores\n"
     ]
    }
   ],
   "source": [
    "# Load 500 test samples\n",
    "print(\"Loading test data...\")\n",
    "\n",
    "# Check if test_samples_500.csv exists, if not create it from original data\n",
    "import os\n",
    "test_file = '../test_samples_500.csv'\n",
    "\n",
    "if not os.path.exists(test_file):\n",
    "    print(f\"⚠️  {test_file} not found, creating from original dataset...\")\n",
    "    \n",
    "    # Load original dataset (WITHOUT OCEAN scores - that's the point!)\n",
    "    original_file = '../data/loan_final_desc50plus.csv'\n",
    "    \n",
    "    if os.path.exists(original_file):\n",
    "        print(f\"  Loading: {original_file}\")\n",
    "        df_original = pd.read_csv(original_file, low_memory=False)\n",
    "        print(f\"  Total samples: {len(df_original):,}\")\n",
    "        \n",
    "        # Take first 500 samples (corresponding to sample_id 0-499 in OCEAN ground truth)\n",
    "        df_samples = df_original.head(500).copy()\n",
    "        \n",
    "        # Verify desc column exists\n",
    "        if 'desc' not in df_samples.columns:\n",
    "            raise ValueError(\"desc column not found in dataset!\")\n",
    "        \n",
    "        # Save to test file\n",
    "        df_samples.to_csv(test_file, index=False)\n",
    "        print(f\"  ✓ Created {test_file} with {len(df_samples)} samples\")\n",
    "        print(f\"  ✓ These correspond to sample_id 0-499 in OCEAN ground truth files\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Original dataset not found: {original_file}\\n\"\n",
    "                                f\"  Please ensure loan_final_desc50plus.csv exists in data/ directory\")\n",
    "else:\n",
    "    print(f\"  Loading existing file: {test_file}\")\n",
    "    df_samples = pd.read_csv(test_file)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(df_samples)} samples\")\n",
    "print(f\"  Columns: {len(df_samples.columns)}\")\n",
    "print(f\"  Has 'desc': {'desc' in df_samples.columns}\")\n",
    "\n",
    "if 'desc' in df_samples.columns:\n",
    "    desc_count = df_samples['desc'].notna().sum()\n",
    "    print(f\"  Valid descriptions: {desc_count}/{len(df_samples)}\")\n",
    "\n",
    "print(f\"\\nFirst 3 descriptions (preview):\")\n",
    "for i in range(min(3, len(df_samples))):\n",
    "    desc = str(df_samples.iloc[i]['desc'])[:100]\n",
    "    print(f\"  [{i}] {desc}...\")\n",
    "\n",
    "# Load OCEAN ground truth (use best model)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Loading OCEAN ground truth...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ocean_gt_file = '../ocean_ground_truth/deepseek_v3.1_ocean_500.csv'\n",
    "\n",
    "if not os.path.exists(ocean_gt_file):\n",
    "    # If file doesn't exist, try other models\n",
    "    print(f\"⚠️  {ocean_gt_file} not found, searching for alternatives...\")\n",
    "    ocean_dir = '../ocean_ground_truth'\n",
    "    if os.path.exists(ocean_dir):\n",
    "        files = [f for f in os.listdir(ocean_dir) if f.endswith('_ocean_500.csv')]\n",
    "        if files:\n",
    "            ocean_gt_file = os.path.join(ocean_dir, files[0])\n",
    "            print(f\"  Using: {files[0]}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No OCEAN ground truth files found in {ocean_dir}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Directory not found: {ocean_dir}\")\n",
    "\n",
    "df_ocean = pd.read_csv(ocean_gt_file)\n",
    "print(f\"\\n✓ Loaded {len(df_ocean)} OCEAN scores\")\n",
    "print(f\"  Columns: {df_ocean.columns.tolist()}\")\n",
    "print(f\"\\nOCEAN score statistics:\")\n",
    "print(df_ocean.describe())\n",
    "\n",
    "# Verify alignment\n",
    "if len(df_samples) != len(df_ocean):\n",
    "    print(f\"\\n⚠️  WARNING: Sample count mismatch!\")\n",
    "    print(f\"  Test samples: {len(df_samples)}\")\n",
    "    print(f\"  OCEAN scores: {len(df_ocean)}\")\n",
    "else:\n",
    "    print(f\"\\n✓ Data alignment verified: {len(df_samples)} samples match {len(df_ocean)} OCEAN scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define BGE Embedding Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Trying to load from: ../.env\n",
      "[DEBUG] Current working directory: /Users/jietaoxie/Documents/GitHub/Credibly-INFO-5900/notebooks\n",
      "[DEBUG] File exists: True\n",
      "[DEBUG] File content length: 209 chars\n",
      "[DEBUG] Found key: HF_TOKEN\n",
      "[DEBUG] Token found, length: 37\n",
      "\n",
      "============================================================\n",
      "HF Token loaded: YES ✓\n",
      "Token preview: hf_TdTspnR...voFvX\n",
      "Token length: 37\n",
      "============================================================\n",
      "\n",
      "✓ BGE embedding extraction function defined (with enhanced retry)\n",
      "  - Max retries: 5\n",
      "  - Exponential backoff for 500 errors\n",
      "  - Timeout: 60s\n"
     ]
    }
   ],
   "source": [
    "# Load HF Token with debugging\n",
    "def load_hf_token():\n",
    "    import os\n",
    "    \n",
    "    # Method 1: Try loading from .env file\n",
    "    env_path = '../.env'\n",
    "    print(f\"[DEBUG] Trying to load from: {env_path}\")\n",
    "    print(f\"[DEBUG] Current working directory: {os.getcwd()}\")\n",
    "    print(f\"[DEBUG] File exists: {os.path.exists(env_path)}\")\n",
    "    \n",
    "    try:\n",
    "        with open(env_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            print(f\"[DEBUG] File content length: {len(content)} chars\")\n",
    "            \n",
    "            for line in content.split('\\n'):\n",
    "                if line.strip() and not line.startswith('#'):\n",
    "                    if '=' in line:\n",
    "                        key, value = line.strip().split('=', 1)\n",
    "                        print(f\"[DEBUG] Found key: {key}\")\n",
    "                        if key == 'HF_TOKEN':\n",
    "                            print(f\"[DEBUG] Token found, length: {len(value)}\")\n",
    "                            return value.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[DEBUG] Error reading .env file: {e}\")\n",
    "    \n",
    "    # Method 2: Try environment variable\n",
    "    env_token = os.getenv('HF_TOKEN', '')\n",
    "    if env_token:\n",
    "        print(f\"[DEBUG] Token found in environment variable\")\n",
    "        return env_token\n",
    "    \n",
    "    print(f\"[DEBUG] No token found!\")\n",
    "    return ''\n",
    "\n",
    "hf_token = load_hf_token()\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"HF Token loaded: {'YES ✓' if hf_token else 'NO ✗'}\")\n",
    "if hf_token:\n",
    "    print(f\"Token preview: {hf_token[:10]}...{hf_token[-5:]}\")\n",
    "    print(f\"Token length: {len(hf_token)}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Define BGE embedding extraction function with enhanced retry logic\n",
    "def extract_bge_embedding(text: str, max_retries: int = 5, base_delay: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Call HF Inference API to extract BGE-Large embeddings with exponential backoff\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        max_retries: Maximum retry attempts (increased to 5)\n",
    "        base_delay: Base retry delay in seconds\n",
    "    \n",
    "    Returns:\n",
    "        1024-dimensional embedding vector\n",
    "    \"\"\"\n",
    "    api_url = \"https://api-inference.huggingface.co/models/BAAI/bge-large-en-v1.5\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {hf_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                api_url,\n",
    "                headers=headers,\n",
    "                json={\"inputs\": text},\n",
    "                timeout=60  # Increased timeout\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                features = response.json()\n",
    "                \n",
    "                # Handle different response formats\n",
    "                if isinstance(features, list):\n",
    "                    if len(features) > 0:\n",
    "                        if isinstance(features[0], list):\n",
    "                            # features is [token_embeddings]\n",
    "                            avg_feature = np.mean(features, axis=0)\n",
    "                        else:\n",
    "                            # features is already the embedding\n",
    "                            avg_feature = features\n",
    "                    else:\n",
    "                        raise ValueError(\"Empty features list\")\n",
    "                else:\n",
    "                    # Assume it's already an embedding\n",
    "                    avg_feature = features\n",
    "                \n",
    "                return np.array(avg_feature)\n",
    "            \n",
    "            elif response.status_code == 500:\n",
    "                # Internal server error - exponential backoff\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = base_delay * (2 ** attempt)  # Exponential backoff: 3s, 6s, 12s, 24s\n",
    "                    print(f\"    API 500 error (attempt {attempt+1}/{max_retries}), waiting {delay}s...\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise Exception(f\"API Error 500 after {max_retries} retries\")\n",
    "            \n",
    "            elif response.status_code == 503:\n",
    "                # Model loading\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = base_delay * 2  # Wait longer for model loading\n",
    "                    print(f\"    Model loading... waiting {delay}s (attempt {attempt+1}/{max_retries})\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise Exception(f\"API Error 503 after {max_retries} retries\")\n",
    "            \n",
    "            elif response.status_code == 429:\n",
    "                # Rate limit - wait even longer\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = base_delay * (attempt + 2)  # Linear increase: 6s, 9s, 12s\n",
    "                    print(f\"    Rate limited, waiting {delay}s...\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise Exception(f\"Rate limited after {max_retries} retries\")\n",
    "            \n",
    "            else:\n",
    "                error_msg = response.text[:200] if hasattr(response, 'text') else 'Unknown error'\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"    API Error {response.status_code}, retrying...\")\n",
    "                    time.sleep(base_delay * (attempt + 1))\n",
    "                    continue\n",
    "                else:\n",
    "                    raise Exception(f\"API Error {response.status_code}: {error_msg}\")\n",
    "        \n",
    "        except requests.exceptions.Timeout:\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = base_delay * (attempt + 1)\n",
    "                print(f\"    Request timeout, waiting {delay}s...\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                raise Exception(\"Request timeout after all retries\")\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = base_delay * (attempt + 1)\n",
    "                print(f\"    Network error: {str(e)[:50]}, waiting {delay}s...\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = base_delay * (attempt + 1)\n",
    "                print(f\"    Error: {str(e)[:50]}, waiting {delay}s...\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    raise Exception(\"Failed to extract embedding after all retries\")\n",
    "\n",
    "print(\"✓ BGE embedding extraction function defined (with enhanced retry)\")\n",
    "print(\"  - Max retries: 5\")\n",
    "print(\"  - Exponential backoff for 500 errors\")\n",
    "print(\"  - Timeout: 60s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Batch Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Starting BGE Embeddings extraction (500 samples)\n",
      "================================================================================\n",
      "[ 25/500]   5.0% | ✓25 ✗0 (100.0% success) | 1.37 samples/s | ETA: 5.8min\n",
      "[ 50/500]  10.0% | ✓50 ✗0 (100.0% success) | 1.38 samples/s | ETA: 5.4min\n",
      "[ 75/500]  15.0% | ✓75 ✗0 (100.0% success) | 1.39 samples/s | ETA: 5.1min\n",
      "[100/500]  20.0% | ✓100 ✗0 (100.0% success) | 1.38 samples/s | ETA: 4.8min\n",
      "[125/500]  25.0% | ✓125 ✗0 (100.0% success) | 1.38 samples/s | ETA: 4.5min\n",
      "[150/500]  30.0% | ✓150 ✗0 (100.0% success) | 1.38 samples/s | ETA: 4.2min\n",
      "[175/500]  35.0% | ✓175 ✗0 (100.0% success) | 1.39 samples/s | ETA: 3.9min\n",
      "[200/500]  40.0% | ✓200 ✗0 (100.0% success) | 1.38 samples/s | ETA: 3.6min\n",
      "[225/500]  45.0% | ✓225 ✗0 (100.0% success) | 1.39 samples/s | ETA: 3.3min\n",
      "[250/500]  50.0% | ✓250 ✗0 (100.0% success) | 1.39 samples/s | ETA: 3.0min\n",
      "[275/500]  55.0% | ✓275 ✗0 (100.0% success) | 1.39 samples/s | ETA: 2.7min\n",
      "[300/500]  60.0% | ✓300 ✗0 (100.0% success) | 1.39 samples/s | ETA: 2.4min\n",
      "[325/500]  65.0% | ✓325 ✗0 (100.0% success) | 1.39 samples/s | ETA: 2.1min\n",
      "[350/500]  70.0% | ✓350 ✗0 (100.0% success) | 1.39 samples/s | ETA: 1.8min\n",
      "[375/500]  75.0% | ✓375 ✗0 (100.0% success) | 1.39 samples/s | ETA: 1.5min\n",
      "[400/500]  80.0% | ✓400 ✗0 (100.0% success) | 1.39 samples/s | ETA: 1.2min\n",
      "[425/500]  85.0% | ✓425 ✗0 (100.0% success) | 1.39 samples/s | ETA: 0.9min\n",
      "[450/500]  90.0% | ✓450 ✗0 (100.0% success) | 1.39 samples/s | ETA: 0.6min\n",
      "[475/500]  95.0% | ✓475 ✗0 (100.0% success) | 1.39 samples/s | ETA: 0.3min\n",
      "[500/500] 100.0% | ✓500 ✗0 (100.0% success) | 1.39 samples/s | ETA: 0.0min\n",
      "\n",
      "================================================================================\n",
      "Embedding extraction complete\n",
      "================================================================================\n",
      "\n",
      "Time elapsed: 6.0 minutes (361.1 seconds)\n",
      "Success: 500/500 (100.0%)\n",
      "Failed: 0/500 (0.0%)\n",
      "\n",
      "Embedding matrix shape: (500, 1024)\n",
      "Data type: float64\n",
      "Memory usage: 3.9 MB\n",
      "Average time per sample: 0.72s\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Starting BGE Embeddings extraction (500 samples)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "embeddings = []\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "error_indices = []\n",
    "\n",
    "start_time = time.time()\n",
    "total_samples = len(df_samples)\n",
    "\n",
    "# Increased delay to avoid API rate limits and 500 errors\n",
    "DELAY_BETWEEN_REQUESTS = 0.5  # Increased from 0.3 to 0.5 seconds\n",
    "\n",
    "for idx, (_, row) in enumerate(df_samples.iterrows(), 1):\n",
    "    text = row.get('desc', '')\n",
    "    \n",
    "    if len(text.strip()) < 10:\n",
    "        # Skip too short descriptions\n",
    "        embeddings.append(np.zeros(1024))\n",
    "        error_count += 1\n",
    "        error_indices.append(idx - 1)\n",
    "        print(f\"  [{idx}] Skipping: text too short\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Extract embedding\n",
    "        emb = extract_bge_embedding(text)\n",
    "        \n",
    "        if emb is not None and len(emb) == 1024:\n",
    "            embeddings.append(emb)\n",
    "            success_count += 1\n",
    "        else:\n",
    "            embeddings.append(np.zeros(1024))\n",
    "            error_count += 1\n",
    "            error_indices.append(idx - 1)\n",
    "            print(f\"  [{idx}] Error: Invalid embedding dimension\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        embeddings.append(np.zeros(1024))\n",
    "        error_count += 1\n",
    "        error_indices.append(idx - 1)\n",
    "        print(f\"  [{idx}] Error: {str(e)[:100]}\")\n",
    "    \n",
    "    # Show progress\n",
    "    if idx % 25 == 0 or idx == total_samples:  # Show progress more frequently\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = idx / elapsed if elapsed > 0 else 0\n",
    "        eta = (total_samples - idx) / rate if rate > 0 else 0\n",
    "        \n",
    "        progress = idx / total_samples * 100\n",
    "        success_rate = success_count / idx * 100 if idx > 0 else 0\n",
    "        print(f\"[{idx:3d}/{total_samples}] {progress:5.1f}% | ✓{success_count} ✗{error_count} ({success_rate:.1f}% success) | {rate:.2f} samples/s | ETA: {eta/60:.1f}min\")\n",
    "    \n",
    "    # Add delay to avoid rate limiting and reduce 500 errors\n",
    "    time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "\n",
    "elapsed_total = time.time() - start_time\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"Embedding extraction complete\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"\\nTime elapsed: {elapsed_total/60:.1f} minutes ({elapsed_total:.1f} seconds)\")\n",
    "print(f\"Success: {success_count}/{total_samples} ({success_count/total_samples*100:.1f}%)\")\n",
    "print(f\"Failed: {error_count}/{total_samples} ({error_count/total_samples*100:.1f}%)\")\n",
    "\n",
    "if error_count > 0:\n",
    "    print(f\"\\nFailed indices (first 20): {error_indices[:20]}\")\n",
    "\n",
    "# Convert to numpy array\n",
    "X = np.array(embeddings)\n",
    "print(f\"\\nEmbedding matrix shape: {X.shape}\")\n",
    "print(f\"Data type: {X.dtype}\")\n",
    "print(f\"Memory usage: {X.nbytes / 1024 / 1024:.1f} MB\")\n",
    "print(f\"Average time per sample: {elapsed_total/total_samples:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save Embeddings and Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results...\n",
      "\n",
      "Embeddings saved: ../bge_embeddings_500.npy\n",
      "  Shape: (500, 1024)\n",
      "  Size: 3.9 MB\n",
      "\n",
      "OCEAN targets saved: ../ocean_targets_500.csv\n",
      "  Shape: (500, 6)\n",
      "  Columns: ['sample_id', 'openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
      "\n",
      "Data consistency check passed\n",
      "   Embeddings count: 500\n",
      "   OCEAN targets count: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving results...\\n\")\n",
    "\n",
    "# Save embeddings\n",
    "embedding_file = '../bge_embeddings_500.npy'\n",
    "np.save(embedding_file, X)\n",
    "print(f\"Embeddings saved: {embedding_file}\")\n",
    "print(f\"  Shape: {X.shape}\")\n",
    "print(f\"  Size: {os.path.getsize(embedding_file) / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Save OCEAN targets\n",
    "ocean_target_file = '../ocean_targets_500.csv'\n",
    "df_ocean.to_csv(ocean_target_file, index=False)\n",
    "print(f\"\\nOCEAN targets saved: {ocean_target_file}\")\n",
    "print(f\"  Shape: {df_ocean.shape}\")\n",
    "print(f\"  Columns: {df_ocean.columns.tolist()}\")\n",
    "\n",
    "# Verify data consistency\n",
    "if len(X) == len(df_ocean):\n",
    "    print(f\"\\nData consistency check passed\")\n",
    "    print(f\"   Embeddings count: {len(X)}\")\n",
    "    print(f\"   OCEAN targets count: {len(df_ocean)}\")\n",
    "else:\n",
    "    print(f\"\\nWARNING: Data inconsistency\")\n",
    "    print(f\"   Embeddings: {len(X)}\")\n",
    "    print(f\"   OCEAN targets: {len(df_ocean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate Statistics Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics report saved: ../05e_extraction_summary.json\n",
      "\n",
      "================================================================================\n",
      "Summary\n",
      "================================================================================\n",
      "{\n",
      "  \"phase\": \"05e - Extract BGE Embeddings\",\n",
      "  \"timestamp\": \"2025-10-29T18:11:39.357684\",\n",
      "  \"total_samples\": 500,\n",
      "  \"success_count\": 500,\n",
      "  \"error_count\": 0,\n",
      "  \"success_rate\": \"100.00%\",\n",
      "  \"embedding_model\": \"BAAI/bge-large-en-v1.5\",\n",
      "  \"embedding_dimension\": 1024,\n",
      "  \"embedding_file\": \"../bge_embeddings_500.npy\",\n",
      "  \"ocean_target_file\": \"../ocean_targets_500.csv\",\n",
      "  \"ocean_features\": [\n",
      "    \"sample_id\",\n",
      "    \"openness\",\n",
      "    \"conscientiousness\",\n",
      "    \"extraversion\",\n",
      "    \"agreeableness\",\n",
      "    \"neuroticism\"\n",
      "  ],\n",
      "  \"ocean_statistics\": {\n",
      "    \"sample_id\": {\n",
      "      \"mean\": 249.5,\n",
      "      \"std\": 144.4818327679989,\n",
      "      \"min\": 0.0,\n",
      "      \"max\": 499.0\n",
      "    },\n",
      "    \"openness\": {\n",
      "      \"mean\": 0.2932,\n",
      "      \"std\": 0.10302907346938493,\n",
      "      \"min\": 0.2,\n",
      "      \"max\": 0.8\n",
      "    },\n",
      "    \"conscientiousness\": {\n",
      "      \"mean\": 0.7647999999999999,\n",
      "      \"std\": 0.11413594538118181,\n",
      "      \"min\": 0.2,\n",
      "      \"max\": 0.9\n",
      "    },\n",
      "    \"extraversion\": {\n",
      "      \"mean\": 0.25560000000000005,\n",
      "      \"std\": 0.08025909945976334,\n",
      "      \"min\": 0.1,\n",
      "      \"max\": 0.7\n",
      "    },\n",
      "    \"agreeableness\": {\n",
      "      \"mean\": 0.48979999999999996,\n",
      "      \"std\": 0.14818866272262204,\n",
      "      \"min\": 0.2,\n",
      "      \"max\": 0.9\n",
      "    },\n",
      "    \"neuroticism\": {\n",
      "      \"mean\": 0.38300000000000006,\n",
      "      \"std\": 0.20142528214843625,\n",
      "      \"min\": 0.1,\n",
      "      \"max\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"processing_time_seconds\": 361.14296102523804,\n",
      "  \"samples_per_second\": 1.3844932726379737\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate summary report\n",
    "summary = {\n",
    "    'phase': '05e - Extract BGE Embeddings',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'total_samples': int(total_samples),\n",
    "    'success_count': int(success_count),\n",
    "    'error_count': int(error_count),\n",
    "    'success_rate': f\"{success_count/total_samples*100:.2f}%\",\n",
    "    'embedding_model': 'BAAI/bge-large-en-v1.5',\n",
    "    'embedding_dimension': 1024,\n",
    "    'embedding_file': embedding_file,\n",
    "    'ocean_target_file': ocean_target_file,\n",
    "    'ocean_features': df_ocean.columns.tolist(),\n",
    "    'ocean_statistics': {},\n",
    "    'processing_time_seconds': elapsed_total,\n",
    "    'samples_per_second': success_count / elapsed_total if elapsed_total > 0 else 0\n",
    "}\n",
    "\n",
    "# Add OCEAN statistics\n",
    "for col in df_ocean.columns:\n",
    "    summary['ocean_statistics'][col] = {\n",
    "        'mean': float(df_ocean[col].mean()),\n",
    "        'std': float(df_ocean[col].std()),\n",
    "        'min': float(df_ocean[col].min()),\n",
    "        'max': float(df_ocean[col].max())\n",
    "    }\n",
    "\n",
    "# Save summary\n",
    "summary_file = '../05e_extraction_summary.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"Statistics report saved: {summary_file}\")\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"Summary\")\n",
    "print(\"=\"*80)\n",
    "print(json.dumps(summary, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Step 05e Complete\n",
    "\n",
    "**Output Files**:\n",
    "- `bge_embeddings_500.npy` - 500x1024 embeddings matrix\n",
    "- `ocean_targets_500.csv` - 500x5 OCEAN scores\n",
    "- `05e_extraction_summary.json` - Extraction report\n",
    "\n",
    "**Next Step**:\n",
    "Run `05f_train_ridge_models.ipynb` to train Ridge regression models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
