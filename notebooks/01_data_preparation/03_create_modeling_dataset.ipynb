{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - 创建干净的建模数据集\n",
    "\n",
    "**目标**: 创建一个干净的、无数据泄漏的建模数据集\n",
    "\n",
    "## 处理步骤:\n",
    "1. 加载有 desc 的数据\n",
    "2. 删除所有 POST-LOAN 特征（防止数据泄漏）\n",
    "3. 删除覆盖率 < 80% 的特征（质量控制）\n",
    "4. 删除 METADATA 特征（除了 desc - 保留用于 OCEAN 提取）\n",
    "5. 创建二分类目标变量（Fully Paid vs Charged Off）\n",
    "6. 保存干净数据集\n",
    "7. 生成质量报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置显示选项\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"库加载成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 加载原始数据\nprint(\"加载原始数据 loan.csv...\")\ndf = pd.read_csv('../../data/loan.csv', low_memory=False)\nprint(f\"原始数据: {df.shape[0]:,} 行 × {df.shape[1]} 列\")\n\n# 筛选有 desc 的数据\nprint(\"\\n筛选有 desc 的数据...\")\ndf_with_desc = df[\n    df['desc'].notna() & \n    (df['desc'].astype(str).str.strip().str.len() > 1)\n].copy()\n\nprint(f\"有 desc 的数据: {df_with_desc.shape[0]:,} 行 × {df_with_desc.shape[1]} 列\")\nprint(f\"覆盖率: {len(df_with_desc)/len(df)*100:.2f}%\")\n\n# 释放原始数据内存\ndel df\n\nprint(\"\\n数据加载完成！\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 定义特征分类\n",
    "\n",
    "基于 02_feature_selection_and_leakage_check.ipynb 的分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST-LOAN 特征（必须删除 - 会导致数据泄漏）\n",
    "post_loan_features = [\n",
    "    # Payment related (generated after loan issued)\n",
    "    'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv',\n",
    "    'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee',\n",
    "    'recoveries', 'collection_recovery_fee',\n",
    "    'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d',\n",
    "    'last_credit_pull_d', 'last_fico_range_high', 'last_fico_range_low',\n",
    "    \n",
    "    # Hardship and debt settlement (post-loan events)\n",
    "    'hardship_flag', 'hardship_type', 'hardship_reason',\n",
    "    'hardship_status', 'hardship_start_date', 'hardship_end_date',\n",
    "    'hardship_loan_status', 'hardship_dpd', 'hardship_length',\n",
    "    'hardship_amount', 'hardship_payoff_balance_amount',\n",
    "    'deferral_term', 'payment_plan_start_date',\n",
    "    'debt_settlement_flag', 'debt_settlement_flag_date',\n",
    "    'settlement_status', 'settlement_date', 'settlement_amount',\n",
    "    'settlement_percentage', 'settlement_term',\n",
    "    \n",
    "    # Other post-loan info\n",
    "    'pymnt_plan', 'initial_list_status',  # policy file date is post-approval\n",
    "    'policy_code',  # internal policy code\n",
    "]\n",
    "\n",
    "# METADATA 特征（无预测价值 - 删除，但保留 desc）\n",
    "metadata_features = [\n",
    "    'id', 'member_id', 'url',  # ID fields\n",
    "    'funded_amnt_inv',  # duplicate of funded_amnt for investors\n",
    "    # 注意: 'desc' 暂时保留用于 OCEAN 提取\n",
    "]\n",
    "\n",
    "# OUTCOME 特征（目标变量相关 - 特殊处理）\n",
    "outcome_features = [\n",
    "    'loan_status',  # 将用于创建目标变量\n",
    "]\n",
    "\n",
    "print(f\"POST-LOAN 特征数量: {len(post_loan_features)}\")\n",
    "print(f\"METADATA 特征数量: {len(metadata_features)}\")\n",
    "print(f\"OUTCOME 特征数量: {len(outcome_features)}\")\n",
    "print(f\"\\n保留 'desc' 字段用于后续 OCEAN 特征提取\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 分析特征覆盖率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 计算所有特征的覆盖率\nprint(\"计算特征覆盖率...\\n\")\n\ncoverage_stats = []\n\nfor col in df_with_desc.columns:\n    non_null = df_with_desc[col].notna().sum()\n    coverage = (non_null / len(df_with_desc)) * 100\n    \n    # 判断特征类型\n    if col in post_loan_features:\n        feature_type = 'POST-LOAN'\n        keep_status = '❌ DELETE (Leakage)'\n    elif col in metadata_features:\n        feature_type = 'METADATA'\n        keep_status = '❌ DELETE (No value)'\n    elif col in outcome_features:\n        feature_type = 'OUTCOME'\n        keep_status = '⚠️ SPECIAL (Target)'\n    elif col == 'desc':\n        feature_type = 'TEXT'\n        keep_status = '✅ KEEP (For OCEAN)'\n    else:\n        feature_type = 'PRE-LOAN'\n        if coverage >= 80:\n            keep_status = '✅ KEEP (Good quality)'\n        else:\n            keep_status = f'❌ DELETE (Coverage {coverage:.1f}% < 80%)'\n    \n    coverage_stats.append({\n        '特征名': col,\n        '类型': feature_type,\n        '覆盖率%': f\"{coverage:.2f}\",\n        '非空数量': f\"{non_null:,}\",\n        '处理决策': keep_status,\n        'dtype': str(df_with_desc[col].dtype)\n    })\n\ncoverage_df = pd.DataFrame(coverage_stats)\ncoverage_df['coverage_numeric'] = coverage_df['覆盖率%'].astype(float)\ncoverage_df = coverage_df.sort_values('coverage_numeric', ascending=False)\n\nprint(\"特征覆盖率分析完成！\")\nprint(f\"\\n总特征数: {len(coverage_df)}\")\n\n# 统计各类特征\nprint(\"\\n=\" * 80)\nprint(\"特征类型统计\")\nprint(\"=\" * 80)\nprint(coverage_df['类型'].value_counts())\n\nprint(\"\\n=\" * 80)\nprint(\"处理决策统计\")\nprint(\"=\" * 80)\nkeep_count = coverage_df['处理决策'].str.contains('KEEP').sum()\ndelete_count = coverage_df['处理决策'].str.contains('DELETE').sum()\nspecial_count = coverage_df['处理决策'].str.contains('SPECIAL').sum()\n\nprint(f\"保留特征: {keep_count}\")\nprint(f\"删除特征: {delete_count}\")\nprint(f\"特殊处理: {special_count}\")\n\n# 保存覆盖率报告\ncoverage_df.to_csv('../../feature_coverage_report.csv', index=False)\nprint(\"\\n覆盖率报告已保存: feature_coverage_report.csv\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 查看需要删除的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看需要删除的特征\n",
    "delete_features = coverage_df[coverage_df['处理决策'].str.contains('DELETE')]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"需要删除的特征 (共 {len(delete_features)} 个)\")\n",
    "print(\"=\" * 80)\n",
    "print(delete_features[['特征名', '类型', '覆盖率%', '处理决策']].to_string(index=False))\n",
    "\n",
    "# 按删除原因分组\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"删除原因分析\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "leakage_delete = delete_features[delete_features['类型'] == 'POST-LOAN']\n",
    "metadata_delete = delete_features[delete_features['类型'] == 'METADATA']\n",
    "quality_delete = delete_features[\n",
    "    (delete_features['类型'] == 'PRE-LOAN') & \n",
    "    (delete_features['覆盖率%'].astype(float) < 80)\n",
    "]\n",
    "\n",
    "print(f\"因数据泄漏删除 (POST-LOAN): {len(leakage_delete)} 个\")\n",
    "print(f\"因无预测价值删除 (METADATA): {len(metadata_delete)} 个\")\n",
    "print(f\"因质量不达标删除 (覆盖率<80%): {len(quality_delete)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 删除特征并创建干净数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 收集所有需要删除的特征名\n",
    "features_to_delete = delete_features['特征名'].tolist()\n",
    "\n",
    "print(f\"开始删除 {len(features_to_delete)} 个特征...\\n\")\n",
    "print(f\"删除前数据形状: {df_with_desc.shape}\")\n",
    "\n",
    "# 删除特征\n",
    "df_clean = df_with_desc.drop(columns=features_to_delete, errors='ignore')\n",
    "\n",
    "print(f\"删除后数据形状: {df_clean.shape}\")\n",
    "print(f\"保留特征数: {df_clean.shape[1]}\")\n",
    "print(f\"\\n保留的特征包括:\")\n",
    "print(f\"- desc (用于 OCEAN 提取)\")\n",
    "print(f\"- loan_status (用于创建目标变量)\")\n",
    "print(f\"- {df_clean.shape[1] - 2} 个高质量 PRE-LOAN 特征\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 创建目标变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 loan_status 的分布\n",
    "print(\"=\" * 80)\n",
    "print(\"loan_status 分布\")\n",
    "print(\"=\" * 80)\n",
    "print(df_clean['loan_status'].value_counts())\n",
    "print(f\"\\n总计: {len(df_clean):,} 条记录\")\n",
    "\n",
    "# 创建二分类目标变量\n",
    "# 1 = Charged Off (违约), 0 = Fully Paid (正常还款)\n",
    "print(\"\\n创建目标变量...\")\n",
    "\n",
    "# 定义正常还款的状态\n",
    "fully_paid_statuses = ['Fully Paid', 'Current', 'In Grace Period']\n",
    "# 定义违约的状态\n",
    "charged_off_statuses = ['Charged Off', 'Default', 'Late (31-120 days)', 'Late (16-30 days)']\n",
    "\n",
    "# 只保留明确的 Fully Paid 和 Charged Off 状态\n",
    "df_clean_binary = df_clean[\n",
    "    (df_clean['loan_status'] == 'Fully Paid') | \n",
    "    (df_clean['loan_status'] == 'Charged Off')\n",
    "].copy()\n",
    "\n",
    "print(f\"\\n筛选后数据量: {len(df_clean_binary):,} 条\")\n",
    "print(\"\\nloan_status 分布 (筛选后):\")\n",
    "print(df_clean_binary['loan_status'].value_counts())\n",
    "\n",
    "# 创建目标变量\n",
    "df_clean_binary['target'] = (df_clean_binary['loan_status'] == 'Charged Off').astype(int)\n",
    "\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"目标变量分布\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"target = 0 (Fully Paid): {(df_clean_binary['target']==0).sum():,}\")\n",
    "print(f\"target = 1 (Charged Off): {(df_clean_binary['target']==1).sum():,}\")\n",
    "print(f\"\\n违约率: {df_clean_binary['target'].mean()*100:.2f}%\")\n",
    "\n",
    "# 现在可以删除 loan_status\n",
    "df_clean_binary = df_clean_binary.drop(columns=['loan_status'])\n",
    "\n",
    "print(f\"\\n最终数据形状: {df_clean_binary.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: 数据类型分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析保留特征的数据类型\n",
    "print(\"=\" * 80)\n",
    "print(\"保留特征的数据类型分布\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "numeric_features = df_clean_binary.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df_clean_binary.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# 移除 target 和 desc\n",
    "if 'target' in numeric_features:\n",
    "    numeric_features.remove('target')\n",
    "if 'desc' in categorical_features:\n",
    "    categorical_features.remove('desc')\n",
    "\n",
    "print(f\"\\n数值型特征: {len(numeric_features)} 个\")\n",
    "print(f\"分类特征: {len(categorical_features)} 个\")\n",
    "print(f\"文本特征: 1 个 (desc)\")\n",
    "print(f\"目标变量: 1 个 (target)\")\n",
    "\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"数值型特征列表\")\n",
    "print(\"=\" * 80)\n",
    "for i, feat in enumerate(numeric_features, 1):\n",
    "    print(f\"{i:3d}. {feat}\")\n",
    "\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"分类特征列表\")\n",
    "print(\"=\" * 80)\n",
    "for i, feat in enumerate(categorical_features, 1):\n",
    "    print(f\"{i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: 保存干净数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 保存干净的建模数据集\noutput_file = '../../data/loan_clean_for_modeling.csv'\n\nprint(f\"保存干净数据集到: {output_file}\")\ndf_clean_binary.to_csv(output_file, index=False)\n\nimport os\nfile_size = os.path.getsize(output_file) / (1024 * 1024)  # MB\nprint(f\"\\n文件大小: {file_size:.2f} MB\")\nprint(f\"数据形状: {df_clean_binary.shape[0]:,} 行 × {df_clean_binary.shape[1]} 列\")\n\n# 保存特征列表\nfeature_lists = {\n    'numeric_features': numeric_features,\n    'categorical_features': categorical_features,\n    'text_feature': ['desc'],\n    'target': ['target']\n}\n\nimport json\nwith open('../../feature_lists_clean.json', 'w') as f:\n    json.dump(feature_lists, f, indent=2)\n\nprint(\"\\n特征列表已保存: feature_lists_clean.json\")\nprint(\"\\n✅ 数据清洗完成！\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: 数据质量总结报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"数据清洗总结报告\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1️⃣ 数据规模变化\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"原始数据集: 2,260,668 行 × 145 列\")\n",
    "print(f\"有 desc 的数据: {len(df_with_desc):,} 行 × {len(df_with_desc.columns)} 列\")\n",
    "print(f\"最终建模数据: {df_clean_binary.shape[0]:,} 行 × {df_clean_binary.shape[1]} 列\")\n",
    "print(f\"数据保留率: {len(df_clean_binary)/2260668*100:.2f}%\")\n",
    "\n",
    "print(\"\\n2️⃣ 特征删除统计\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"原始特征数: 145\")\n",
    "print(f\"删除的特征数: {len(features_to_delete)}\")\n",
    "print(f\"  - POST-LOAN (防止泄漏): {len(leakage_delete)}\")\n",
    "print(f\"  - METADATA (无价值): {len(metadata_delete)}\")\n",
    "print(f\"  - 低质量 (覆盖率<80%): {len(quality_delete)}\")\n",
    "print(f\"保留的特征数: {df_clean_binary.shape[1]}\")\n",
    "print(f\"  - 数值型: {len(numeric_features)}\")\n",
    "print(f\"  - 分类型: {len(categorical_features)}\")\n",
    "print(f\"  - 文本型: 1 (desc)\")\n",
    "print(f\"  - 目标变量: 1 (target)\")\n",
    "\n",
    "print(\"\\n3️⃣ 目标变量分布\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Fully Paid (target=0): {(df_clean_binary['target']==0).sum():,} ({(df_clean_binary['target']==0).sum()/len(df_clean_binary)*100:.2f}%)\")\n",
    "print(f\"Charged Off (target=1): {(df_clean_binary['target']==1).sum():,} ({(df_clean_binary['target']==1).sum()/len(df_clean_binary)*100:.2f}%)\")\n",
    "print(f\"违约率: {df_clean_binary['target'].mean()*100:.2f}%\")\n",
    "\n",
    "print(\"\\n4️⃣ 数据质量检查\")\n",
    "print(\"-\" * 80)\n",
    "# 检查每个特征的缺失率\n",
    "missing_report = []\n",
    "for col in df_clean_binary.columns:\n",
    "    if col not in ['target', 'desc']:\n",
    "        missing_pct = (df_clean_binary[col].isna().sum() / len(df_clean_binary)) * 100\n",
    "        if missing_pct > 0:\n",
    "            missing_report.append({\n",
    "                '特征': col,\n",
    "                '缺失率%': f\"{missing_pct:.2f}\"\n",
    "            })\n",
    "\n",
    "if missing_report:\n",
    "    missing_df = pd.DataFrame(missing_report)\n",
    "    missing_df['missing_numeric'] = missing_df['缺失率%'].astype(float)\n",
    "    missing_df = missing_df.sort_values('missing_numeric', ascending=False)\n",
    "    missing_df = missing_df.drop('missing_numeric', axis=1)\n",
    "    \n",
    "    print(f\"有缺失值的特征: {len(missing_report)} 个\")\n",
    "    print(\"\\n缺失率最高的前10个特征:\")\n",
    "    print(missing_df.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"所有特征都没有缺失值 ✅\")\n",
    "\n",
    "print(\"\\n5️⃣ 下一步行动\")\n",
    "print(\"-\" * 80)\n",
    "print(\"✅ 数据清洗完成，可以进行以下步骤:\")\n",
    "print(\"\")\n",
    "print(\"1. 04_xgboost_baseline.ipynb\")\n",
    "print(\"   - 使用干净数据训练 XGBoost 基线模型\")\n",
    "print(\"   - 不包含 OCEAN 特征\")\n",
    "print(\"   - 建立性能基准\")\n",
    "print(\"\")\n",
    "print(\"2. 05_ocean_feature_extraction.ipynb\")\n",
    "print(\"   - 从 desc 字段提取 OCEAN 人格特征\")\n",
    "print(\"   - 注意避免 train/test leakage\")\n",
    "print(\"\")\n",
    "print(\"3. 06_xgboost_with_ocean.ipynb\")\n",
    "print(\"   - 训练包含 OCEAN 特征的完整模型\")\n",
    "print(\"   - 对比基线模型性能\")\n",
    "print(\"\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: 可视化数据概览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 创建可视化\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# 1. 目标变量分布\nax1 = axes[0, 0]\ntarget_counts = df_clean_binary['target'].value_counts()\ncolors = ['#2ecc71', '#e74c3c']\nax1.bar(['Fully Paid\\n(target=0)', 'Charged Off\\n(target=1)'], \n        target_counts.values, color=colors, alpha=0.7, edgecolor='black')\nax1.set_ylabel('Count', fontsize=12, fontweight='bold')\nax1.set_title('Target Variable Distribution', fontsize=14, fontweight='bold')\nax1.grid(axis='y', alpha=0.3)\nfor i, v in enumerate(target_counts.values):\n    ax1.text(i, v, f'{v:,}\\n({v/len(df_clean_binary)*100:.1f}%)', \n             ha='center', va='bottom', fontweight='bold')\n\n# 2. 特征类型分布\nax2 = axes[0, 1]\nfeature_type_counts = [len(numeric_features), len(categorical_features), 1]\nfeature_types = ['Numeric', 'Categorical', 'Text']\ncolors2 = ['#3498db', '#9b59b6', '#f39c12']\nwedges, texts, autotexts = ax2.pie(feature_type_counts, labels=feature_types, \n                                     autopct='%1.1f%%', colors=colors2, \n                                     startangle=90, textprops={'fontweight': 'bold'})\nax2.set_title('Feature Type Distribution', fontsize=14, fontweight='bold')\n\n# 3. 特征删除原因\nax3 = axes[1, 0]\ndelete_reasons = ['POST-LOAN\\n(Leakage)', 'METADATA\\n(No value)', \n                  'Low Quality\\n(Coverage<80%)', 'Kept']\ndelete_counts = [len(leakage_delete), len(metadata_delete), \n                 len(quality_delete), df_clean_binary.shape[1]]\ncolors3 = ['#e74c3c', '#95a5a6', '#e67e22', '#2ecc71']\nbars = ax3.barh(delete_reasons, delete_counts, color=colors3, alpha=0.7, edgecolor='black')\nax3.set_xlabel('Count', fontsize=12, fontweight='bold')\nax3.set_title('Feature Retention Analysis', fontsize=14, fontweight='bold')\nax3.grid(axis='x', alpha=0.3)\nfor i, (bar, count) in enumerate(zip(bars, delete_counts)):\n    ax3.text(count, bar.get_y() + bar.get_height()/2, \n             f' {count}', va='center', fontweight='bold')\n\n# 4. 数据规模变化\nax4 = axes[1, 1]\ndata_stages = ['Original\\nDataset', 'With\\ndesc', 'Clean\\nBinary']\ndata_counts = [2260668, len(df_with_desc), len(df_clean_binary)]\ncolors4 = ['#34495e', '#3498db', '#2ecc71']\nbars = ax4.bar(data_stages, data_counts, color=colors4, alpha=0.7, edgecolor='black')\nax4.set_ylabel('Number of Rows', fontsize=12, fontweight='bold')\nax4.set_title('Dataset Size Changes', fontsize=14, fontweight='bold')\nax4.grid(axis='y', alpha=0.3)\nfor bar, count in zip(bars, data_counts):\n    height = bar.get_height()\n    ax4.text(bar.get_x() + bar.get_width()/2., height,\n             f'{count:,}',\n             ha='center', va='bottom', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('../../data_cleaning_summary.png', dpi=300, bbox_inches='tight')\nprint(\"\\n可视化已保存: data_cleaning_summary.png\")\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}