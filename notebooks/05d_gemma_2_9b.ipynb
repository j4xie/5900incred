{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05d - OCEAN Generation: Gemma-2-9B\n",
        "\n",
        "**Model**: google/gemma-2-9b-it  \n",
        "**Provider**: nebius  \n",
        "**Samples**: 500  \n",
        "**Output**: ../ocean_ground_truth/gemma_2_9b_ocean_500.csv  \n",
        "**Estimated Time**: 1.5-2 hours\n",
        "\n",
        "This notebook generates OCEAN personality scores for 500 loan application samples using the Gemma-2-9B model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Libraries imported\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print('✓ Libraries imported')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ HF token loaded\n"
          ]
        }
      ],
      "source": [
        "def load_env():\n",
        "    env_dict = {}\n",
        "    try:\n",
        "        with open('../.env', 'r') as f:\n",
        "            for line in f:\n",
        "                if line.strip() and not line.startswith('#'):\n",
        "                    key, value = line.strip().split('=', 1)\n",
        "                    env_dict[key] = value\n",
        "    except:\n",
        "        print('Warning: Unable to read .env file')\n",
        "    return env_dict\n",
        "\n",
        "env_vars = load_env()\n",
        "hf_token = env_vars.get('HF_TOKEN', '')\n",
        "print('✓ HF token loaded' if hf_token else '❌ HF_TOKEN not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Loaded 500 samples\n"
          ]
        }
      ],
      "source": [
        "df_samples = pd.read_csv('../test_samples_500.csv')\n",
        "print(f'✓ Loaded {len(df_samples)} samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Define Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Gemma-2-9B\n",
            "Provider: nebius\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = 'google/gemma-2-9b-it'\n",
        "PROVIDER = 'nebius'\n",
        "DISPLAY_NAME = 'Gemma-2-9B'\n",
        "OUTPUT_FILE = '../ocean_ground_truth/gemma_2_9b_ocean_500.csv'\n",
        "CHECKPOINT_FILE = '../ocean_ground_truth/.checkpoint_gemma_2_9b.json'\n",
        "\n",
        "print(f'Model: {DISPLAY_NAME}')\n",
        "print(f'Provider: {PROVIDER}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ OCEAN prompt template defined\n"
          ]
        }
      ],
      "source": [
        "ocean_prompt_template = '''You are a psychologist specialized in the Big Five (OCEAN) personality assessment for credit behavior research.\n",
        "\n",
        "Analyze the loan applicant's text and provide personality scores for each of the Big Five traits. Base your assessment on ANY available linguistic cues, writing style, word choice, and expressed intentions in the text.\n",
        "\n",
        "Trait definitions and scoring guidelines:\n",
        "- Openness (0.0-1.0): curiosity, imagination, preference for novelty and new ideas\n",
        "  * High (0.7-1.0): words like \"learn,\" \"try new,\" \"explore,\" \"creative,\" \"open-minded,\" \"different,\" \"unique\"\n",
        "  * Medium (0.4-0.6): neutral or mixed signals\n",
        "  * Low (0.0-0.3): focus on routine, traditional, familiar, conservative language\n",
        "  \n",
        "- Conscientiousness (0.0-1.0): organization, discipline, reliability, planning, self-control\n",
        "  * High (0.7-1.0): \"planning,\" \"saving,\" \"on time,\" \"responsibility,\" \"organized,\" \"careful\"\n",
        "  * Medium (0.4-0.6): neutral or mixed signals\n",
        "  * Low (0.0-0.3): impulsive, unplanned, casual language\n",
        "  \n",
        "- Extraversion (0.0-1.0): sociability, assertiveness, energy, enthusiasm\n",
        "  * High (0.7-1.0): \"team,\" \"connect,\" \"talk,\" \"outgoing,\" \"social,\" \"people,\" \"friends\"\n",
        "  * Medium (0.4-0.6): neutral or mixed signals\n",
        "  * Low (0.0-0.3): solitary, quiet, reserved language\n",
        "  \n",
        "- Agreeableness (0.0-1.0): cooperation, empathy, kindness, trust\n",
        "  * High (0.7-1.0): \"help,\" \"care,\" \"family,\" \"support,\" \"honest,\" \"kind,\" \"together\"\n",
        "  * Medium (0.4-0.6): neutral or mixed signals\n",
        "  * Low (0.0-0.3): competitive, critical, confrontational language\n",
        "  \n",
        "- Neuroticism (0.0-1.0): emotional instability, anxiety, sensitivity to stress\n",
        "  * High (0.7-1.0): \"worry,\" \"stress,\" \"pressure,\" \"concern,\" \"can't sleep,\" \"anxious,\" \"difficult\"\n",
        "  * Medium (0.4-0.6): neutral or mixed signals\n",
        "  * Low (0.0-0.3): calm, stable, confident language\n",
        "\n",
        "IMPORTANT: You MUST provide a score between 0.0 and 1.0 for each trait based on the available text. Do NOT default to 0.5 unless you genuinely find perfectly neutral/balanced evidence. Use the full range of scores (0.0-1.0) to reflect varying degrees of each trait.\n",
        "\n",
        "Loan description:\n",
        "{description_text}\n",
        "\n",
        "Return ONLY valid JSON in this exact format:\n",
        "{{\n",
        "  \"openness\": 0.X,\n",
        "  \"conscientiousness\": 0.X,\n",
        "  \"extraversion\": 0.X,\n",
        "  \"agreeableness\": 0.X,\n",
        "  \"neuroticism\": 0.X\n",
        "}}'''\n",
        "\n",
        "print('✓ OCEAN prompt template defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Define API Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ API function defined\n"
          ]
        }
      ],
      "source": [
        "def call_llm_for_ocean_scores(description_text, model_name, provider, api_token, max_retries=3):\n",
        "    prompt = ocean_prompt_template.format(description_text=description_text)\n",
        "    api_url = 'https://router.huggingface.co/v1/chat/completions'\n",
        "    headers = {'Authorization': f'Bearer {api_token}', 'Content-Type': 'application/json'}\n",
        "    payload = {\n",
        "        'messages': [{'role': 'user', 'content': prompt}],\n",
        "        'model': f'{model_name}:{provider}',\n",
        "        'stream': False,\n",
        "        'max_tokens': 200,\n",
        "        'temperature': 0.7\n",
        "    }\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = requests.post(api_url, headers=headers, json=payload, timeout=30)\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                if 'choices' in result and len(result['choices']) > 0:\n",
        "                    text_output = result['choices'][0].get('message', {}).get('content', '')\n",
        "                    try:\n",
        "                        json_start = text_output.find('{')\n",
        "                        if json_start != -1:\n",
        "                            json_string = text_output[json_start:]\n",
        "                            json_end = json_string.find('}') + 1\n",
        "                            json_string = json_string[:json_end]\n",
        "                            score_dict = json.loads(json_string)\n",
        "                            return_value = {}\n",
        "                            for key in ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']:\n",
        "                                if key in score_dict:\n",
        "                                    return_value[key] = float(score_dict[key])\n",
        "                            if len(return_value) == 5:\n",
        "                                return return_value\n",
        "                    except:\n",
        "                        pass\n",
        "            elif response.status_code == 429 and attempt < max_retries - 1:\n",
        "                time.sleep(2 * (attempt + 1))\n",
        "                continue\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(2)\n",
        "    return None\n",
        "\n",
        "print('✓ API function defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Load Checkpoint (if exists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No checkpoint found, starting from scratch\n"
          ]
        }
      ],
      "source": [
        "os.makedirs('../ocean_ground_truth', exist_ok=True)\n",
        "\n",
        "if os.path.exists(CHECKPOINT_FILE):\n",
        "    with open(CHECKPOINT_FILE, 'r') as f:\n",
        "        checkpoint = json.load(f)\n",
        "    print(f'✓ Checkpoint loaded: {checkpoint[\"processed_count\"]}/{checkpoint[\"total_count\"]}')\n",
        "    ocean_scores = checkpoint['ocean_scores']\n",
        "    start_idx = checkpoint['processed_count']\n",
        "else:\n",
        "    print('No checkpoint found, starting from scratch')\n",
        "    ocean_scores = []\n",
        "    start_idx = 0\n",
        "\n",
        "success_count = sum(1 for s in ocean_scores if s is not None)\n",
        "failure_count = len(ocean_scores) - success_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Process All Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Processing Gemma-2-9B\n",
            "================================================================================\n",
            "Total samples: 500\n",
            "Starting from: 0\n",
            "================================================================================\n",
            "50/500 (10.0%) | Success: 50 (100.0%) | ETA: 17.3min\n",
            "100/500 (20.0%) | Success: 100 (100.0%) | ETA: 15.4min\n",
            "150/500 (30.0%) | Success: 150 (100.0%) | ETA: 13.6min\n",
            "200/500 (40.0%) | Success: 200 (100.0%) | ETA: 11.5min\n",
            "250/500 (50.0%) | Success: 250 (100.0%) | ETA: 9.4min\n",
            "300/500 (60.0%) | Success: 300 (100.0%) | ETA: 7.5min\n",
            "350/500 (70.0%) | Success: 350 (100.0%) | ETA: 5.6min\n",
            "400/500 (80.0%) | Success: 400 (100.0%) | ETA: 3.8min\n",
            "450/500 (90.0%) | Success: 450 (100.0%) | ETA: 1.9min\n",
            "500/500 (100.0%) | Success: 500 (100.0%) | ETA: 0.0min\n",
            "\n",
            "✅ COMPLETE: 19.0min | Success: 500/500 (100.0%)\n"
          ]
        }
      ],
      "source": [
        "print('=' * 80)\n",
        "print(f'Processing {DISPLAY_NAME}')\n",
        "print('=' * 80)\n",
        "print(f'Total samples: {len(df_samples)}')\n",
        "print(f'Starting from: {start_idx}')\n",
        "print('=' * 80)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for idx in range(start_idx, len(df_samples)):\n",
        "    row = df_samples.iloc[idx]\n",
        "    description = row.get('desc', '')\n",
        "    \n",
        "    if len(description) < 10:\n",
        "        ocean_scores.append(None)\n",
        "        failure_count += 1\n",
        "        continue\n",
        "    \n",
        "    ocean_score = call_llm_for_ocean_scores(description, MODEL_NAME, PROVIDER, hf_token, max_retries=2)\n",
        "    \n",
        "    if ocean_score:\n",
        "        ocean_scores.append(ocean_score)\n",
        "        success_count += 1\n",
        "    else:\n",
        "        ocean_scores.append(None)\n",
        "        failure_count += 1\n",
        "    \n",
        "    if (idx + 1) % 50 == 0 or (idx + 1) == len(df_samples):\n",
        "        elapsed = time.time() - start_time\n",
        "        rate = (idx + 1 - start_idx) / elapsed if elapsed > 0 else 0\n",
        "        eta = (len(df_samples) - (idx + 1)) / rate / 60 if rate > 0 else 0\n",
        "        print(f'{idx + 1}/{len(df_samples)} ({(idx+1)/len(df_samples)*100:.1f}%) | Success: {success_count} ({success_count/(idx+1)*100:.1f}%) | ETA: {eta:.1f}min')\n",
        "        checkpoint = {'model_name': MODEL_NAME, 'provider': PROVIDER, 'display_name': DISPLAY_NAME, 'total_count': len(df_samples), 'processed_count': idx+1, 'success_count': success_count, 'failure_count': failure_count, 'ocean_scores': ocean_scores, 'last_update': datetime.now().isoformat()}\n",
        "        with open(CHECKPOINT_FILE, 'w') as f:\n",
        "            json.dump(checkpoint, f, indent=2)\n",
        "    time.sleep(1)\n",
        "\n",
        "print(f'\\n✅ COMPLETE: {(time.time()-start_time)/60:.1f}min | Success: {success_count}/{len(df_samples)} ({success_count/len(df_samples)*100:.1f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Results saved: ../ocean_ground_truth/gemma_2_9b_ocean_500.csv (500 rows, 500 valid)\n",
            "✓ Checkpoint removed\n"
          ]
        }
      ],
      "source": [
        "data_list = [{'sample_id': idx, **score} if score else {'sample_id': idx, 'openness': None, 'conscientiousness': None, 'extraversion': None, 'agreeableness': None, 'neuroticism': None} for idx, score in enumerate(ocean_scores)]\n",
        "df_ocean = pd.DataFrame(data_list)\n",
        "df_ocean.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f'✓ Results saved: {OUTPUT_FILE} ({len(df_ocean)} rows, {df_ocean[\"openness\"].notna().sum()} valid)')\n",
        "if os.path.exists(CHECKPOINT_FILE):\n",
        "    os.remove(CHECKPOINT_FILE)\n",
        "    print('✓ Checkpoint removed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Display Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "OCEAN Statistics\n",
            "================================================================================\n",
            "         openness  conscientiousness  extraversion  agreeableness  neuroticism\n",
            "count  500.000000         500.000000    500.000000     500.000000   500.000000\n",
            "mean     0.284800           0.594800      0.280000       0.510300     0.205400\n",
            "std      0.069776           0.105476      0.088179       0.122265     0.151383\n",
            "min      0.100000           0.100000      0.100000       0.200000     0.000000\n",
            "25%      0.200000           0.600000      0.200000       0.400000     0.100000\n",
            "50%      0.300000           0.600000      0.300000       0.500000     0.200000\n",
            "75%      0.300000           0.700000      0.300000       0.600000     0.200000\n",
            "max      0.700000           0.800000      0.800000       0.900000     0.800000\n",
            "\n",
            "✅ ALL DONE!\n"
          ]
        }
      ],
      "source": [
        "print('=' * 80)\n",
        "print('OCEAN Statistics')\n",
        "print('=' * 80)\n",
        "print(df_ocean[['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']].describe())\n",
        "print('\\n✅ ALL DONE!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
