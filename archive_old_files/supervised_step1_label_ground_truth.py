"""
Supervised Learning - Phase 1: ç”¨ LLM æ ‡æ³¨ Ground Truth OCEAN åˆ†æ•°

è¿™ä¸€æ­¥ä¼šï¼š
1. ä»æ•°æ®é›†ä¸­éšæœºæŠ½å– N æ¡æ ·æœ¬
2. ç”¨ LLM (OpenAI API) ç»™æ¯æ¡æ ·æœ¬æ‰“ OCEAN åˆ†æ•°
3. ä¿å­˜ä¸ºè®­ç»ƒé›†ï¼ˆground truthï¼‰

é¢„è®¡æˆæœ¬: ~$1-3 (å–å†³äºæ ·æœ¬æ•°é‡)
é¢„è®¡æ—¶é—´: 10-20 åˆ†é’Ÿ (å–å†³äº API é€Ÿç‡é™åˆ¶)
"""
import sys
sys.path.append('.')

import pandas as pd
import numpy as np
import kagglehub
import os
from text_features.personality_simple import SimplifiedOceanScorer, OCEAN_DIMS

print("=" * 70)
print("Supervised Learning - Phase 1: æ ‡æ³¨ Ground Truth")
print("=" * 70)

# ========== é…ç½® ==========
SAMPLE_SIZE = 500  # æ ‡æ³¨æ ·æœ¬æ•°é‡ï¼ˆå¯è°ƒæ•´ï¼š500-1000ï¼‰
USE_API = True      # æ˜¯å¦ä½¿ç”¨çœŸå® LLM APIï¼ˆéœ€è¦ OPENAI_API_KEYï¼‰

# æ£€æŸ¥ API key
if USE_API and not os.getenv('OPENAI_API_KEY'):
    print("\nâš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    print("è¯·è®¾ç½® API key: export OPENAI_API_KEY='sk-...'")
    print("\næˆ–è€…è®¾ç½® USE_API=False ä½¿ç”¨ offline æ¨¡å¼ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰")
    response = input("\nç»§ç»­ä½¿ç”¨ offline æ¨¡å¼? (y/n): ")
    if response.lower() != 'y':
        exit(0)
    USE_API = False

# ========== åŠ è½½æ•°æ® ==========
print(f"\nã€Step 1ã€‘åŠ è½½æ•°æ®")
print("-" * 70)

path = kagglehub.dataset_download("ethon0426/lending-club-20072020q1")
file_path = path + "/Loan_status_2007-2020Q3.gzip"

# åŠ è½½æ›´å¤šæ•°æ®ä»¥ä¾¿æŠ½æ ·
df = pd.read_csv(file_path, nrows=10000, low_memory=False)
df = df[df['loan_status'].isin(["Fully Paid", "Charged Off"])].copy()
df['target'] = (df['loan_status'] == "Charged Off").astype(int)

print(f"âœ… æ•°æ®åŠ è½½: {len(df)} è¡Œ")
print(f"   è¿çº¦ç‡: {df['target'].mean():.2%}")

# ========== åˆ†å±‚æŠ½æ · ==========
print(f"\nã€Step 2ã€‘åˆ†å±‚æŠ½æ ·ï¼ˆç¡®ä¿è¿çº¦/éè¿çº¦æ¯”ä¾‹ä¸€è‡´ï¼‰")
print("-" * 70)

# æŒ‰ target åˆ†å±‚æŠ½æ ·
sample_df = df.groupby('target', group_keys=False).apply(
    lambda x: x.sample(n=int(SAMPLE_SIZE * len(x) / len(df)), random_state=42)
).reset_index(drop=True)

print(f"âœ… æŠ½æ ·å®Œæˆ: {len(sample_df)} æ¡")
print(f"   è¿çº¦: {(sample_df['target']==1).sum()} æ¡")
print(f"   éè¿çº¦: {(sample_df['target']==0).sum()} æ¡")

# ========== LLM æ ‡æ³¨ ==========
print(f"\nã€Step 3ã€‘LLM æ ‡æ³¨ OCEAN åˆ†æ•°")
print("-" * 70)

if USE_API:
    print(f"ğŸ”„ ä½¿ç”¨ OpenAI API æ ‡æ³¨...")
    print(f"   æ¨¡å‹: gpt-4o-mini")
    print(f"   æ ·æœ¬æ•°: {len(sample_df)}")
    print(f"   é¢„è®¡æˆæœ¬: ~${len(sample_df) * 0.002:.2f}")
    print(f"   é¢„è®¡æ—¶é—´: ~{len(sample_df) * 1.2 / 60:.1f} åˆ†é’Ÿ")
    print()

    scorer = SimplifiedOceanScorer(
        cache_dir="../artifacts/persona_cache_supervised",
        offline_mode=False,  # å¯ç”¨ API
        model="gpt-4o-mini"
    )
else:
    print(f"âš ï¸  ä½¿ç”¨ Offline æ¨¡å¼ï¼ˆä»…ç”¨äºæµ‹è¯•ç®¡çº¿ï¼‰")
    scorer = SimplifiedOceanScorer(
        cache_dir="../artifacts/persona_cache_supervised",
        offline_mode=True
    )

# æ‰¹é‡æ‰“åˆ†
ocean_scores = scorer.score_batch(sample_df, rate_limit_delay=0.5)

# è½¬æ¢ä¸º DataFrame
ocean_df = pd.DataFrame(ocean_scores)

# åˆå¹¶åˆ°æ ·æœ¬æ•°æ®
for dim in OCEAN_DIMS:
    sample_df[f'{dim}_truth'] = ocean_df[dim]

print(f"\nâœ… æ ‡æ³¨å®Œæˆï¼")
print(f"   ç»Ÿè®¡: {scorer.get_stats()}")

# æ˜¾ç¤ºæ ·ä¾‹
print(f"\nã€æ ‡æ³¨æ ·ä¾‹ã€‘")
display_cols = ['grade', 'purpose', 'term', 'home_ownership'] + \
               [f'{dim}_truth' for dim in OCEAN_DIMS]
print(sample_df[display_cols].head(10).to_string(index=False))

# ========== ä¿å­˜ Ground Truth ==========
print(f"\nã€Step 4ã€‘ä¿å­˜ Ground Truth è®­ç»ƒé›†")
print("-" * 70)

output_path = 'artifacts/results/ground_truth_ocean.csv'
sample_df.to_csv(output_path, index=False)

print(f"âœ… å·²ä¿å­˜: {output_path}")
print(f"   åŒ…å«å­—æ®µ:")
print(f"   - åŸå§‹ç‰¹å¾: grade, purpose, term, etc.")
print(f"   - Ground Truth: openness_truth, conscientiousness_truth, ...")
print(f"   - Target: target (è¿çº¦æ ‡ç­¾)")

# ========== ç»Ÿè®¡åˆ†æ ==========
print(f"\nã€Step 5ã€‘Ground Truth ç»Ÿè®¡åˆ†æ")
print("-" * 70)

truth_cols = [f'{dim}_truth' for dim in OCEAN_DIMS]
print("\nOCEAN Ground Truth ç»Ÿè®¡:")
stats = sample_df[truth_cols].describe().T[['mean', 'std', 'min', 'max']]
print(stats.to_string())

print("\nOCEAN ä¸è¿çº¦ç‡çš„ç›¸å…³æ€§:")
for dim in OCEAN_DIMS:
    corr = sample_df[f'{dim}_truth'].corr(sample_df['target'])
    print(f"  {dim:20s}: r = {corr:+.3f}")

print("\n" + "=" * 70)
print("âœ… Phase 1 å®Œæˆï¼Ground Truth å·²å‡†å¤‡å¥½")
print("=" * 70)

if USE_API:
    print("\nğŸ’° å®é™…æˆæœ¬ç»Ÿè®¡:")
    print(f"   API è°ƒç”¨: {scorer.get_stats()['api_calls']} æ¬¡")
    print(f"   ç¼“å­˜å‘½ä¸­: {scorer.get_stats()['cache_hits']} æ¬¡")
    print(f"   ä¼°ç®—æˆæœ¬: ~${scorer.get_stats()['api_calls'] * 0.002:.2f}")

print("\nä¸‹ä¸€æ­¥: è¿è¡Œ supervised_step2_learn_weights.py")
print("è¿™å°†è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹å­¦ä¹ æƒé‡")
