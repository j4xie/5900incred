{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama OCEAN 特征生成完整流程\n",
    "## 使用 Llama-3.1-8B-Instruct 模型（免费）\n",
    "\n",
    "---\n",
    "\n",
    "### 流程概览\n",
    "\n",
    "1. **Llama 打标签** (500样本) → OCEAN ground truth\n",
    "2. **学习权重** (Ridge Regression) → categorical → OCEAN 映射\n",
    "3. **生成特征** (全量数据) → 10000行 × 5列 OCEAN\n",
    "4. **XGBoost 对比** → Baseline vs Baseline+OCEAN\n",
    "\n",
    "**成本**: $0 (Llama 免费)  \n",
    "**时间**: ~20分钟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kagglehub\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 项目模块\n",
    "from utils.io import load_lending_club_data, prepare_binary_target\n",
    "from utils.seed import set_seed\n",
    "from utils.metrics import compute_all_metrics, delong_test\n",
    "from text_features.ocean_llama_labeler import OceanLlamaLabeler, OCEAN_DIMS\n",
    "from utils.ocean_weight_learner import OceanWeightLearner\n",
    "from utils.ocean_feature_generator import OceanFeatureGenerator\n",
    "from utils.ocean_evaluator import OceanEvaluator\n",
    "\n",
    "set_seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载数据\n",
    "path = kagglehub.dataset_download(\"ethon0426/lending-club-20072020q1\")\n",
    "file_path = path + \"/Loan_status_2007-2020Q3.gzip\"\n",
    "\n",
    "# 加载数据（先用 10000 行测试）\n",
    "ROW_LIMIT = 10000\n",
    "\n",
    "df = load_lending_club_data(file_path, row_limit=ROW_LIMIT)\n",
    "df = prepare_binary_target(df, target_col=\"loan_status\")\n",
    "\n",
    "print(f\"\\n数据形状: {df.shape}\")\n",
    "print(f\"违约率: {df['target'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Llama 打标签（生成 Ground Truth）\n",
    "\n",
    "**说明**: 使用 Llama 模型给 500 个样本打 OCEAN 人格分数  \n",
    "**成本**: $0 (免费)  \n",
    "**时间**: ~10-15分钟  \n",
    "\n",
    "**⚠️ 重要**: 需要先配置 `.env` 文件中的 `HF_TOKEN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化标注器\n",
    "labeler = OceanLlamaLabeler()\n",
    "\n",
    "# 批量打标签（500样本，分层抽样）\n",
    "df_truth = labeler.label_batch(\n",
    "    df, \n",
    "    sample_size=500, \n",
    "    stratified=True,\n",
    "    rate_limit_delay=0.5  # API 限流\n",
    ")\n",
    "\n",
    "# 保存 ground truth\n",
    "df_truth.to_csv('../artifacts/ground_truth_llama.csv', index=False)\n",
    "print(\"\\n✅ Ground Truth 已保存到: artifacts/ground_truth_llama.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 评估 Ground Truth 质量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = OceanEvaluator()\n",
    "truth_quality = evaluator.evaluate_ground_truth_quality(df_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 学习权重（Ridge Regression）\n",
    "\n",
    "**说明**: 学习 categorical variables → OCEAN 的映射规律  \n",
    "**方法**: Ridge Regression (L2 正则化)  \n",
    "**输出**: 每个 OCEAN 维度的权重系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 categorical variables\n",
    "CATEGORICAL_VARS = [\n",
    "    'grade', 'purpose', 'term', 'home_ownership',\n",
    "    'emp_length', 'verification_status', 'application_type'\n",
    "]\n",
    "\n",
    "# 过滤存在的列\n",
    "CATEGORICAL_VARS = [c for c in CATEGORICAL_VARS if c in df_truth.columns]\n",
    "\n",
    "print(f\"使用的 categorical variables: {CATEGORICAL_VARS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化学习器\n",
    "learner = OceanWeightLearner(method='ridge', alpha=0.1)\n",
    "\n",
    "# 学习权重\n",
    "weights, encoder = learner.fit(\n",
    "    X_categorical=df_truth[CATEGORICAL_VARS],\n",
    "    y_ocean_truth=df_truth[[f'{d}_truth' for d in OCEAN_DIMS]],\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# 保存权重\n",
    "joblib.dump(\n",
    "    {'weights': weights, 'encoder': encoder},\n",
    "    '../artifacts/ocean_weights_llama.pkl'\n",
    ")\n",
    "print(\"\\n✅ 权重已保存到: artifacts/ocean_weights_llama.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 查看学习结果摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.get_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 查看各维度 Top 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in OCEAN_DIMS:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"{dim.upper()} - Top 10 特征\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    display(learner.get_top_features(dim, top_n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 生成全量 OCEAN 特征\n",
    "\n",
    "**说明**: 使用学到的权重给全量数据（10000行）生成 OCEAN 特征  \n",
    "**成本**: $0 (本地计算)  \n",
    "**时间**: 即时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化生成器\n",
    "generator = OceanFeatureGenerator(weights, encoder)\n",
    "\n",
    "# 生成 OCEAN 特征\n",
    "df_full = generator.generate_features(df)\n",
    "\n",
    "print(\"\\n✅ OCEAN 特征已添加到数据集\")\n",
    "print(f\"新增列: {OCEAN_DIMS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 评估生成特征的预测能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_power = evaluator.evaluate_predictive_power(df_full, target_col='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汇总报告\n",
    "summary = evaluator.generate_summary_report()\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XGBoost A/B 对比测试\n",
    "\n",
    "**对比方案**:\n",
    "- **方案 A**: Baseline (结构化变量)\n",
    "- **方案 B**: Baseline + OCEAN (5个性格特征)\n",
    "\n",
    "**评估指标**: ROC-AUC, PR-AUC, KS, Brier Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 baseline 特征\n",
    "numeric_features = [\n",
    "    \"loan_amnt\", \"int_rate\", \"installment\", \"annual_inc\", \"dti\",\n",
    "    \"inq_last_6mths\", \"open_acc\", \"pub_rec\", \"revol_bal\", \"revol_util\",\n",
    "    \"total_acc\"\n",
    "]\n",
    "numeric_features = [c for c in numeric_features if c in df_full.columns]\n",
    "\n",
    "categorical_features_model = [c for c in CATEGORICAL_VARS if c in df_full.columns]\n",
    "\n",
    "baseline_features = numeric_features + categorical_features_model\n",
    "ocean_features = OCEAN_DIMS\n",
    "\n",
    "print(f\"Baseline 特征数: {len(baseline_features)}\")\n",
    "print(f\"OCEAN 特征数: {len(ocean_features)}\")\n",
    "print(f\"总特征数 (Baseline+OCEAN): {len(baseline_features) + len(ocean_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理：OneHot 编码 categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 数值特征处理\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "# categorical 特征处理\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "])\n",
    "\n",
    "# 方案 A: Baseline\n",
    "preprocessor_A = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features_model),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# 方案 B: Baseline + OCEAN\n",
    "preprocessor_B = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"ocean\", \"passthrough\", ocean_features),  # OCEAN 直接通过\n",
    "        (\"cat\", categorical_transformer, categorical_features_model),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "y = df_full['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_full, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"训练集: {len(X_train)} 样本\")\n",
    "print(f\"测试集: {len(X_test)} 样本\")\n",
    "print(f\"训练集违约率: {y_train.mean():.2%}\")\n",
    "print(f\"测试集违约率: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 训练方案 A: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n训练方案 A: Baseline (无 OCEAN)...\\n\")\n",
    "\n",
    "# 预处理\n",
    "X_train_A = preprocessor_A.fit_transform(X_train)\n",
    "X_test_A = preprocessor_A.transform(X_test)\n",
    "\n",
    "# 训练 XGBoost\n",
    "pos = int((y_train == 1).sum())\n",
    "neg = int((y_train == 0).sum())\n",
    "scale_pos_weight = neg / max(1, pos)\n",
    "\n",
    "model_A = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric=\"auc\"\n",
    ")\n",
    "\n",
    "model_A.fit(X_train_A, y_train, verbose=False)\n",
    "\n",
    "# 预测\n",
    "y_proba_A = model_A.predict_proba(X_test_A)[:, 1]\n",
    "metrics_A = compute_all_metrics(y_test, y_proba_A)\n",
    "\n",
    "print(\"\\n方案 A 结果:\")\n",
    "for k, v in metrics_A.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 训练方案 B: Baseline + OCEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n训练方案 B: Baseline + OCEAN...\\n\")\n",
    "\n",
    "# 预处理\n",
    "X_train_B = preprocessor_B.fit_transform(X_train)\n",
    "X_test_B = preprocessor_B.transform(X_test)\n",
    "\n",
    "# 训练 XGBoost\n",
    "model_B = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric=\"auc\"\n",
    ")\n",
    "\n",
    "model_B.fit(X_train_B, y_train, verbose=False)\n",
    "\n",
    "# 预测\n",
    "y_proba_B = model_B.predict_proba(X_test_B)[:, 1]\n",
    "metrics_B = compute_all_metrics(y_test, y_proba_B)\n",
    "\n",
    "print(\"\\n方案 B 结果:\")\n",
    "for k, v in metrics_B.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 对比结果与统计显著性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = evaluator.compare_models(y_test, y_proba_A, y_proba_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 可视化对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ROC Curve\n",
    "fpr_A, tpr_A, _ = roc_curve(y_test, y_proba_A)\n",
    "fpr_B, tpr_B, _ = roc_curve(y_test, y_proba_B)\n",
    "\n",
    "axes[0].plot(fpr_A, tpr_A, label=f\"Baseline (AUC={auc(fpr_A, tpr_A):.3f})\", linewidth=2)\n",
    "axes[0].plot(fpr_B, tpr_B, label=f\"+ OCEAN (AUC={auc(fpr_B, tpr_B):.3f})\", linewidth=2)\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve Comparison')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "prec_A, rec_A, _ = precision_recall_curve(y_test, y_proba_A)\n",
    "prec_B, rec_B, _ = precision_recall_curve(y_test, y_proba_B)\n",
    "\n",
    "axes[1].plot(rec_A, prec_A, label=f\"Baseline (PR-AUC={metrics_A['pr_auc']:.3f})\", linewidth=2)\n",
    "axes[1].plot(rec_B, prec_B, label=f\"+ OCEAN (PR-AUC={metrics_B['pr_auc']:.3f})\", linewidth=2)\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve Comparison')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../artifacts/results/llama_ocean_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最佳模型\n",
    "joblib.dump(model_B, '../artifacts/xgb_ocean_llama.pkl')\n",
    "print(\"✅ 模型已保存: artifacts/xgb_ocean_llama.pkl\")\n",
    "\n",
    "# 保存对比结果\n",
    "results_df = pd.DataFrame([\n",
    "    {'model': 'Baseline', **metrics_A},\n",
    "    {'model': 'Baseline+OCEAN', **metrics_B}\n",
    "])\n",
    "results_df.to_csv('../artifacts/results/llama_ocean_results.csv', index=False)\n",
    "print(\"✅ 结果已保存: artifacts/results/llama_ocean_results.csv\")\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 总结\n",
    "\n",
    "### ✅ 完成的工作\n",
    "\n",
    "1. 使用 Llama 模型为 500 个样本生成 OCEAN ground truth\n",
    "2. 使用 Ridge Regression 学习 categorical → OCEAN 映射权重\n",
    "3. 为全量 10000 样本生成 OCEAN 特征\n",
    "4. XGBoost A/B 对比测试\n",
    "\n",
    "### 📊 结果摘要\n",
    "\n",
    "（运行后填写）\n",
    "\n",
    "- **ROC-AUC 提升**: +_____ \n",
    "- **PR-AUC 提升**: +_____\n",
    "- **KS 提升**: +_____\n",
    "- **统计显著性**: p = _____\n",
    "\n",
    "### 💰 成本\n",
    "\n",
    "- **总成本**: $0 (Llama 免费)\n",
    "- **总时间**: ~20分钟\n",
    "\n",
    "### 🎯 下一步\n",
    "\n",
    "1. 如果效果显著：扩展到完整数据集（100k+样本）\n",
    "2. 尝试其他文本源（如果有 `desc` 字段）\n",
    "3. 特征解释分析（SHAP）\n",
    "4. 生产部署"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
