{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCEAN Features: Interpretability & Robustness Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from text_features.personality import OCEAN_DIMS\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "shap.initjs()  # Initialize SHAP JS visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained XGBoost + OCEAN model from previous notebook\n",
    "model_path = '../artifacts/xgb_ocean_model.joblib'\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "print(f\"Model loaded from {model_path}\")\n",
    "print(f\"Pipeline steps: {model.named_steps.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data (you may need to regenerate from notebook 03)\n",
    "# For demo purposes, we'll load a sample\n",
    "\n",
    "# TODO: Replace this with actual X_test, y_test from notebook 03\n",
    "# For now, create placeholder\n",
    "print(\"Note: Load X_test, y_test from notebook 03 or regenerate data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names after preprocessing\n",
    "feature_names = model.named_steps['preprocess'].get_feature_names_out()\n",
    "\n",
    "# Get feature importances from XGBoost\n",
    "importances = model.named_steps['clf'].feature_importances_\n",
    "\n",
    "# Create DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 Features by Importance:\")\n",
    "print(importance_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 30 features\n",
    "top_features = importance_df.head(30)\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='steelblue')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance (Gain)')\n",
    "plt.title('Top 30 XGBoost Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../artifacts/results/feature_importance_top30.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ranking of OCEAN features\n",
    "ocean_importance = importance_df[importance_df['feature'].str.contains('|'.join(OCEAN_DIMS), case=False)]\n",
    "\n",
    "print(\"\\nOCEAN Features Importance Ranking:\")\n",
    "print(ocean_importance)\n",
    "\n",
    "if len(ocean_importance) > 0:\n",
    "    avg_rank = importance_df.reset_index(drop=True).reset_index().merge(\n",
    "        ocean_importance, on='feature'\n",
    "    )['index'].mean()\n",
    "    print(f\"\\nAverage rank of OCEAN features: {avg_rank:.1f} / {len(importance_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SHAP Analysis\n",
    "\n",
    "### 3.1 Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data through preprocessing pipeline\n",
    "# X_test_transformed = model.named_steps['preprocess'].transform(X_test)\n",
    "\n",
    "# Create SHAP explainer\n",
    "# explainer = shap.TreeExplainer(model.named_steps['clf'])\n",
    "# shap_values = explainer(X_test_transformed)\n",
    "\n",
    "print(\"TODO: Uncomment and run after loading X_test from notebook 03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global SHAP summary plot (beeswarm)\n",
    "# shap.summary_plot(shap_values, X_test_transformed, \n",
    "#                  feature_names=feature_names, max_display=20)\n",
    "# plt.savefig('../artifacts/results/shap_summary_beeswarm.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP bar plot (mean absolute SHAP values)\n",
    "# shap.summary_plot(shap_values, X_test_transformed, \n",
    "#                  feature_names=feature_names, plot_type='bar', max_display=20)\n",
    "# plt.savefig('../artifacts/results/shap_summary_bar.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 OCEAN-Specific SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SHAP values for OCEAN dimensions only\n",
    "# ocean_indices = [i for i, name in enumerate(feature_names) \n",
    "#                 if any(dim in name for dim in OCEAN_DIMS)]\n",
    "\n",
    "# if ocean_indices:\n",
    "#     ocean_feature_names = [feature_names[i] for i in ocean_indices]\n",
    "#     ocean_shap_values = shap_values.values[:, ocean_indices]\n",
    "#     ocean_features = X_test_transformed[:, ocean_indices]\n",
    "#     \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     shap.summary_plot(ocean_shap_values, ocean_features, \n",
    "#                      feature_names=ocean_feature_names)\n",
    "#     plt.title('SHAP Values for OCEAN Dimensions')\n",
    "#     plt.savefig('../artifacts/results/shap_ocean_only.png', dpi=150, bbox_inches='tight')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Local Explanations (Individual Cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select interesting samples:\n",
    "# - High-risk prediction (model says likely default)\n",
    "# - Low-risk prediction (model says unlikely default)\n",
    "\n",
    "# y_proba = model.predict_proba(X_test)[:, 1]\n",
    "# high_risk_idx = np.argmax(y_proba)\n",
    "# low_risk_idx = np.argmin(y_proba)\n",
    "\n",
    "# print(f\"High-risk sample index: {high_risk_idx} (predicted prob: {y_proba[high_risk_idx]:.3f})\")\n",
    "# print(f\"Low-risk sample index: {low_risk_idx} (predicted prob: {y_proba[low_risk_idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force plot for high-risk sample\n",
    "# shap.force_plot(explainer.expected_value, \n",
    "#                shap_values.values[high_risk_idx], \n",
    "#                X_test_transformed[high_risk_idx],\n",
    "#                feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force plot for low-risk sample\n",
    "# shap.force_plot(explainer.expected_value, \n",
    "#                shap_values.values[low_risk_idx], \n",
    "#                X_test_transformed[low_risk_idx],\n",
    "#                feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis\n",
    "\n",
    "Check if OCEAN features are redundant with existing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations between OCEAN and key numeric features\n",
    "# key_features = ['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'revol_util'] + OCEAN_DIMS\n",
    "# corr_matrix = X_train[key_features].corr()\n",
    "\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "#            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "# plt.title('Correlation: OCEAN vs Key Financial Features')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('../artifacts/results/ocean_correlation_with_features.png', dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check maximum correlation of each OCEAN dimension with other features\n",
    "# for dim in OCEAN_DIMS:\n",
    "#     corr_with_others = corr_matrix[dim].drop(OCEAN_DIMS).abs().sort_values(ascending=False)\n",
    "#     print(f\"\\n{dim.capitalize()}:\")\n",
    "#     print(f\"  Highest correlation: {corr_with_others.index[0]} ({corr_with_others.iloc[0]:.3f})\")\n",
    "#     print(f\"  Top 3: {corr_with_others.head(3).to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Robustness Checks\n",
    "\n",
    "### 5.1 Text Truncation Sensitivity\n",
    "\n",
    "Test how different truncation lengths affect OCEAN scores and model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different max_chars: [400, 800, 1200]\n",
    "# For offline mode, this will show consistency of deterministic fallback\n",
    "# For API mode, this tests prompt sensitivity\n",
    "\n",
    "from text_features.personality import OceanScorer\n",
    "\n",
    "# Sample 100 texts\n",
    "# sample_titles = X_train['title_clean'].sample(100, random_state=42).tolist()\n",
    "# sample_emp = X_train['emp_title_clean'].sample(100, random_state=42).tolist()\n",
    "\n",
    "# truncation_lengths = [400, 800, 1200]\n",
    "# truncation_results = {}\n",
    "\n",
    "# for max_chars in truncation_lengths:\n",
    "#     scorer = OceanScorer(offline_mode=True, max_chars=max_chars)\n",
    "#     scores = scorer.score_batch(sample_titles, sample_emp)\n",
    "#     scores_df = pd.DataFrame(scores)\n",
    "#     truncation_results[max_chars] = scores_df\n",
    "#     print(f\"Max chars {max_chars}: Mean OCEAN scores\")\n",
    "#     print(scores_df.mean())\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Consistency Check (Repeated Scoring)\n",
    "\n",
    "For offline mode: should be 100% consistent (deterministic)\n",
    "For API mode with temperature=0: should have very low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the same 10 samples multiple times\n",
    "# sample_text = \"Debt Consolidation | Software Engineer\"\n",
    "# \n",
    "# scorer = OceanScorer(offline_mode=True)\n",
    "# repeated_scores = []\n",
    "# \n",
    "# for i in range(5):\n",
    "#     score = scorer.score(\"Debt Consolidation\", \"Software Engineer\")\n",
    "#     repeated_scores.append(score)\n",
    "# \n",
    "# repeated_df = pd.DataFrame(repeated_scores)\n",
    "# print(\"Repeated scoring consistency (std should be 0 for offline mode):\")\n",
    "# print(repeated_df.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary & Insights\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "**Feature Importance:**\n",
    "- OCEAN features rank: _____ (fill after analysis)\n",
    "- Most important OCEAN dimension: _____\n",
    "- Least important OCEAN dimension: _____\n",
    "\n",
    "**SHAP Insights:**\n",
    "- Direction of effects: Does high conscientiousness reduce default risk? _____\n",
    "- Magnitude: How large are OCEAN effects compared to financial features? _____\n",
    "\n",
    "**Correlation:**\n",
    "- Max correlation with existing features: _____ (should be < 0.7 for independence)\n",
    "- Evidence of multicollinearity: _____\n",
    "\n",
    "**Robustness:**\n",
    "- Truncation sensitivity: _____\n",
    "- Scoring consistency: _____\n",
    "\n",
    "### Recommendations\n",
    "1. If OCEAN features show reasonable importance + interpretable directions → **Production candidate**\n",
    "2. If highly correlated with existing features → **May be redundant**\n",
    "3. If unstable across prompts/truncation → **Need better text or prompt engineering**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
