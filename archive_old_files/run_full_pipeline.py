"""
å®Œæ•´æµç¨‹: Step 4-10 ä¸€æ¬¡æ€§è¿è¡Œ
ä»æ•°æ®åŠ è½½ â†’ OCEAN æ‰“åˆ† â†’ æ¨¡å‹è®­ç»ƒ â†’ A/B å¯¹æ¯” â†’ å¯è§†åŒ–
"""
import sys
sys.path.append('.')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import kagglehub
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score, average_precision_score

from text_features.personality_simple import SimplifiedOceanScorer, OCEAN_DIMS
from utils.seed import set_seed

# è®¾ç½®éšæœºç§å­
set_seed(42)
sns.set_style('whitegrid')

print("=" * 70)
print(" "*20 + "å®Œæ•´ OCEAN é›†æˆæµç¨‹")
print("=" * 70)

# ========== Step 4: åŠ è½½æ•°æ® ==========
print("\nã€Step 4ã€‘ åŠ è½½æ•°æ® (5000 æ¡)")
print("-" * 70)

path = kagglehub.dataset_download("ethon0426/lending-club-20072020q1")
file_path = path + "/Loan_status_2007-2020Q3.gzip"

ROW_LIMIT = 5000
df = pd.read_csv(file_path, nrows=ROW_LIMIT, low_memory=False)

# å‡†å¤‡ target
df = df[df['loan_status'].isin(["Fully Paid", "Charged Off"])].copy()
df['target'] = (df['loan_status'] == "Charged Off").astype(int)

print(f"âœ… æ•°æ®åŠ è½½: {len(df)} è¡Œ")
print(f"   è¿çº¦ç‡: {df['target'].mean():.2%}")

# æ‰¹é‡æ‰“åˆ†
print(f"\nğŸ”„ OCEAN æ‰“åˆ†ä¸­...")
scorer = SimplifiedOceanScorer(offline_mode=True)
ocean_scores = scorer.score_batch(df, rate_limit_delay=0)
ocean_df = pd.DataFrame(ocean_scores)

# ========== Step 5: åˆå¹¶ OCEAN ç‰¹å¾ ==========
print(f"\nã€Step 5ã€‘ åˆå¹¶ OCEAN ç‰¹å¾åˆ° DataFrame")
print("-" * 70)

for dim in OCEAN_DIMS:
    df[dim] = ocean_df[dim]

print(f"âœ… å·²æ·»åŠ  5 ä¸ª OCEAN ç‰¹å¾: {OCEAN_DIMS}")
print(f"\nOCEAN ç»Ÿè®¡:")
ocean_stats = df[OCEAN_DIMS].describe().T[['mean', 'std', 'min', 'max']]
print(ocean_stats.to_string())

# ========== å‡†å¤‡ç‰¹å¾ ==========
print(f"\nã€ç‰¹å¾å·¥ç¨‹ã€‘ å‡†å¤‡ Baseline å’Œ OCEAN ç‰¹å¾")
print("-" * 70)

# Baseline æ•°å€¼ç‰¹å¾
numeric_features = [
    "loan_amnt", "int_rate", "installment", "annual_inc", "dti",
    "inq_last_6mths", "open_acc", "pub_rec", "revol_bal", "revol_util",
    "total_acc"
]
numeric_features = [c for c in numeric_features if c in df.columns]

# åˆ†ç±»ç‰¹å¾
categorical_features = [
    "term", "grade", "sub_grade", "emp_length", "home_ownership",
    "verification_status", "purpose", "application_type"
]
categorical_features = [c for c in categorical_features if c in df.columns]

# æ¸…ç†ç™¾åˆ†æ¯”åˆ—
for col in ["int_rate", "revol_util"]:
    if col in df.columns and df[col].dtype == object:
        df[col] = pd.to_numeric(df[col].astype(str).str.rstrip("%"), errors="coerce")

print(f"âœ… Baseline æ•°å€¼ç‰¹å¾: {len(numeric_features)} ä¸ª")
print(f"âœ… Baseline åˆ†ç±»ç‰¹å¾: {len(categorical_features)} ä¸ª")
print(f"âœ… OCEAN ç‰¹å¾: {len(OCEAN_DIMS)} ä¸ª")

# å®šä¹‰ä¸¤ä¸ªç‰¹å¾é›†
features_baseline = numeric_features + categorical_features
features_with_ocean = numeric_features + OCEAN_DIMS + categorical_features

print(f"\nğŸ“Š ç‰¹å¾é›† A (Baseline): {len(features_baseline)} ä¸ªç‰¹å¾")
print(f"ğŸ“Š ç‰¹å¾é›† B (Baseline+OCEAN): {len(features_with_ocean)} ä¸ªç‰¹å¾")

# Train/Test Split
X = df[features_with_ocean].copy()
y = df['target'].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nâœ… æ•°æ®åˆ‡åˆ†: Train={len(X_train)}, Test={len(X_test)}")

# ========== Step 6: è®­ç»ƒ Baseline æ¨¡å‹ (XGBoost) ==========
print(f"\nã€Step 6ã€‘ è®­ç»ƒ Baseline æ¨¡å‹ (ä¸å« OCEAN)")
print("-" * 70)

X_train_a = X_train[features_baseline]
X_test_a = X_test[features_baseline]

numeric_a = [f for f in numeric_features if f in features_baseline]
categorical_a = [f for f in categorical_features if f in features_baseline]

# æ„å»º pipeline
numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median"))
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=True))
])

preprocess_a = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_a),
        ("cat", categorical_transformer, categorical_a),
    ],
    remainder="drop",
    sparse_threshold=0.3
)

pos = int((y_train == 1).sum())
neg = int((y_train == 0).sum())
scale_pos_weight = neg / max(1, pos)

model_a = Pipeline(steps=[
    ("preprocess", preprocess_a),
    ("clf", XGBClassifier(
        objective="binary:logistic",
        tree_method="hist",
        n_estimators=100,  # å‡å°‘æ•°é‡åŠ å¿«è®­ç»ƒ
        learning_rate=0.1,
        max_depth=5,
        scale_pos_weight=scale_pos_weight,
        random_state=42,
        verbosity=0
    ))
])

print(f"ğŸ”„ è®­ç»ƒä¸­...")
model_a.fit(X_train_a, y_train)

y_proba_a = model_a.predict_proba(X_test_a)[:, 1]
roc_auc_a = roc_auc_score(y_test, y_proba_a)
pr_auc_a = average_precision_score(y_test, y_proba_a)

print(f"âœ… Baseline æ¨¡å‹è®­ç»ƒå®Œæˆ")
print(f"   ROC-AUC: {roc_auc_a:.4f}")
print(f"   PR-AUC:  {pr_auc_a:.4f}")

# ========== Step 7: è®­ç»ƒå¢å¼ºæ¨¡å‹ (Baseline + OCEAN) ==========
print(f"\nã€Step 7ã€‘ è®­ç»ƒå¢å¼ºæ¨¡å‹ (å« OCEAN)")
print("-" * 70)

X_train_b = X_train[features_with_ocean]
X_test_b = X_test[features_with_ocean]

numeric_b = [f for f in numeric_features + OCEAN_DIMS if f in features_with_ocean]
categorical_b = [f for f in categorical_features if f in features_with_ocean]

preprocess_b = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_b),
        ("cat", categorical_transformer, categorical_b),
    ],
    remainder="drop",
    sparse_threshold=0.3
)

model_b = Pipeline(steps=[
    ("preprocess", preprocess_b),
    ("clf", XGBClassifier(
        objective="binary:logistic",
        tree_method="hist",
        n_estimators=100,
        learning_rate=0.1,
        max_depth=5,
        scale_pos_weight=scale_pos_weight,
        random_state=42,
        verbosity=0
    ))
])

print(f"ğŸ”„ è®­ç»ƒä¸­...")
model_b.fit(X_train_b, y_train)

y_proba_b = model_b.predict_proba(X_test_b)[:, 1]
roc_auc_b = roc_auc_score(y_test, y_proba_b)
pr_auc_b = average_precision_score(y_test, y_proba_b)

print(f"âœ… å¢å¼ºæ¨¡å‹è®­ç»ƒå®Œæˆ")
print(f"   ROC-AUC: {roc_auc_b:.4f}")
print(f"   PR-AUC:  {pr_auc_b:.4f}")

# ========== Step 8: A/B å¯¹æ¯” ==========
print(f"\nã€Step 8ã€‘ A/B å¯¹æ¯”")
print("=" * 70)
print(f"{'Metric':<15} {'A (Baseline)':<20} {'B (+OCEAN)':<20} {'Delta':<15}")
print("-" * 70)

delta_roc = roc_auc_b - roc_auc_a
delta_pr = pr_auc_b - pr_auc_a

print(f"{'ROC-AUC':<15} {roc_auc_a:<20.4f} {roc_auc_b:<20.4f} {delta_roc:+.4f}")
print(f"{'PR-AUC':<15} {pr_auc_a:<20.4f} {pr_auc_b:<20.4f} {delta_pr:+.4f}")
print("=" * 70)

# åˆ¤æ–­æ˜¯å¦è¾¾åˆ°æˆåŠŸæ ‡å‡†
success = False
if delta_roc >= 0.010:
    print(f"âœ… ROC-AUC æå‡ {delta_roc:.4f} >= +0.010 (æˆåŠŸ!)")
    success = True
elif delta_pr >= 0.008:
    print(f"âœ… PR-AUC æå‡ {delta_pr:.4f} >= +0.008 (æˆåŠŸ!)")
    success = True
else:
    print(f"âš ï¸  æœªè¾¾åˆ°æœ€ä½æå‡æ ‡å‡† (ROC-AUC +0.010 æˆ– PR-AUC +0.008)")
    print(f"   ä½†æŠ€æœ¯ç®¡çº¿å·²éªŒè¯å¯è¡Œ")

# ========== Step 9: å¯è§†åŒ– ==========
print(f"\nã€Step 9ã€‘ ç”Ÿæˆå¯è§†åŒ–")
print("-" * 70)

from sklearn.metrics import roc_curve, precision_recall_curve

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ROC Curve
fpr_a, tpr_a, _ = roc_curve(y_test, y_proba_a)
fpr_b, tpr_b, _ = roc_curve(y_test, y_proba_b)

axes[0].plot(fpr_a, tpr_a, label=f"Baseline (AUC={roc_auc_a:.3f})", linewidth=2)
axes[0].plot(fpr_b, tpr_b, label=f"+ OCEAN (AUC={roc_auc_b:.3f})", linewidth=2)
axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1)
axes[0].set_xlabel('False Positive Rate')
axes[0].set_ylabel('True Positive Rate')
axes[0].set_title('ROC Curve Comparison')
axes[0].legend()
axes[0].grid(True)

# Precision-Recall Curve
prec_a, rec_a, _ = precision_recall_curve(y_test, y_proba_a)
prec_b, rec_b, _ = precision_recall_curve(y_test, y_proba_b)

axes[1].plot(rec_a, prec_a, label=f"Baseline (PR-AUC={pr_auc_a:.3f})", linewidth=2)
axes[1].plot(rec_b, prec_b, label=f"+ OCEAN (PR-AUC={pr_auc_b:.3f})", linewidth=2)
axes[1].set_xlabel('Recall')
axes[1].set_ylabel('Precision')
axes[1].set_title('Precision-Recall Curve Comparison')
axes[1].legend()
axes[1].grid(True)

plt.tight_layout()
plt.savefig('artifacts/results/ab_comparison.png', dpi=150)
print(f"âœ… å›¾è¡¨å·²ä¿å­˜: artifacts/results/ab_comparison.png")

# ========== Step 10: å¯¼å‡ºç»“æœ ==========
print(f"\nã€Step 10ã€‘ å¯¼å‡ºç»“æœ")
print("-" * 70)

results = {
    'model': ['XGBoost_Baseline', 'XGBoost_OCEAN'],
    'n_features': [len(features_baseline), len(features_with_ocean)],
    'roc_auc': [roc_auc_a, roc_auc_b],
    'pr_auc': [pr_auc_a, pr_auc_b],
    'roc_delta': [0, delta_roc],
    'pr_delta': [0, delta_pr]
}

results_df = pd.DataFrame(results)
results_df.to_csv('artifacts/results/ab_results.csv', index=False)
print(f"âœ… ç»“æœå·²ä¿å­˜: artifacts/results/ab_results.csv")
print(f"\næœ€ç»ˆç»“æœè¡¨:")
print(results_df.to_string(index=False))

print(f"\n" + "=" * 70)
print(" "*25 + "ğŸ‰ æµç¨‹å®Œæˆï¼")
print("=" * 70)
print(f"\næŸ¥çœ‹ç»“æœ:")
print(f"  - å›¾è¡¨: artifacts/results/ab_comparison.png")
print(f"  - æ•°æ®: artifacts/results/ab_results.csv")
