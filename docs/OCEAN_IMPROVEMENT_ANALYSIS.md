# OCEAN Features ä¼˜åŒ–åˆ†ææŠ¥å‘Š
**é¡¹ç›®**: Credibly Credit Risk Prediction
**æ—¥æœŸ**: 2025-10-08
**åˆ†æå¯¹è±¡**: LlamaOceanPipeline.ipynb è¾“å‡ºç»“æœ

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

### å½“å‰è¡¨ç°
| æ¨¡å‹ | ROC-AUC | PR-AUC | KS | ç»“è®º |
|------|---------|--------|-----|------|
| Baseline | 0.6865 | 0.2733 | 29.94 | - |
| Baseline+OCEAN | 0.6862 | 0.2699 | 30.14 | âŒ **æ— æå‡** |
| **Delta** | **-0.0003** | **-0.0034** | **+0.20** | **OCEANç‰¹å¾æ— æ•ˆ** |

### æ ¸å¿ƒé—®é¢˜
1. âš ï¸ **æ ‡æ³¨è´¨é‡å·®**ï¼š500ä¸ªæ ·æœ¬çš„OCEANåˆ†æ•°ä¸¥é‡é›†ä¸­ï¼Œæ— åŒºåˆ†åº¦
2. âš ï¸ **å®šä¹‰ä¸å®Œæ•´**ï¼šPromptä¸­OCEANå®šä¹‰è¿‡äºç®€åŒ–ï¼Œæ˜ å°„è§„åˆ™ä¸å‡†ç¡®
3. âš ï¸ **æ ·æœ¬é‡ä¸è¶³**ï¼š500æ ·æœ¬å­¦ä¹ 70ä¸ªç‰¹å¾æƒé‡ï¼Œè¿‡æ‹Ÿåˆé£é™©é«˜

### é¢„æœŸç»“æœ vs å®é™…
- **æ–‡çŒ®é¢„æœŸ** (Yu et al. 2023): ROC-AUC +0.010 åˆ° +0.030
- **å®é™…ç»“æœ**: ROC-AUC -0.0003
- **å·®è·**: **æœªè¾¾åˆ°é¢„æœŸï¼Œç‰¹å¾å®Œå…¨æ— æ•ˆ**

---

## ğŸ” é—®é¢˜è¯Šæ–­

### é—®é¢˜1: æ ‡æ³¨è´¨é‡å·® - åˆ†å¸ƒä¸¥é‡é›†ä¸­

#### æ•°æ®è¯æ®
ä» `artifacts/ground_truth_llama.csv` åˆ†æï¼ˆ500ä¸ªæ ·æœ¬ï¼‰ï¼š

| OCEANç»´åº¦ | ä¸»è¦å–å€¼ | Std | é—®é¢˜æè¿° |
|-----------|---------|-----|---------|
| **openness** | å‡ ä¹å…¨æ˜¯ 0.35 | 0.049 | âŒ æ— åŒºåˆ†åº¦ï¼Œ96%æ ·æœ¬ç›¸åŒ |
| **conscientiousness** | 0.85/0.55/0.45 | 0.241 | âš ï¸ åªæœ‰3ä¸ªå€¼ï¼Œè¿‡äºç¦»æ•£ |
| **extraversion** | 0.25/0.35 | 0.076 | âŒ åªæœ‰2ä¸ªä¸»è¦å€¼ |
| **agreeableness** | 0.45/0.55 | 0.100 | âš ï¸ åªæœ‰2ä¸ªä¸»è¦å€¼ |
| **neuroticism** | 0.15-0.7 | è¾ƒå¥½ | âœ“ ç›¸å¯¹è¾ƒå¥½ï¼Œä½†ä»ä¸å¤Ÿè¿ç»­ |

**æ ·æœ¬åˆ†å¸ƒç¤ºä¾‹**ï¼ˆå‰50è¡Œï¼‰ï¼š
```
openness_truth:
  0.35: 45æ¬¡  (90%)
  0.30: 3æ¬¡
  0.40: 2æ¬¡

conscientiousness_truth:
  0.85: 30æ¬¡  (60%)
  0.55: 10æ¬¡  (20%)
  0.45: 7æ¬¡   (14%)
```

#### ä¸ºä»€ä¹ˆè¿™æ˜¯è‡´å‘½é—®é¢˜ï¼Ÿ

**æŠ€æœ¯è§£é‡Š**ï¼š
```python
# Ridgeå›å½’å­¦ä¹ è¿‡ç¨‹
X = one_hot_encoded_features  # shape: (500, 70)
y = openness_truth            # shape: (500,)

# å¦‚æœyä¸­96%çš„å€¼éƒ½æ˜¯0.35
y = [0.35, 0.35, 0.35, 0.35, ..., 0.40, 0.35]

# Ridgeå›å½’ä¼šå­¦åˆ°ï¼š
# weight_all â‰ˆ 0.0  ï¼ˆæ‰€æœ‰ç‰¹å¾æƒé‡æ¥è¿‘0ï¼‰
# intercept â‰ˆ 0.35  ï¼ˆç›´æ¥é¢„æµ‹å‡å€¼ï¼‰

# ç»“æœï¼šOCEAN_score = 0.35 + 0.0Ã—features â‰ˆ 0.35ï¼ˆå¸¸æ•°ï¼‰
```

**ä¼ é€’åˆ°XGBoostçš„åæœ**ï¼š
- XGBoostæ¥æ”¶çš„OCEANç‰¹å¾å‡ ä¹æ˜¯å¸¸æ•°
- ä¿¡æ¯å¢ç›Š (Information Gain) â‰ˆ 0
- ç‰¹å¾è¢«å¿½ç•¥ï¼Œæ— æ³•æå‡é¢„æµ‹æ€§èƒ½

---

### é—®é¢˜2: Promptè®¾è®¡çš„æ ¹æœ¬ç¼ºé™·

#### å½“å‰Promptåˆ†æ
**ä½ç½®**: `text_features/ocean_llama_labeler.py:80-114`

**ç¼ºé™·1: èŒƒå›´æŒ‡å¯¼å¯¼è‡´èšé›†æ•ˆåº”**

```python
# å½“å‰promptçš„æŒ‡å¯¼
- openness:
  * Grade A/B + conservative â†’ 0.2-0.4
  * Grade F/G + risky â†’ 0.7-0.9
```

**é—®é¢˜**ï¼š
- å¤§éƒ¨åˆ†å€Ÿæ¬¾äººæ˜¯ **Grade C/D/E**ï¼ˆå 60-70%ï¼‰
- Promptæ²¡æœ‰ç»™C/D/Eçš„æ˜ç¡®æŒ‡å¯¼
- Llamaæ¨¡å‹é»˜è®¤ç»™ä¸­é—´å€¼ â†’ 0.35-0.45
- **ç»“æœï¼š80%æ ·æœ¬èšé›†åœ¨ 0.35 é™„è¿‘**

**ç¼ºé™·2: æ˜ å°„è§„åˆ™ä¸ç¬¦åˆå¿ƒç†å­¦ç†è®º**

```python
# å½“å‰promptçš„é”™è¯¯æ˜ å°„
- extraversion:
  * Social purposes (wedding, vacation) â†’ 0.6-0.8 (extroverted)
  * Private purposes (debt consolidation) â†’ 0.2-0.4 (introverted)
```

**å¿ƒç†å­¦é”™è¯¯**ï¼š
- âŒ **debt_consolidation â‰  introverted**
- å€ºåŠ¡æ•´åˆæ˜¯ç†è´¢è¡Œä¸ºï¼Œä¸ç¤¾äº¤æ€§æ— å…³
- çœŸæ­£çš„extraversionåº”è¯¥çœ‹ï¼š
  - Employment type (sales vs engineer)
  - Joint application (social cooperation)
  - Group activities (wedding, vacation)

**ä½†æ•°æ®ä¸­è¿™äº›ä¿¡å·å¾ˆå¼±**ï¼Œå¯¼è‡´æ¨¡å‹åªèƒ½ç»™é»˜è®¤å€¼

**ç¼ºé™·3: ç¼ºå°‘è¿ç»­æ€§æ€ç»´**

```python
# Promptç»™äº†Aå’ŒGçš„æŒ‡å¯¼ï¼Œä½†B/C/D/Eæ€ä¹ˆåŠï¼Ÿ
Grade A â†’ conscientiousness 0.7-0.9
Grade G â†’ conscientiousness 0.1-0.3
Grade C â†’ ???  # PromptæœªæåŠï¼Œæ¨¡å‹ç»™ 0.5
```

**Llamaçš„ä¿å®ˆç­–ç•¥**ï¼š
- ä¸ç¡®å®šæ—¶ç»™ä¸­é—´å€¼ (0.4-0.6)
- Temperature=0 åŠ å‰§ä¿å®ˆæ€§
- ç»“æœï¼šå¤§é‡æ ·æœ¬å †ç§¯åœ¨ 0.35, 0.45, 0.55

---

### é—®é¢˜3: ç‰¹å¾ç©ºé—´çš„ç»´åº¦è¯…å’’

#### æ•°æ®å¤æ‚åº¦åˆ†æ

**ç¼–ç å‰**ï¼š
```python
categorical_vars = [
    'grade', 'purpose', 'term', 'home_ownership',
    'emp_length', 'verification_status', 'application_type'
]
# 7-8ä¸ªå˜é‡
```

**ç¼–ç å (One-Hot)**ï¼š
```python
# grade: A,B,C,D,E,F,G â†’ 7 features
# purpose: 14ä¸ªç±»åˆ« â†’ 14 features
# term: 2ä¸ªç±»åˆ« â†’ 2 features
# emp_length: 11ä¸ªç±»åˆ« â†’ 11 features
# ...
# æ€»è®¡: ~70ä¸ªäºŒå€¼ç‰¹å¾
```

**æ ·æœ¬-ç‰¹å¾æ¯”ç‡**ï¼š
```
500 samples / 70 features â‰ˆ 7.1 samples per feature
```

#### ç»Ÿè®¡åæœ

**Ridgeå›å½’è¦æ±‚**ï¼š
- ç†æƒ³æ ·æœ¬-ç‰¹å¾æ¯”: **10:1 åˆ° 20:1**
- å½“å‰æ¯”ç‡: **7:1** âš ï¸ æ¥è¿‘ä¸‹é™

**æŸäº›ç±»åˆ«çš„æ ·æœ¬æå°‘**ï¼š
```python
purpose = 'wedding': 12 samples  (2.4%)
purpose = 'renewable_energy': 5 samples (1.0%)
emp_length = '< 1 year': 18 samples (3.6%)
```

**å­¦ä¹ è¿™äº›ç±»åˆ«çš„æƒé‡ â†’ å®Œå…¨ä¸å¯é **

#### è¿‡æ‹Ÿåˆé£é™©

```python
# æç«¯ä¾‹å­
category = 'purpose_wedding', 12 samples
å¦‚æœè¿™12ä¸ªæ ·æœ¬æ°å¥½æœ‰é«˜opennessæ ‡æ³¨ â†’ 0.75
Ridgeä¼šå­¦åˆ°: weight_wedding = +0.3

ä½†è¿™å¯èƒ½æ˜¯éšæœºå™ªå£°ï¼Œä¸æ˜¯çœŸå®æ¨¡å¼
åœ¨æµ‹è¯•é›†ä¸Šï¼šweddingçš„é¢„æµ‹ä¼šåé«˜ï¼ˆæ³›åŒ–å¤±è´¥ï¼‰
```

---

### é—®é¢˜4: OCEANä¸ä¿¡ç”¨é£é™©çš„ç†è®ºåŸºç¡€è–„å¼±

#### æ–‡çŒ®è¯æ® (Yu et al. 2023)

| OCEANç»´åº¦ | ä¸è¿çº¦çš„ç›¸å…³æ€§ | ç»Ÿè®¡æ˜¾è‘—æ€§ | å®é™…è´¡çŒ® |
|-----------|--------------|-----------|---------|
| **Conscientiousness** | **è´Ÿç›¸å…³** (r = -0.18) | âœ… p < 0.001 | **é«˜** |
| **Neuroticism** | **æ­£ç›¸å…³** (r = +0.12) | âœ… p < 0.01 | **ä¸­** |
| Openness | å¼±æ­£ç›¸å…³ (r = +0.04) | âš ï¸ p = 0.08 | ä½ |
| Extraversion | æ— å…³ (r = -0.01) | âŒ p = 0.72 | **æ— ** |
| Agreeableness | å¼±è´Ÿç›¸å…³ (r = -0.03) | âš ï¸ p = 0.15 | ä½ |

**ç»“è®º**ï¼š
- åªæœ‰ **2ä¸ªç»´åº¦** çœŸæ­£é‡è¦ï¼šConscientiousness, Neuroticism
- å…¶ä»–3ä¸ªç»´åº¦å¯¹ä¿¡ç”¨é£é™©é¢„æµ‹è´¡çŒ®å¾ˆå°
- **å½“å‰æ–¹æ³•èŠ±äº†åŒæ ·ç²¾åŠ›æ ‡æ³¨5ä¸ªç»´åº¦ â†’ æ•ˆç‡ä½ä¸‹**

---

## ğŸ› ï¸ æ”¹è¿›æ–¹æ¡ˆ

### æ–¹æ¡ˆA: Promptå·¥ç¨‹ + æ ·æœ¬é‡å¢åŠ ï¼ˆæ¸è¿›å¼ä¼˜åŒ–ï¼‰

#### A.1 é‡æ–°è®¾è®¡Prompt

**æ ¸å¿ƒæ”¹è¿›**ï¼š
1. âœ… æ·»åŠ å®Œæ•´çš„Big Fiveå­¦æœ¯å®šä¹‰ï¼ˆ6 facets per dimensionï¼‰
2. âœ… ä½¿ç”¨åˆ†ä½æ•°æ˜ å°„è¦†ç›–å…¨éƒ¨grade
3. âœ… å¼ºåˆ¶åˆ†å¸ƒçº¦æŸï¼ˆæä¾›3ä¸ªä¸åŒæ¡£æ¬¡çš„ä¾‹å­ï¼‰
4. âœ… ä¿®æ­£å¿ƒç†å­¦é”™è¯¯ï¼ˆextraversionçš„æ˜ å°„ï¼‰

**æ–°Promptè®¾è®¡**ï¼š

```python
def _build_prompt_v2(self, row: pd.Series) -> str:
    """
    ä¼˜åŒ–ç‰ˆPrompt - å¼ºåˆ¶å…¨èŒƒå›´åˆ†å¸ƒ
    """
    # æ„å»ºå€Ÿæ¬¾äººç”»åƒï¼ˆåŒä¹‹å‰ï¼‰
    profile = self._build_profile(row)

    prompt = f"""You are an expert psychologist specializing in Big Five personality assessment for credit risk modeling.

TASK: Rate this borrower on Big Five (OCEAN) traits using a 0.0-1.0 scale.

=== BORROWER PROFILE ===
{profile}

=== BIG FIVE DEFINITIONS (Based on Costa & McCrae) ===

1. **OPENNESS** - Imagination, Curiosity, Preference for Variety

   HIGH (0.70-0.90):
   - Unconventional loan purposes (small business, renewable energy)
   - Long-term self-employment (entrepreneurial)
   - Diverse credit usage patterns
   - Grade F/G + entrepreneurial purpose â†’ 0.75-0.85

   MODERATE (0.40-0.60):
   - Standard purposes (debt consolidation, car, home)
   - Mixed employment history
   - Grade C/D/E â†’ 0.45-0.55

   LOW (0.20-0.40):
   - Very conservative purposes (home improvement only)
   - Long-term traditional employment
   - Grade A/B + conservative purpose â†’ 0.25-0.35

2. **CONSCIENTIOUSNESS** - Organization, Responsibility, Self-Discipline

   HIGH (0.70-0.90):
   - Grade A/B (excellent credit history)
   - 10+ years employment
   - Owns home
   - Example: Grade A + 10+ years + OWN â†’ 0.78-0.88

   MODERATE (0.40-0.60):
   - Grade C/D (average responsibility)
   - 3-7 years employment
   - Mortgage or Rent
   - Example: Grade C + 5 years + MORTGAGE â†’ 0.48-0.58

   LOW (0.20-0.40):
   - Grade F/G (poor credit management)
   - <2 years employment
   - Renting
   - Example: Grade G + <1 year + RENT â†’ 0.22-0.32

3. **EXTRAVERSION** - Sociability, Assertiveness, Energy Level

   HIGH (0.65-0.85):
   - Social purposes: wedding, major_purchase (car for social mobility)
   - Joint applications (social cooperation)
   - Example: wedding + joint app â†’ 0.70-0.80

   MODERATE (0.40-0.60):
   - Neutral purposes: debt_consolidation, credit_card, medical
   - Individual applications
   - **DEFAULT FOR MOST CASES** â†’ 0.45-0.55

   LOW (0.25-0.45):
   - Very private purposes: medical (sensitive)
   - Long employment at same place (less social mobility)
   - Example: medical + 10+ years same job â†’ 0.30-0.40

4. **AGREEABLENESS** - Trust, Cooperation, Empathy

   HIGH (0.65-0.85):
   - Verified income (transparency, trust)
   - Joint application (cooperation)
   - Home ownership (community integration)
   - Example: Verified + Joint + OWN â†’ 0.70-0.80

   MODERATE (0.40-0.60):
   - Source Verified or Not Verified
   - Individual application
   - **DEFAULT FOR MOST CASES** â†’ 0.45-0.55

   LOW (0.25-0.45):
   - Not Verified income (defensive)
   - Rent (less community ties)
   - Example: Not Verified + RENT â†’ 0.35-0.45

5. **NEUROTICISM** - Anxiety, Emotional Instability, Stress Reactivity

   HIGH (0.65-0.90):
   - Grade F/G (financial stress history)
   - Short employment (<2 years, instability)
   - High DTI (financial pressure) - if available
   - Example: Grade G + <1 year â†’ 0.72-0.85

   MODERATE (0.40-0.60):
   - Grade C/D/E (moderate stress)
   - 3-7 years employment
   - Example: Grade D + 5 years â†’ 0.48-0.58

   LOW (0.20-0.40):
   - Grade A/B (financially stable)
   - 10+ years employment (life stability)
   - Owns home (low stress)
   - Example: Grade A + 10+ years + OWN â†’ 0.22-0.32

=== CRITICAL INSTRUCTIONS ===
1. **Use the ENTIRE 0.15-0.90 range** - Avoid clustering around 0.5
2. **Follow the grade-to-score mapping strictly**:
   - Grade A â†’ C: 0.75-0.85, N: 0.20-0.30
   - Grade B â†’ C: 0.65-0.75, N: 0.30-0.40
   - Grade C â†’ C: 0.55-0.65, N: 0.40-0.50
   - Grade D â†’ C: 0.45-0.55, N: 0.50-0.60
   - Grade E â†’ C: 0.35-0.45, N: 0.60-0.70
   - Grade F â†’ C: 0.25-0.35, N: 0.70-0.80
   - Grade G â†’ C: 0.20-0.30, N: 0.75-0.85

3. **Be DECISIVE**: Strong signals â†’ extreme scores (0.25 or 0.82), NOT 0.45
4. **When truly uncertain** (weak signals) â†’ use moderate values (0.45-0.55)
5. **Output ONLY JSON**, no explanation

=== EXAMPLE 1: Grade A Borrower (Strong positive signals) ===
{{"openness": 0.32, "conscientiousness": 0.81, "extraversion": 0.52, "agreeableness": 0.68, "neuroticism": 0.24}}

=== EXAMPLE 2: Grade C Borrower (Moderate signals) ===
{{"openness": 0.51, "conscientiousness": 0.58, "extraversion": 0.47, "agreeableness": 0.53, "neuroticism": 0.49}}

=== EXAMPLE 3: Grade G Borrower (Strong negative signals) ===
{{"openness": 0.76, "conscientiousness": 0.27, "extraversion": 0.48, "agreeableness": 0.42, "neuroticism": 0.79}}

=== YOUR TASK ===
Now rate this borrower following the above guidelines. Be decisive and use the full scale.
Output JSON only:"""

    return prompt
```

**å…³é”®æ”¹è¿›ç‚¹**ï¼š

| é—®é¢˜ | æ—§æ–¹æ¡ˆ | æ–°æ–¹æ¡ˆ |
|-----|--------|--------|
| Gradeè¦†ç›–ä¸å…¨ | åªç»™Aå’ŒG | ç»™å‡ºA-Gå…¨éƒ¨7ä¸ªç­‰çº§çš„æ˜ å°„ |
| ä¾‹å­å•ä¸€ | åªç»™1ä¸ªå¼ºä¿¡å·ä¾‹å­ | ç»™3ä¸ªä¾‹å­ï¼ˆé«˜/ä¸­/ä½æ¡£ï¼‰ |
| Extraversionæ˜ å°„é”™è¯¯ | debt â†’ introverted | debt â†’ neutral (0.45-0.55) |
| åˆ†æ•°èšé›† | å…è®¸ä¸­é—´å€¼ | æ˜ç¡®"Be DECISIVE", å¼ºä¿¡å·â†’æç«¯å€¼ |

---

#### A.2 åˆ†å±‚æŠ½æ ·ç­–ç•¥ä¼˜åŒ–

**é—®é¢˜**ï¼šå½“å‰500æ ·æœ¬å¯èƒ½gradeåˆ†å¸ƒä¸å‡

**æ”¹è¿›**ï¼šæŒ‰gradeåˆ†å±‚æŠ½æ ·

```python
def stratified_sampling_by_grade(df, total_samples=1000):
    """
    æŒ‰gradeå’ŒtargetåŒé‡åˆ†å±‚æŠ½æ ·
    ç¡®ä¿æ¯ä¸ªgradeæœ‰è¶³å¤Ÿæ ·æœ¬
    """
    # Gradeåˆ†å¸ƒç›®æ ‡ï¼ˆåŸºäºé‡è¦æ€§ï¼‰
    grade_targets = {
        'A': 180,  # å¤šé‡‡æ ·Aï¼ˆå­¦ä¹ é«˜conscientiousnessï¼‰
        'B': 180,
        'C': 160,
        'D': 160,
        'E': 140,
        'F': 100,  # å¤šé‡‡æ ·F/Gï¼ˆå­¦ä¹ ä½conscientiousnessï¼‰
        'G': 80,
    }

    samples = []
    for grade, n in grade_targets.items():
        df_grade = df[df['grade'] == grade]

        # åœ¨è¯¥gradeå†…æŒ‰targetåˆ†å±‚
        if 'target' in df_grade.columns:
            n_default = min(n // 2, (df_grade['target'] == 1).sum())
            n_paid = min(n // 2, (df_grade['target'] == 0).sum())

            samples.append(df_grade[df_grade['target'] == 1].sample(n_default, random_state=42))
            samples.append(df_grade[df_grade['target'] == 0].sample(n_paid, random_state=42))
        else:
            samples.append(df_grade.sample(min(n, len(df_grade)), random_state=42))

    return pd.concat(samples).sample(frac=1, random_state=42)

# ä½¿ç”¨
sample_df = stratified_sampling_by_grade(df, total_samples=1000)
```

**ä¼˜åŠ¿**ï¼š
- âœ… ç¡®ä¿æ¯ä¸ªgradeæœ‰è¶³å¤Ÿæ ·æœ¬ï¼ˆA: 180, G: 80ï¼‰
- âœ… åœ¨æ¯ä¸ªgradeå†…ä¿æŒdefault/non-defaultå¹³è¡¡
- âœ… æé«˜æç«¯caseï¼ˆAå’ŒGï¼‰çš„æƒé‡å­¦ä¹ ç¨³å®šæ€§

---

#### A.3 å°æ‰¹é‡éªŒè¯æµç¨‹ï¼ˆTest-Before-Scaleï¼‰

**ç›®çš„**ï¼šé¿å…æµªè´¹APIæˆæœ¬ï¼Œå…ˆéªŒè¯promptæœ‰æ•ˆæ€§

**æµç¨‹**ï¼š

```python
# Step 1: å°æ‰¹é‡æµ‹è¯•ï¼ˆ20ä¸ªæ ·æœ¬ï¼‰
test_sample = stratified_sampling_by_grade(df, total_samples=20)
labeler = OceanLlamaLabeler()
test_labels = labeler.label_batch(test_sample, sample_size=20, rate_limit_delay=0.5)

# Step 2: åˆ†å¸ƒéªŒè¯
def validate_distribution(df_labeled, min_std=0.15, min_unique=10):
    """
    éªŒè¯OCEANåˆ†å¸ƒæ˜¯å¦æ»¡è¶³è¦æ±‚
    """
    results = {}
    for dim in OCEAN_DIMS:
        col = f'{dim}_truth'
        std = df_labeled[col].std()
        unique = df_labeled[col].nunique()
        range_span = df_labeled[col].max() - df_labeled[col].min()

        passed = (std >= min_std) and (unique >= min_unique) and (range_span >= 0.4)

        results[dim] = {
            'std': std,
            'unique': unique,
            'range': (df_labeled[col].min(), df_labeled[col].max()),
            'passed': passed
        }

        print(f"{dim:20s}: std={std:.3f}, unique={unique:2d}, range={range_span:.2f} {'âœ…' if passed else 'âŒ'}")

    all_passed = all(r['passed'] for r in results.values())
    return all_passed, results

# Step 3: åˆ¤æ–­
passed, results = validate_distribution(test_labels)

if passed:
    print("\nâœ… åˆ†å¸ƒéªŒè¯é€šè¿‡ï¼Œå¯ä»¥è¿›è¡Œæ‰¹é‡æ ‡æ³¨")
else:
    print("\nâŒ åˆ†å¸ƒéªŒè¯å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–Prompt")
    print("å»ºè®®ï¼š")
    for dim, res in results.items():
        if not res['passed']:
            if res['std'] < 0.15:
                print(f"  - {dim}: æ ‡å‡†å·®å¤ªå°({res['std']:.3f})ï¼Œå¢å¼º'Be DECISIVE'æŒ‡ä»¤")
            if res['unique'] < 10:
                print(f"  - {dim}: å”¯ä¸€å€¼å¤ªå°‘({res['unique']})ï¼Œé¿å…å›ºå®šå€¼å»ºè®®")
```

**é¢„æœŸè¾“å‡º**ï¼š
```
openness            : std=0.187, unique=15, range=0.58 âœ…
conscientiousness   : std=0.242, unique=18, range=0.63 âœ…
extraversion        : std=0.156, unique=12, range=0.45 âœ…
agreeableness       : std=0.168, unique=13, range=0.48 âœ…
neuroticism         : std=0.238, unique=17, range=0.61 âœ…

âœ… åˆ†å¸ƒéªŒè¯é€šè¿‡ï¼Œå¯ä»¥è¿›è¡Œæ‰¹é‡æ ‡æ³¨
```

**å¦‚æœå¤±è´¥** â†’ å›åˆ°A.1ä¼˜åŒ–Promptï¼Œé‡æ–°æµ‹è¯•

---

#### A.4 æ‰¹é‡æ ‡æ³¨ï¼ˆæˆæœ¬ä¼˜åŒ–ï¼‰

**æˆæœ¬ä¼°ç®—**ï¼š

| æ ·æœ¬é‡ | APIè°ƒç”¨æ¬¡æ•° | æˆæœ¬ï¼ˆLlama 3.1 70Bï¼‰ | æ—¶é—´ |
|--------|------------|---------------------|------|
| 500 | 500 | ~$1.50 | 10åˆ†é’Ÿ |
| 1000 | 1000 | ~$3.00 | 20åˆ†é’Ÿ |
| 1500 | 1500 | ~$4.50 | 30åˆ†é’Ÿ |

**æ¨è**ï¼š1000ä¸ªæ ·æœ¬ï¼ˆå¹³è¡¡æˆæœ¬å’Œæ•ˆæœï¼‰

```python
# æ‰¹é‡æ ‡æ³¨
sample_df = stratified_sampling_by_grade(df, total_samples=1000)
labeler = OceanLlamaLabeler()  # ä½¿ç”¨ä¼˜åŒ–åçš„prompt
df_truth = labeler.label_batch(
    sample_df,
    sample_size=1000,
    stratified=False,  # å·²ç»åœ¨å¤–éƒ¨åˆ†å±‚
    rate_limit_delay=0.5
)

# ä¿å­˜
df_truth.to_csv('../artifacts/ground_truth_llama_v2.csv', index=False)
```

---

#### A.5 ä»£ç å®ç°ä½ç½®

**éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶**ï¼š
```
text_features/ocean_llama_labeler.py
  - Line 40-116: ä¿®æ”¹ _build_prompt() æ–¹æ³•
  - Line 196-263: ä¿®æ”¹ label_batch() ä½¿ç”¨æ–°çš„åˆ†å±‚æŠ½æ ·
```

**å®Œæ•´ä»£ç è§é™„å½•A**

---

### æ–¹æ¡ˆB: ç®€åŒ–æ–¹æ³•ï¼ˆåªå…³æ³¨æ ¸å¿ƒç»´åº¦ï¼‰

#### B.1 ç†è®ºä¾æ®

**æ–‡çŒ®è¯æ®**ï¼šåªæœ‰2ä¸ªç»´åº¦å¯¹ä¿¡ç”¨é£é™©æœ‰æ˜¾è‘—å½±å“
1. **Conscientiousness**: r = -0.18, p < 0.001 âœ…
2. **Neuroticism**: r = +0.12, p < 0.01 âœ…

**ä¼˜åŠ¿**ï¼š
- âœ… å‡å°‘æ ‡æ³¨å¤æ‚åº¦ï¼ˆ5ç»´â†’2ç»´ï¼‰
- âœ… é›†ä¸­ç²¾åŠ›æé«˜å…³é”®ç»´åº¦çš„è´¨é‡
- âœ… 500æ ·æœ¬è¶³å¤Ÿå­¦ä¹ 2ä¸ªç»´åº¦ï¼ˆ250 samples per dimensionï¼‰
- âœ… Promptæ›´ç®€æ´ï¼Œæ¨¡å‹ç†è§£æ›´å‡†ç¡®

---

#### B.2 ç®€åŒ–Promptè®¾è®¡

```python
def _build_prompt_simplified(self, row: pd.Series) -> str:
    """
    ç®€åŒ–ç‰ˆPrompt - åªæ ‡æ³¨2ä¸ªæ ¸å¿ƒç»´åº¦
    """
    profile = self._build_profile(row)

    prompt = f"""You are an expert psychologist assessing personality traits for credit risk prediction.

TASK: Rate this borrower on TWO key personality dimensions using 0.0-1.0 scale.

=== BORROWER PROFILE ===
{profile}

=== DIMENSION 1: CONSCIENTIOUSNESS ===
Measures: Responsibility, organization, self-discipline, planning ability

HIGH (0.70-0.90): Responsible, organized, plans ahead
- Grade A/B
- 10+ years employment
- Owns home
- Short-term loan (36 months, more cautious)
â†’ Example: Grade A + 10+ years + OWN â†’ 0.78-0.86

MODERATE (0.40-0.60): Average responsibility
- Grade C/D/E
- 3-7 years employment
- Rents or Mortgage
â†’ Example: Grade D + 5 years + RENT â†’ 0.46-0.56

LOW (0.20-0.40): Less organized, spontaneous
- Grade F/G
- <2 years employment
- Renting
- Long-term loan (60 months, less planning)
â†’ Example: Grade G + <1 year + RENT â†’ 0.24-0.34

=== DIMENSION 2: NEUROTICISM ===
Measures: Anxiety, emotional instability, stress reactivity, impulse control

HIGH (0.65-0.90): Anxious, emotionally unstable, poor impulse control
- Grade F/G (history of financial stress)
- Short/unstable employment
- High-risk choices (long-term loans with bad credit)
â†’ Example: Grade G + <1 year â†’ 0.72-0.84

MODERATE (0.40-0.60): Average emotional stability
- Grade C/D/E
- Moderate employment stability
â†’ Example: Grade D + 5 years â†’ 0.48-0.58

LOW (0.20-0.40): Calm, emotionally stable, good impulse control
- Grade A/B (financially stable)
- 10+ years employment
- Conservative choices
â†’ Example: Grade A + 10+ years â†’ 0.22-0.34

=== MAPPING RULES ===
Use this grade-to-score mapping as a baseline:

| Grade | Conscientiousness | Neuroticism |
|-------|------------------|-------------|
| A     | 0.78-0.86        | 0.20-0.28   |
| B     | 0.68-0.76        | 0.30-0.38   |
| C     | 0.58-0.66        | 0.40-0.48   |
| D     | 0.48-0.56        | 0.50-0.58   |
| E     | 0.38-0.46        | 0.60-0.68   |
| F     | 0.28-0.36        | 0.70-0.78   |
| G     | 0.22-0.30        | 0.76-0.84   |

Adjust within the range based on employment length and home ownership:
- +0.04 if 10+ years employment
- +0.03 if owns home
- -0.03 if <2 years employment
- -0.02 if renting

=== CRITICAL INSTRUCTIONS ===
1. Follow the grade mapping strictly
2. Use the full 0.2-0.9 range
3. Be decisive - avoid defaulting to 0.5
4. Output ONLY JSON with 2 dimensions

=== EXAMPLES ===
Grade A, 10+ years, OWN:
{{"conscientiousness": 0.84, "neuroticism": 0.23}}

Grade D, 5 years, RENT:
{{"conscientiousness": 0.51, "neuroticism": 0.54}}

Grade G, <1 year, RENT:
{{"conscientiousness": 0.26, "neuroticism": 0.79}}

Now rate this borrower. Output JSON only:"""

    return prompt
```

**å…³é”®ç‰¹ç‚¹**ï¼š
1. âœ… åªå…³æ³¨2ä¸ªç»´åº¦ï¼Œå‡å°‘å¤æ‚åº¦
2. âœ… æä¾›æ˜ç¡®çš„grade-to-scoreæ˜ å°„è¡¨
3. âœ… ç»™å‡ºè°ƒæ•´è§„åˆ™ï¼ˆemployment, home ownershipï¼‰
4. âœ… æ›´å®¹æ˜“è®©æ¨¡å‹ç†è§£å’Œæ‰§è¡Œ

---

#### B.3 å®ç°å˜æ›´

**éœ€è¦ä¿®æ”¹**ï¼š
```python
# ocean_llama_labeler.py
OCEAN_DIMS = ["conscientiousness", "neuroticism"]  # ä»5ä¸ªå‡å°‘åˆ°2ä¸ª

# LlamaOceanPipeline.ipynb
# æ‰€æœ‰ç”¨åˆ°OCEAN_DIMSçš„åœ°æ–¹è‡ªåŠ¨æ›´æ–°
```

**Ridgeå›å½’**ï¼š
```python
# å­¦ä¹ 2ä¸ªç»´åº¦çš„æƒé‡
for dim in ['conscientiousness', 'neuroticism']:
    model = Ridge(alpha=0.1, random_state=42)
    model.fit(X_encoded, sample_df[f'{dim}_truth'])
    weights[dim] = {...}
```

**XGBoostæ¨¡å‹**ï¼š
```python
# Baseline + 2 OCEAN features (instead of 5)
baseline_features = [...]  # 19ä¸ªç‰¹å¾
ocean_features = ['conscientiousness', 'neuroticism']  # 2ä¸ªç‰¹å¾
# Total: 21 features
```

---

#### B.4 é¢„æœŸæ•ˆæœ

**ä¸ºä»€ä¹ˆå¯èƒ½æ›´å¥½**ï¼š

1. **æ ‡æ³¨è´¨é‡æå‡**ï¼š
   - 2ä¸ªç»´åº¦ â†’ Promptæ›´ç®€æ´ â†’ Llamaç†è§£æ›´å‡†ç¡®
   - æ˜ç¡®çš„æ˜ å°„è¡¨ â†’ å‡å°‘éšæœºæ€§

2. **ç»Ÿè®¡æ•ˆç‡æå‡**ï¼š
   - 500æ ·æœ¬å­¦ä¹ 2ä¸ªç»´åº¦ â†’ 250 samples/dimension
   - vs æ–¹æ¡ˆA: 1000æ ·æœ¬å­¦ä¹ 5ä¸ªç»´åº¦ â†’ 200 samples/dimension
   - **æ›´é«˜çš„æ ·æœ¬-ç»´åº¦æ¯” â†’ æ›´ç¨³å®šçš„æƒé‡**

3. **ä¿¡å·å™ªå£°æ¯”æå‡**ï¼š
   - åªä½¿ç”¨çœŸæ­£é‡è¦çš„ç»´åº¦ â†’ å‡å°‘å™ªå£°
   - æ–‡çŒ®è¯æ˜è¿™2ä¸ªç»´åº¦æœ‰æ˜¾è‘—æ•ˆæœ â†’ æå‡å¯èƒ½æ€§é«˜

**é¢„æœŸROC-AUCæå‡**ï¼š+0.008 åˆ° +0.015

---

### æ–¹æ¡ˆC: å®Œå…¨é‡æ„ï¼ˆBehavioral Scoresï¼‰

#### C.1 åŠ¨æœºï¼šæ”¾å¼ƒOCEANæ¡†æ¶

**æ ¹æœ¬é—®é¢˜**ï¼š
- å€Ÿè´·æ•°æ®çš„categoricalç‰¹å¾ä¿¡æ¯å¤ªå°‘
- æ— æ³•å‡†ç¡®æ¨æ–­Big Five personality
- **ä¸ºä»€ä¹ˆä¸ç›´æ¥ä»æ•°æ®ä¸­å­¦ä¹ è¡Œä¸ºç‰¹å¾ï¼Ÿ**

**æ–°æ€è·¯**ï¼š
- ä¸ç”¨å¿ƒç†å­¦æ¦‚å¿µï¼ˆOCEANï¼‰
- åˆ›å»º"Financial Behavior Scores"
- ç›´æ¥ä»å†å²è¿çº¦æ•°æ®å­¦ä¹ 

---

#### C.2 Behavioral Scoresè®¾è®¡

**Score 1: Financial Discipline Score**
- **å®šä¹‰**ï¼šè´¢åŠ¡ç®¡ç†èƒ½åŠ›å’Œè´£ä»»æ„Ÿ
- **åŸºäºç‰¹å¾**ï¼šgrade, delinq_2yrs, pub_rec
- **å­¦ä¹ æ–¹æ³•**ï¼šTarget Encoding

```python
from category_encoders import TargetEncoder

# Target Encoding: ç”¨è¿çº¦ç‡ç¼–ç ç±»åˆ«å˜é‡
encoder = TargetEncoder()
df['financial_discipline_score'] = encoder.fit_transform(df['grade'], df['target'])

# ç»“æœï¼š
# Grade A â†’ 0.073 (7.3% default rate, ä½é£é™© â†’ é«˜discipline)
# Grade G â†’ 0.403 (40.3% default rate, é«˜é£é™© â†’ ä½discipline)

# åè½¬ä¸ºæ­£å‘åˆ†æ•°
df['financial_discipline_score'] = 1 - df['financial_discipline_score']
# Grade A â†’ 0.927 (é«˜discipline)
# Grade G â†’ 0.597 (ä½discipline)
```

**Score 2: Risk-Taking Score**
- **å®šä¹‰**ï¼šæ„¿æ„æ‰¿æ‹…é£é™©çš„ç¨‹åº¦
- **åŸºäºç‰¹å¾**ï¼šloan_amnt, term, purpose
- **å­¦ä¹ æ–¹æ³•**ï¼šç»„åˆå¤šä¸ªTarget Encoding

```python
# Loan amounté£é™©ï¼ˆç›¸å¯¹äºæ”¶å…¥ï¼‰
df['loan_to_income_ratio'] = df['loan_amnt'] / df['annual_inc']

# Purposeé£é™©
purpose_risk = encoder.fit_transform(df['purpose'], df['target'])
df['purpose_risk_score'] = purpose_risk

# Termé£é™©ï¼ˆ60 months > 36 monthsï¼‰
df['term_risk_score'] = df['term'].map({' 36 months': 0.4, ' 60 months': 0.6})

# ç»¼åˆRisk-Taking Score
df['risk_taking_score'] = (
    0.4 * df['loan_to_income_ratio'].clip(0, 2) / 2 +  # normalized
    0.4 * df['purpose_risk_score'] +
    0.2 * df['term_risk_score']
)
```

**Score 3: Stability Score**
- **å®šä¹‰**ï¼šç”Ÿæ´»å’ŒèŒä¸šç¨³å®šæ€§
- **åŸºäºç‰¹å¾**ï¼šemp_length, home_ownership, inq_last_6mths

```python
# Employment stability
emp_stability = df['emp_length'].map({
    '< 1 year': 0.1, '1 year': 0.2, '2 years': 0.3,
    '3 years': 0.4, '4 years': 0.5, '5 years': 0.6,
    '6 years': 0.65, '7 years': 0.7, '8 years': 0.75,
    '9 years': 0.8, '10+ years': 0.9
})

# Home stability
home_stability = df['home_ownership'].map({
    'RENT': 0.3, 'MORTGAGE': 0.6, 'OWN': 0.9, 'OTHER': 0.5
})

# Credit inquiry stability (fewer inquiries = more stable)
inquiry_stability = 1 - (df['inq_last_6mths'].clip(0, 5) / 5)

# ç»¼åˆStability Score
df['stability_score'] = (
    0.5 * emp_stability +
    0.3 * home_stability +
    0.2 * inquiry_stability
)
```

---

#### C.3 å®Œæ•´å®ç°

```python
import pandas as pd
from category_encoders import TargetEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score

# ========== Behavioral Scoresåˆ›å»º ==========
def create_behavioral_scores(df):
    """
    åˆ›å»º3ä¸ªè¡Œä¸ºåˆ†æ•°ç‰¹å¾
    """
    # 1. Financial Discipline Score
    encoder_grade = TargetEncoder()
    grade_default_rate = encoder_grade.fit_transform(df['grade'], df['target'])
    df['financial_discipline_score'] = 1 - grade_default_rate

    # 2. Risk-Taking Score
    encoder_purpose = TargetEncoder()
    purpose_risk = encoder_purpose.fit_transform(df['purpose'], df['target'])

    df['loan_to_income_ratio'] = (df['loan_amnt'] / df['annual_inc']).clip(0, 2)
    df['term_risk'] = df['term'].map({' 36 months': 0.4, ' 60 months': 0.6})

    df['risk_taking_score'] = (
        0.4 * (df['loan_to_income_ratio'] / 2) +
        0.4 * purpose_risk +
        0.2 * df['term_risk']
    )

    # 3. Stability Score
    emp_map = {
        '< 1 year': 0.1, '1 year': 0.2, '2 years': 0.3,
        '3 years': 0.4, '4 years': 0.5, '5 years': 0.6,
        '6 years': 0.65, '7 years': 0.7, '8 years': 0.75,
        '9 years': 0.8, '10+ years': 0.9
    }
    home_map = {'RENT': 0.3, 'MORTGAGE': 0.6, 'OWN': 0.9, 'OTHER': 0.5}

    df['emp_stability'] = df['emp_length'].map(emp_map).fillna(0.5)
    df['home_stability'] = df['home_ownership'].map(home_map).fillna(0.5)
    df['inquiry_stability'] = 1 - (df['inq_last_6mths'].clip(0, 5) / 5)

    df['stability_score'] = (
        0.5 * df['emp_stability'] +
        0.3 * df['home_stability'] +
        0.2 * df['inquiry_stability']
    )

    return df

# ========== åº”ç”¨åˆ°æ•°æ® ==========
df = create_behavioral_scores(df)

# ========== ç‰¹å¾å®šä¹‰ ==========
baseline_features = [
    "loan_amnt", "int_rate", "installment", "annual_inc", "dti",
    "inq_last_6mths", "open_acc", "pub_rec", "revol_bal", "revol_util",
    "total_acc", "grade", "purpose", "term", "home_ownership",
    "emp_length", "verification_status", "application_type"
]

behavioral_features = [
    'financial_discipline_score',
    'risk_taking_score',
    'stability_score'
]

# ========== A/Bå¯¹æ¯” ==========
X_train, X_test, y_train, y_test = train_test_split(
    df, df['target'], test_size=0.2, random_state=42, stratify=df['target']
)

# Model A: Baseline only
model_A = XGBClassifier(n_estimators=300, max_depth=6, random_state=42)
model_A.fit(X_train[baseline_features], y_train)
y_proba_A = model_A.predict_proba(X_test[baseline_features])[:, 1]

# Model C: Baseline + Behavioral Scores
model_C = XGBClassifier(n_estimators=300, max_depth=6, random_state=42)
model_C.fit(X_train[baseline_features + behavioral_features], y_train)
y_proba_C = model_C.predict_proba(X_test[baseline_features + behavioral_features])[:, 1]

# è¯„ä¼°
print(f"Model A (Baseline):      ROC-AUC = {roc_auc_score(y_test, y_proba_A):.4f}")
print(f"Model C (+Behavioral):   ROC-AUC = {roc_auc_score(y_test, y_proba_C):.4f}")
print(f"Improvement:             Î” = {roc_auc_score(y_test, y_proba_C) - roc_auc_score(y_test, y_proba_A):+.4f}")
```

---

#### C.4 ä¼˜ç¼ºç‚¹åˆ†æ

**ä¼˜åŠ¿**ï¼š
- âœ… **æ— éœ€APIæˆæœ¬**ï¼ˆä¸ç”¨GenAIæ ‡æ³¨ï¼‰
- âœ… **æ— æ ‡æ³¨è´¨é‡é—®é¢˜**ï¼ˆç›´æ¥ä»æ•°æ®å­¦ä¹ ï¼‰
- âœ… **æ›´ç›´æ¥**ï¼ˆä¸ç»•å¼¯å­ç”¨å¿ƒç†å­¦ç†è®ºï¼‰
- âœ… **å¯è§£é‡Šæ€§å¼º**ï¼š
  - Financial Discipline = 1 - è¿çº¦ç‡ï¼ˆç›´è§‚ï¼‰
  - Risk-Taking = è´·æ¬¾é£é™©ç»„åˆï¼ˆå¯ç†è§£ï¼‰
  - Stability = ç”Ÿæ´»ç¨³å®šæ€§ï¼ˆåˆç†ï¼‰
- âœ… **å®æ–½å¿«**ï¼ˆ1å°æ—¶å†…å®Œæˆï¼‰

**åŠ£åŠ¿**ï¼š
- âŒ **ç¼ºå°‘å­¦æœ¯æ–°é¢–æ€§**ï¼ˆä¸æ˜¯Big Fiveç ”ç©¶ï¼‰
- âŒ **Target Leakageé£é™©**ï¼š
  - ç”¨targetç¼–ç ç‰¹å¾ â†’ å¯èƒ½è¿‡æ‹Ÿåˆ
  - éœ€è¦ç”¨CVé˜²æ­¢leakage
- âŒ **å¯èƒ½ä¸baselineé‡å¤**ï¼š
  - gradeå·²ç»åœ¨baselineä¸­ â†’ financial_disciplineå¯èƒ½å†—ä½™

**é€‚ç”¨åœºæ™¯**ï¼š
- å¦‚æœç›®æ ‡æ˜¯**å®é™…ä¸šåŠ¡æ•ˆæœ** â†’ æ¨èæ–¹æ¡ˆC
- å¦‚æœç›®æ ‡æ˜¯**å­¦æœ¯ç ”ç©¶/è®ºæ–‡** â†’ æ¨èæ–¹æ¡ˆAæˆ–B

---

## ğŸ“‹ æ¨èè¡ŒåŠ¨è·¯å¾„

### çŸ­æœŸï¼ˆ2-3å¤©ï¼‰

#### Phase 1: å¿«é€ŸéªŒè¯ï¼ˆ4å°æ—¶ï¼‰

1. **å®æ–½æ–¹æ¡ˆC**ï¼ˆBehavioral Scoresï¼‰
   - â±ï¸ 1å°æ—¶ï¼šç¼–å†™ä»£ç 
   - â±ï¸ 1å°æ—¶ï¼šè¿è¡ŒA/Bæµ‹è¯•
   - â±ï¸ 1å°æ—¶ï¼šåˆ†æç»“æœ
   - âœ… ä¼˜åŠ¿ï¼šæ— APIæˆæœ¬ï¼Œå¿«é€ŸéªŒè¯æ˜¯å¦æœ‰æå‡ç©ºé—´

2. **å¦‚æœæ–¹æ¡ˆCæœ‰æ•ˆ**ï¼ˆROC-AUC +0.005ä»¥ä¸Šï¼‰
   - â†’ è¯´æ˜æœ‰"personality-like"ç‰¹å¾çš„æå‡æ½œåŠ›
   - â†’ ç»§ç»­Phase 2ä¼˜åŒ–OCEANæ–¹æ³•

3. **å¦‚æœæ–¹æ¡ˆCæ— æ•ˆ**ï¼ˆROC-AUCæå‡<0.005ï¼‰
   - â†’ è¯´æ˜categoricalç‰¹å¾ä¿¡æ¯ä¸è¶³
   - â†’ è€ƒè™‘æ”¾å¼ƒpersonalityæ–¹å‘ï¼Œè½¬å‘å…¶ä»–ç‰¹å¾å·¥ç¨‹

#### Phase 2: OCEANä¼˜åŒ–ï¼ˆ1-2å¤©ï¼‰

**å¦‚æœPhase 1éªŒè¯æœ‰æ½œåŠ›ï¼Œæ‰§è¡Œä»¥ä¸‹æ­¥éª¤**ï¼š

1. **å®æ–½æ–¹æ¡ˆB**ï¼ˆç®€åŒ–åˆ°2ä¸ªç»´åº¦ï¼‰
   - â±ï¸ 2å°æ—¶ï¼šä¿®æ”¹promptï¼ˆ`ocean_llama_labeler.py`ï¼‰
   - â±ï¸ 0.5å°æ—¶ï¼šå°æ‰¹é‡æµ‹è¯•ï¼ˆ20ä¸ªæ ·æœ¬ï¼Œ$0.10ï¼‰
   - â±ï¸ éªŒè¯åˆ†å¸ƒè´¨é‡

2. **å¦‚æœæµ‹è¯•é€šè¿‡**ï¼š
   - â±ï¸ 1å°æ—¶ï¼šæ‰¹é‡æ ‡æ³¨1000ä¸ªæ ·æœ¬ï¼ˆ$3.00ï¼‰
   - â±ï¸ 1å°æ—¶ï¼šé‡æ–°è®­ç»ƒRidge + XGBoost
   - â±ï¸ 1å°æ—¶ï¼šè¯„ä¼°å’Œåˆ†æ

3. **å¦‚æœæµ‹è¯•å¤±è´¥**ï¼š
   - â†’ å®æ–½æ–¹æ¡ˆAï¼ˆ5ä¸ªç»´åº¦ï¼Œå®Œæ•´promptï¼‰
   - â†’ é‡å¤æµ‹è¯•-æ ‡æ³¨æµç¨‹

---

### ä¸­æœŸï¼ˆ1å‘¨ï¼‰

#### Phase 3: æ·±åº¦ä¼˜åŒ–

**å¦‚æœæ–¹æ¡ˆBæœ‰æ•ˆä½†æå‡ä¸å¤Ÿ**ï¼š

1. **å¢åŠ æ ·æœ¬é‡**ï¼ˆ1000 â†’ 1500ï¼‰
2. **ä¼˜åŒ–Ridgeè¶…å‚æ•°**ï¼š
   ```python
   from sklearn.model_selection import GridSearchCV

   param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0]}
   grid = GridSearchCV(Ridge(), param_grid, cv=5)
   grid.fit(X_encoded, y_ocean_truth)
   ```
3. **å°è¯•Elastic Net**ï¼ˆç»“åˆL1+L2æ­£åˆ™åŒ–ï¼‰

**å¦‚æœä»æ— æ•ˆ**ï¼š
- è€ƒè™‘æ¢æ¨¡å‹ï¼šLlama â†’ GPT-4
- æˆæœ¬ï¼š$5-10ï¼ˆ1000 samples Ã— $0.005ï¼‰

---

### é•¿æœŸï¼ˆæœªæ¥å·¥ä½œï¼‰

#### Phase 4: é«˜çº§æ–¹æ³•

1. **æ”¶é›†æ–‡æœ¬æ•°æ®**ï¼š
   - `loan_title` (å·²æœ‰ï¼Œä½†æœªä½¿ç”¨)
   - `emp_title` (èŒä¸šåç§°ï¼Œå¯èƒ½åæ˜ personality)
   - ç”¨NLPæ–¹æ³•ï¼ˆBERT embeddingï¼‰æå–çœŸå®è¯­è¨€ç‰¹å¾

2. **å¤šæ¨¡æ€èåˆ**ï¼š
   - Structured features (å½“å‰æ–¹æ³•)
   - Text features (NLP)
   - Behavioral sequences (å¦‚æœæœ‰æ—¶é—´åºåˆ—æ•°æ®)

3. **æ·±åº¦å­¦ä¹ **ï¼š
   - ç”¨ç¥ç»ç½‘ç»œç›´æ¥å­¦ä¹ personality representation
   - ä¸éœ€è¦æ˜¾å¼OCEANåˆ†æ•°

---

## ğŸ“Š å†³ç­–æ ‘

```
å¼€å§‹
  â†“
Phase 1: å®æ–½æ–¹æ¡ˆC (Behavioral Scores)
  â†“
ROC-AUCæå‡ > 0.005?
  â”œâ”€ YES â†’ è¯´æ˜æœ‰æ½œåŠ›
  â”‚         â†“
  â”‚     Phase 2: å®æ–½æ–¹æ¡ˆB (2ç»´OCEAN)
  â”‚         â†“
  â”‚     å°æ‰¹é‡æµ‹è¯•é€šè¿‡?
  â”‚         â”œâ”€ YES â†’ æ‰¹é‡æ ‡æ³¨ â†’ è¯„ä¼°
  â”‚         â”‚         â†“
  â”‚         â”‚     æå‡ > 0.010?
  â”‚         â”‚         â”œâ”€ YES â†’ âœ… æˆåŠŸï¼Œé¡¹ç›®å®Œæˆ
  â”‚         â”‚         â””â”€ NO â†’ Phase 3: æ·±åº¦ä¼˜åŒ–
  â”‚         â”‚
  â”‚         â””â”€ NO â†’ å®æ–½æ–¹æ¡ˆA (5ç»´OCEAN) â†’ é‡å¤æµ‹è¯•
  â”‚
  â””â”€ NO â†’ categoricalç‰¹å¾ä¿¡æ¯ä¸è¶³
            â†“
        å»ºè®®ï¼š
        1. æ”¾å¼ƒpersonalityæ–¹å‘
        2. æ¢ç´¢å…¶ä»–ç‰¹å¾å·¥ç¨‹
        3. æ”¶é›†æ–‡æœ¬æ•°æ®ï¼ˆé•¿æœŸï¼‰
```

---

## ğŸ’° æˆæœ¬ä¼°ç®—

| æ–¹æ¡ˆ | APIè°ƒç”¨ | æˆæœ¬ | æ—¶é—´ | æˆåŠŸæ¦‚ç‡ |
|------|---------|------|------|---------|
| **æ–¹æ¡ˆC** (Behavioral) | 0 | $0 | 4å°æ—¶ | 60% |
| **æ–¹æ¡ˆB** (2ç»´OCEAN) | 1020 | ~$3 | 8å°æ—¶ | 70% |
| **æ–¹æ¡ˆA** (5ç»´OCEAN) | 1020 | ~$3 | 12å°æ—¶ | 60% |
| **æ–¹æ¡ˆAå¢å¼º** (1500æ ·æœ¬) | 1520 | ~$4.5 | 15å°æ—¶ | 75% |
| **æ¢GPT-4** | 1020 | ~$10 | 8å°æ—¶ | 80% |

**æ¨èæŠ•å…¥**ï¼š
- **æœ€ä½æˆæœ¬è·¯å¾„**ï¼šæ–¹æ¡ˆC ($0) â†’ æ–¹æ¡ˆB ($3) = **$3æ€»è®¡**
- **æœ€é«˜æˆåŠŸç‡è·¯å¾„**ï¼šæ–¹æ¡ˆC ($0) â†’ æ–¹æ¡ˆB ($3) â†’ æ¢GPT-4 ($10) = **$13æ€»è®¡**

---

## âœ… éªŒè¯æ£€æŸ¥æ¸…å•

### æ ‡æ³¨è´¨é‡æ£€æŸ¥

```python
def quality_check(df_labeled):
    """
    æ ‡æ³¨è´¨é‡æ£€æŸ¥æ¸…å•
    """
    checks = {
        'std_check': {},
        'range_check': {},
        'unique_check': {},
        'correlation_check': {}
    }

    for dim in OCEAN_DIMS:
        col = f'{dim}_truth'

        # 1. æ ‡å‡†å·®æ£€æŸ¥ï¼ˆæœŸæœ› > 0.15ï¼‰
        std = df_labeled[col].std()
        checks['std_check'][dim] = {
            'value': std,
            'passed': std >= 0.15,
            'target': 0.15
        }

        # 2. èŒƒå›´æ£€æŸ¥ï¼ˆæœŸæœ›è·¨åº¦ > 0.4ï¼‰
        range_span = df_labeled[col].max() - df_labeled[col].min()
        checks['range_check'][dim] = {
            'value': range_span,
            'passed': range_span >= 0.4,
            'target': 0.4
        }

        # 3. å”¯ä¸€å€¼æ£€æŸ¥ï¼ˆæœŸæœ› > 20ï¼‰
        unique = df_labeled[col].nunique()
        checks['unique_check'][dim] = {
            'value': unique,
            'passed': unique >= 20,
            'target': 20
        }

        # 4. ä¸targetç›¸å…³æ€§æ£€æŸ¥ï¼ˆæœŸæœ› |r| > 0.05ï¼‰
        if 'target' in df_labeled.columns:
            corr = df_labeled[col].corr(df_labeled['target'])
            checks['correlation_check'][dim] = {
                'value': corr,
                'passed': abs(corr) >= 0.05,
                'target': 0.05
            }

    return checks

# ä½¿ç”¨
checks = quality_check(df_truth)

# æ‰“å°æŠ¥å‘Š
print("=== æ ‡æ³¨è´¨é‡æ£€æŸ¥æŠ¥å‘Š ===\n")
for check_type, results in checks.items():
    print(f"{check_type}:")
    for dim, result in results.items():
        status = "âœ…" if result['passed'] else "âŒ"
        print(f"  {dim:20s}: {result['value']:.3f} (target: {result['target']}) {status}")
    print()
```

### æ¨¡å‹æ€§èƒ½æ£€æŸ¥

```python
def model_performance_check(y_test, y_proba_A, y_proba_B):
    """
    æ¨¡å‹æ€§èƒ½æå‡æ£€æŸ¥
    """
    from sklearn.metrics import roc_auc_score, average_precision_score
    from scipy.stats import ttest_rel

    roc_A = roc_auc_score(y_test, y_proba_A)
    roc_B = roc_auc_score(y_test, y_proba_B)
    pr_A = average_precision_score(y_test, y_proba_A)
    pr_B = average_precision_score(y_test, y_proba_B)

    # Bootstrapç½®ä¿¡åŒºé—´
    from sklearn.utils import resample
    n_iterations = 1000
    roc_diffs = []

    for _ in range(n_iterations):
        indices = resample(range(len(y_test)), random_state=_)
        y_boot = y_test.iloc[indices]
        roc_diff = roc_auc_score(y_boot, y_proba_B[indices]) - roc_auc_score(y_boot, y_proba_A[indices])
        roc_diffs.append(roc_diff)

    ci_lower = np.percentile(roc_diffs, 2.5)
    ci_upper = np.percentile(roc_diffs, 97.5)

    print("=== æ¨¡å‹æ€§èƒ½å¯¹æ¯” ===\n")
    print(f"ROC-AUC:")
    print(f"  Baseline:     {roc_A:.4f}")
    print(f"  +OCEAN:       {roc_B:.4f}")
    print(f"  Improvement:  {roc_B - roc_A:+.4f}")
    print(f"  95% CI:       [{ci_lower:+.4f}, {ci_upper:+.4f}]")
    print(f"  Significant:  {'âœ… YES' if ci_lower > 0 else 'âŒ NO'}")
    print()
    print(f"PR-AUC:")
    print(f"  Baseline:     {pr_A:.4f}")
    print(f"  +OCEAN:       {pr_B:.4f}")
    print(f"  Improvement:  {pr_B - pr_A:+.4f}")
```

---

## ğŸ“ é™„å½•

### é™„å½•A: å®Œæ•´ä»£ç å®ç°ï¼ˆæ–¹æ¡ˆBï¼‰

**æ–‡ä»¶**: `text_features/ocean_llama_labeler_v2.py`

```python
"""
OCEAN äººæ ¼ç‰¹å¾æ ‡æ³¨å™¨ - ç®€åŒ–ç‰ˆ
åªæ ‡æ³¨2ä¸ªæ ¸å¿ƒç»´åº¦ï¼šConscientiousness, Neuroticism
"""
import sys
sys.path.append('..')

import pandas as pd
import numpy as np
import json
import time
from typing import Dict, List
from utils.llama_client import LlamaClient

# ç®€åŒ–ä¸º2ä¸ªæ ¸å¿ƒç»´åº¦
OCEAN_DIMS = ["conscientiousness", "neuroticism"]


class OceanLlamaLabelerV2:
    """
    ç®€åŒ–ç‰ˆOCEANæ ‡æ³¨å™¨ - åªæ ‡æ³¨conscientiousnesså’Œneuroticism
    """

    def __init__(self, hf_token: str = None):
        self.client = LlamaClient(hf_token)
        self.stats = {
            "total": 0,
            "success": 0,
            "failed": 0,
            "parse_errors": 0
        }

    def _build_prompt(self, row: pd.Series) -> str:
        """
        æ„å»ºç®€åŒ–ç‰ˆPromptï¼ˆåªæœ‰2ä¸ªç»´åº¦ï¼‰
        """
        # æ„å»ºå€Ÿæ¬¾äººç”»åƒ
        profile_parts = []

        if 'purpose' in row and pd.notna(row['purpose']):
            profile_parts.append(f"- Loan Purpose: {row['purpose']}")

        if 'grade' in row and pd.notna(row['grade']):
            grade_str = f"{row['grade']}"
            if 'sub_grade' in row and pd.notna(row['sub_grade']):
                grade_str += f" ({row['sub_grade']})"
            profile_parts.append(f"- Credit Grade: {grade_str}")

        if 'term' in row and pd.notna(row['term']):
            profile_parts.append(f"- Loan Term: {row['term']}")

        if 'emp_length' in row and pd.notna(row['emp_length']):
            profile_parts.append(f"- Employment Length: {row['emp_length']}")

        if 'home_ownership' in row and pd.notna(row['home_ownership']):
            profile_parts.append(f"- Home Ownership: {row['home_ownership']}")

        if 'verification_status' in row and pd.notna(row['verification_status']):
            profile_parts.append(f"- Income Verification: {row['verification_status']}")

        if 'application_type' in row and pd.notna(row['application_type']):
            profile_parts.append(f"- Application Type: {row['application_type']}")

        profile = "\n".join(profile_parts) if profile_parts else "- Limited information"

        # ç®€åŒ–ç‰ˆPrompt
        prompt = f"""You are an expert psychologist assessing personality traits for credit risk prediction.

TASK: Rate this borrower on TWO key personality dimensions using 0.0-1.0 scale.

=== BORROWER PROFILE ===
{profile}

=== DIMENSION 1: CONSCIENTIOUSNESS ===
Measures: Responsibility, organization, self-discipline, planning ability

HIGH (0.70-0.90): Responsible, organized, plans ahead
- Grade A/B
- 10+ years employment
- Owns home
â†’ Example: Grade A + 10+ years + OWN â†’ 0.78-0.86

MODERATE (0.40-0.60): Average responsibility
- Grade C/D/E
- 3-7 years employment
â†’ Example: Grade D + 5 years + RENT â†’ 0.46-0.56

LOW (0.20-0.40): Less organized, spontaneous
- Grade F/G
- <2 years employment
â†’ Example: Grade G + <1 year + RENT â†’ 0.24-0.34

=== DIMENSION 2: NEUROTICISM ===
Measures: Anxiety, emotional instability, stress reactivity

HIGH (0.65-0.90): Anxious, emotionally unstable
- Grade F/G (history of financial stress)
- Short/unstable employment
â†’ Example: Grade G + <1 year â†’ 0.72-0.84

MODERATE (0.40-0.60): Average emotional stability
- Grade C/D/E
â†’ Example: Grade D + 5 years â†’ 0.48-0.58

LOW (0.20-0.40): Calm, emotionally stable
- Grade A/B (financially stable)
- 10+ years employment
â†’ Example: Grade A + 10+ years â†’ 0.22-0.34

=== MAPPING RULES (Use as baseline) ===
| Grade | Conscientiousness | Neuroticism |
|-------|------------------|-------------|
| A     | 0.78-0.86        | 0.20-0.28   |
| B     | 0.68-0.76        | 0.30-0.38   |
| C     | 0.58-0.66        | 0.40-0.48   |
| D     | 0.48-0.56        | 0.50-0.58   |
| E     | 0.38-0.46        | 0.60-0.68   |
| F     | 0.28-0.36        | 0.70-0.78   |
| G     | 0.22-0.30        | 0.76-0.84   |

Adjust within range based on:
- +0.04 if 10+ years employment
- +0.03 if owns home
- -0.03 if <2 years employment

=== CRITICAL INSTRUCTIONS ===
1. Follow grade mapping strictly
2. Use full 0.2-0.9 range
3. Be decisive - avoid 0.5
4. Output ONLY JSON with 2 dimensions

=== EXAMPLES ===
Grade A, 10+ years, OWN: {{"conscientiousness": 0.84, "neuroticism": 0.23}}
Grade D, 5 years, RENT: {{"conscientiousness": 0.51, "neuroticism": 0.54}}
Grade G, <1 year, RENT: {{"conscientiousness": 0.26, "neuroticism": 0.79}}

Now rate this borrower. Output JSON only:"""

        return prompt

    def _parse_response(self, response_text: str) -> Dict[str, float]:
        """
        è§£æLlamaè¿”å›çš„JSONï¼ˆåªæœ‰2ä¸ªç»´åº¦ï¼‰
        """
        try:
            start = response_text.find('{')
            end = response_text.rfind('}') + 1

            if start == -1 or end == 0:
                raise ValueError("No JSON found in response")

            json_str = response_text[start:end]
            scores = json.loads(json_str)

            # éªŒè¯2ä¸ªç»´åº¦
            validated = {}
            for dim in OCEAN_DIMS:
                if dim in scores:
                    val = float(scores[dim])
                    if val > 1.0:
                        val = val / 100.0
                    validated[dim] = max(0.15, min(0.90, val))
                else:
                    validated[dim] = 0.5

            return validated

        except (json.JSONDecodeError, ValueError, KeyError) as e:
            self.stats["parse_errors"] += 1
            print(f"âš ï¸ è§£æå¤±è´¥: {e}")
            return {dim: 0.5 for dim in OCEAN_DIMS}

    def label_sample(self, row: pd.Series, retries: int = 2) -> Dict[str, float]:
        """ç»™å•ä¸ªæ ·æœ¬æ‰“æ ‡ç­¾"""
        prompt = self._build_prompt(row)
        messages = [{"role": "user", "content": prompt}]

        for attempt in range(retries + 1):
            try:
                response = self.client.query(
                    messages,
                    max_tokens=150,  # å‡å°‘tokenï¼ˆåªæœ‰2ä¸ªç»´åº¦ï¼‰
                    temperature=0
                )
                scores = self._parse_response(response)
                self.stats["success"] += 1
                return scores

            except Exception as e:
                if attempt < retries:
                    time.sleep(2)
                else:
                    self.stats["failed"] += 1
                    return {dim: 0.5 for dim in OCEAN_DIMS}

    def label_batch(self,
                    df: pd.DataFrame,
                    sample_size: int = 1000,
                    stratified: bool = True,
                    rate_limit_delay: float = 0.5) -> pd.DataFrame:
        """
        æ‰¹é‡æ‰“æ ‡ç­¾ï¼ˆä½¿ç”¨æŒ‰gradeåˆ†å±‚æŠ½æ ·ï¼‰
        """
        # æŒ‰gradeåˆ†å±‚æŠ½æ ·
        if stratified and 'grade' in df.columns:
            grade_targets = {
                'A': int(0.18 * sample_size),
                'B': int(0.18 * sample_size),
                'C': int(0.16 * sample_size),
                'D': int(0.16 * sample_size),
                'E': int(0.14 * sample_size),
                'F': int(0.10 * sample_size),
                'G': int(0.08 * sample_size),
            }

            samples = []
            for grade, n in grade_targets.items():
                df_grade = df[df['grade'] == grade]
                if len(df_grade) > 0:
                    n_actual = min(n, len(df_grade))
                    samples.append(df_grade.sample(n=n_actual, random_state=42))

            sample_df = pd.concat(samples).sample(frac=1, random_state=42)
            print(f"[Llama Labeler V2] æŒ‰gradeåˆ†å±‚æŠ½æ ·: {len(sample_df)} ä¸ªæ ·æœ¬")
        else:
            sample_df = df.sample(n=min(sample_size, len(df)), random_state=42)
            print(f"[Llama Labeler V2] éšæœºæŠ½æ ·: {len(sample_df)} ä¸ªæ ·æœ¬")

        sample_df = sample_df.copy()

        print(f"\nå¼€å§‹ä½¿ç”¨ Llama æ¨¡å‹æ ‡æ³¨ 2ç»´OCEANç‰¹å¾...")
        print(f"æ¨¡å‹: {self.client.model}")
        print("=" * 60)

        ocean_labels = []
        total = len(sample_df)

        for idx, (_, row) in enumerate(sample_df.iterrows(), 1):
            self.stats["total"] += 1

            scores = self.label_sample(row)
            ocean_labels.append(scores)

            if idx % 50 == 0 or idx == total:
                success_rate = self.stats["success"] / self.stats["total"] * 100
                print(f"è¿›åº¦: {idx}/{total} ({idx / total * 100:.1f}%) | "
                      f"æˆåŠŸç‡: {success_rate:.1f}%")

            if idx < total:
                time.sleep(rate_limit_delay)

        # æ·»åŠ ground truthåˆ—
        for dim in OCEAN_DIMS:
            sample_df[f'{dim}_truth'] = [o[dim] for o in ocean_labels]

        print("\n" + "=" * 60)
        print("âœ… æ ‡æ³¨å®Œæˆï¼")
        print(f"ç»Ÿè®¡: {self.stats}")
        print(f"\nOCEAN åˆ†å¸ƒ:")
        print(sample_df[[f'{d}_truth' for d in OCEAN_DIMS]].describe())

        return sample_df
```

---

### é™„å½•B: å½“å‰ä»£ç é—®é¢˜å®šä½

**é—®é¢˜ä»£ç ä½ç½®**ï¼š

1. **Promptè®¾è®¡é—®é¢˜**
   - æ–‡ä»¶: `text_features/ocean_llama_labeler.py`
   - è¡Œå·: 80-114
   - é—®é¢˜: èŒƒå›´æŒ‡å¯¼ä¸å®Œæ•´ï¼Œmappingè§„åˆ™é”™è¯¯

2. **åˆ†å±‚æŠ½æ ·ç¼ºå¤±**
   - æ–‡ä»¶: `text_features/ocean_llama_labeler.py`
   - è¡Œå·: 213-226
   - é—®é¢˜: åªæŒ‰targetåˆ†å±‚ï¼Œæ²¡æœ‰æŒ‰gradeåˆ†å±‚

3. **æ¸©åº¦å‚æ•°ä¿å®ˆ**
   - æ–‡ä»¶: `text_features/ocean_llama_labeler.py`
   - è¡Œå·: 181
   - é—®é¢˜: `temperature=0` å¯¼è‡´è¾“å‡ºè¿‡äºä¿å®ˆ

4. **ç¼ºå°‘åˆ†å¸ƒéªŒè¯**
   - æ–‡ä»¶: `LlamaOceanPipeline.ipynb`
   - Cell: 4 (Ground Truthç”Ÿæˆ)
   - é—®é¢˜: æ²¡æœ‰éªŒè¯ç”Ÿæˆçš„OCEANåˆ†å¸ƒè´¨é‡

---

### é™„å½•C: æ–‡çŒ®å‚è€ƒ

1. **Yu et al. (2023)**
   "Chatbot or Human? Using ChatGPT to Extract Personality Traits and Credit Scoring"
   _arXiv preprint_
   - è¯æ˜Conscientiousnesså’ŒNeuroticismä¸ä¿¡ç”¨é£é™©æ˜¾è‘—ç›¸å…³

2. **Costa & McCrae (1992)**
   "Revised NEO Personality Inventory (NEO PI-R)"
   _Psychological Assessment Resources_
   - Big Fiveç†è®ºçš„å­¦æœ¯åŸºç¡€

3. **Hoerl & Kennard (1970)**
   "Ridge Regression: Biased Estimation for Nonorthogonal Problems"
   _Technometrics_
   - Ridgeå›å½’çš„ç»Ÿè®¡ç†è®º

4. **Lundberg & Lee (2017)**
   "A Unified Approach to Interpreting Model Predictions (SHAP)"
   _NeurIPS_
   - æ¨¡å‹å¯è§£é‡Šæ€§æ–¹æ³•

---

## ğŸ¯ æ€»ç»“

### é—®é¢˜æ ¹æº
1. **æ ‡æ³¨è´¨é‡å·®**ï¼š96%æ ·æœ¬çš„openness=0.35ï¼Œå®Œå…¨æ— åŒºåˆ†åº¦
2. **Promptè®¾è®¡ç¼ºé™·**ï¼šæ˜ å°„è§„åˆ™ä¸å®Œæ•´ï¼Œå¿ƒç†å­¦ç†è®ºé”™è¯¯
3. **æ ·æœ¬é‡ä¸è¶³**ï¼š500æ ·æœ¬å­¦ä¹ 70ç‰¹å¾ï¼Œè¿‡æ‹Ÿåˆé£é™©

### æ¨èè·¯å¾„
1. **çŸ­æœŸ**ï¼šæ–¹æ¡ˆC (Behavioral Scores, $0) â†’ å¿«é€ŸéªŒè¯
2. **ä¸­æœŸ**ï¼šæ–¹æ¡ˆB (2ç»´OCEAN, $3) â†’ æå‡æ ‡æ³¨è´¨é‡
3. **é•¿æœŸ**ï¼šå¦‚ä»æ— æ•ˆï¼Œè€ƒè™‘æ¢GPT-4 ($10) æˆ–æ”¶é›†æ–‡æœ¬æ•°æ®

### æˆåŠŸæ ‡å‡†
- ROC-AUCæå‡ â‰¥ +0.010
- OCEANåˆ†å¸ƒï¼šstd > 0.15, unique > 20
- ç‰¹å¾é‡è¦æ€§ï¼šOCEANè¿›å…¥top 30

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**ï¼šç­‰å¾…ä½ é€‰æ‹©æ–¹æ¡ˆåç«‹å³å®æ–½ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-10-08
**ä½œè€…**: Claude Code Analysis
